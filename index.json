[
{
	"uri": "https://k8s.imroc.io/best-practice/configuration-management/helm/upgrade-helm-v2-to-v3/",
	"title": "Helm V2 迁移到 V3",
	"tags": [],
	"description": "",
	"content": "Helm V3 与 V2 版本架构变化较大，数据迁移比较麻烦，官方提供了一个名为 helm-2to3 的插件来简化迁移工作，本文将介绍如何利用此插件迁移 Helm V2 到 V3 版本。这里前提是 Helm V3 已安装，安装方法请参考 这里。\n安装 2to3 插件 一键安装:\n$ helm3 plugin install https://github.com/helm/helm-2to3 Downloading and installing helm-2to3 v0.1.1 ... https://github.com/helm/helm-2to3/releases/download/v0.1.1/helm-2to3_0.1.1_linux_amd64.tar.gz Installed plugin: 2to3 检查插件是否安装成功:\n$ helm3 plugin list NAME VERSION DESCRIPTION 2to3 0.1.1 migrate Helm v2 configuration and releases in-place to Helm v3 迁移 Helm V2 配置 $ helm3 2to3 move config [Helm 2] Home directory: /root/.helm [Helm 3] Config directory: /root/.config/helm [Helm 3] Data directory: /root/.local/share/helm [Helm 3] Create config folder \u0026#34;/root/.config/helm\u0026#34; . [Helm 3] Config folder \u0026#34;/root/.config/helm\u0026#34; created. [Helm 2] repositories file \u0026#34;/root/.helm/repository/repositories.yaml\u0026#34; will copy to [Helm 3] config folder \u0026#34;/root/.config/helm/repositories.yaml\u0026#34; . [Helm 2] repositories file \u0026#34;/root/.helm/repository/repositories.yaml\u0026#34; copied successfully to [Helm 3] config folder \u0026#34;/root/.config/helm/repositories.yaml\u0026#34; . [Helm 3] Create data folder \u0026#34;/root/.local/share/helm\u0026#34; . [Helm 3] data folder \u0026#34;/root/.local/share/helm\u0026#34; created. [Helm 2] plugins \u0026#34;/root/.helm/plugins\u0026#34; will copy to [Helm 3] data folder \u0026#34;/root/.local/share/helm/plugins\u0026#34; . [Helm 2] plugins \u0026#34;/root/.helm/plugins\u0026#34; copied successfully to [Helm 3] data folder \u0026#34;/root/.local/share/helm/plugins\u0026#34; . [Helm 2] starters \u0026#34;/root/.helm/starters\u0026#34; will copy to [Helm 3] data folder \u0026#34;/root/.local/share/helm/starters\u0026#34; . [Helm 2] starters \u0026#34;/root/.helm/starters\u0026#34; copied successfully to [Helm 3] data folder \u0026#34;/root/.local/share/helm/starters\u0026#34; . 上面的操作主要是迁移:\n Chart 仓库 Helm 插件 Chart starters  检查下 repo 和 plugin:\n$ helm3 repo list NAME URL stable https://kubernetes-charts.storage.googleapis.com local http://127.0.0.1:8879/charts $ $ $ helm3 plugin list NAME VERSION DESCRIPTION 2to3 0.1.1 migrate Helm v2 configuration and releases in-place to Helm v3 push 0.1.1 Push chart package to TencentHub 迁移 Heml V2 Release 已经用 Helm V2 部署的应用也可以使用 2to3 的 convert 子命令迁移到 V3，先看下有哪些选项:\n$ helm3 2to3 convert --help migrate Helm v2 release in-place to Helm v3 Usage: 2to3 convert [flags] RELEASE Flags: --delete-v2-releases v2 releases are deleted after migration. By default, the v2 releases are retained --dry-run simulate a convert -h, --help help for convert -l, --label string label to select tiller resources by (default \u0026#34;OWNER=TILLER\u0026#34;) -s, --release-storage string v2 release storage type/object. It can be \u0026#39;secrets\u0026#39; or \u0026#39;configmaps\u0026#39;. This is only used with the \u0026#39;tiller-out-cluster\u0026#39; flag (default \u0026#34;secrets\u0026#34;) -t, --tiller-ns string namespace of Tiller (default \u0026#34;kube-system\u0026#34;) --tiller-out-cluster when Tiller is not running in the cluster e.g. Tillerless  --tiller-out-cluster: 如果你的 Helm V2 是 tiller 在集群外面 (tillerless) 的安装方式，请带上这个参数 --dry-run: 模拟迁移但不做真实迁移操作，建议每次迁移都先带上这个参数测试下效果，没问题的话再去掉这个参数做真实迁移 --tiller-ns: 通常 tiller 如果部署在集群中，并且不在 kube-system 命名空间才指定  看下目前有哪些 helm v2 的 release:\n$ helm ls NAME REVISION UPDATED STATUS CHART APP VERSION NAMESPACE redis 1 Mon Sep 16 14:46:58 2019 DEPLOYED redis-9.1.3 5.0.5 default 选一个用 --dry-run 试下效果:\n$ helm3 2to3 convert redis --dry-run NOTE: This is in dry-run mode, the following actions will not be executed. Run without --dry-run to take the actions described below: Release \u0026#34;redis\u0026#34; will be converted from Helm 2 to Helm 3. [Helm 3] Release \u0026#34;redis\u0026#34; will be created. [Helm 3] ReleaseVersion \u0026#34;redis.v1\u0026#34; will be created. 没有报错，去掉 --dry-run 执行迁移:\n$ helm3 2to3 convert redis Release \u0026#34;redis\u0026#34; will be converted from Helm 2 to Helm 3. [Helm 3] Release \u0026#34;redis\u0026#34; will be created. [Helm 3] ReleaseVersion \u0026#34;redis.v1\u0026#34; will be created. [Helm 3] ReleaseVersion \u0026#34;redis.v1\u0026#34; created. [Helm 3] Release \u0026#34;redis\u0026#34; created. Release \u0026#34;redis\u0026#34; was converted successfully from Helm 2 to Helm 3. Note: the v2 releases still remain and should be removed to avoid conflicts with the migrated v3 releases. 检查迁移结果:\n$ helm ls NAME REVISION UPDATED STATUS CHART APP VERSION NAMESPACE redis 1 Mon Sep 16 14:46:58 2019 DEPLOYED redis-9.1.3 5.0.5 default $ $ $ helm3 ls -a NAME NAMESPACE REVISION UPDATED STATUS CHART redis default 1 2019-09-16 06:46:58.541391356 +0000 UTC deployed redis-9.1.3  helm 3 的 release 区分了命名空间，带上 -a 参数展示所有命名空间的 release  参考资料  How to migrate from Helm v2 to Helm v3: https://helm.sh/blog/migrate-from-helm-v2-to-helm-v3/  "
},
{
	"uri": "https://k8s.imroc.io/optimization/deploy/",
	"title": "应用部署优化",
	"tags": [],
	"description": "",
	"content": "为了提高服务容错能力，我们通常会设置 replicas 给服务创建多个副本，但这并不意味着服务就实现高可用了，下面来介绍应用部署的最佳实践。\n 使用 PodDisruptionBudget 避免驱逐导致服务不可用   使用 preStopHook 和 readinessProbe 保证服务平滑更新不中断   使用反亲和性避免单点故障   "
},
{
	"uri": "https://k8s.imroc.io/deploy/manual/prepare/",
	"title": "部署前的准备工作",
	"tags": [],
	"description": "",
	"content": "准备节点 操作系统 使用 Linux 发行版，本教程主要以 Ubuntu 18.04 为例\nMaster 节点 部署 K8S 控制面组件，推荐三台以上数量的机器\nETCD 节点 部署 ETCD，可以跟 Master 节点用相同的机器，也可以用单独的机器，推荐三台以上数量的机器\nWorker 节点 实际运行工作负载的节点，Master 节点也可以作为 Worker 节点，可以通过 kubelet 参数 --kube-reserved 多预留一些资源给系统组件。\n通常会给 Master 节点打标签，让关键的 Pod 跑在 Master 节点上，比如集群 DNS 服务。\n准备客户端工具 我们需要用 cfssl 和 kubectl 来为各个组件生成证书和 kubeconfig，所以先将这两个工具在某个机器下载安装好。\n安装 cfssl  curl -L https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -o cfssl curl -L https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -o cfssljson curl -L https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -o cfssl-certinfo chmod +x cfssl cfssljson cfssl-certinfo sudo mv cfssl cfssljson cfssl-certinfo /usr/local/bin/ 安装 kubectl wget -q --show-progress --https-only --timestamping \\  https://storage.googleapis.com/kubernetes-release/release/v1.16.1/bin/linux/amd64/kubectl chmod +x kubectl mv kubectl /usr/local/bin/ 生成 CA 证书  由于各个组件都需要配置证书，并且依赖 CA 证书来签发证书，所以我们首先要生成好 CA 证书以及后续的签发配置文件:\ncat \u0026gt; ca-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;Kubernetes\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;SiChuan\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;ChengDu\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;Kubernetes\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;CA\u0026#34; } ] } EOF cfssl gencert -initca ca-csr.json | cfssljson -bare ca cat \u0026gt; ca-config.json \u0026lt;\u0026lt;EOF { \u0026#34;signing\u0026#34;: { \u0026#34;default\u0026#34;: { \u0026#34;expiry\u0026#34;: \u0026#34;8760h\u0026#34; }, \u0026#34;profiles\u0026#34;: { \u0026#34;kubernetes\u0026#34;: { \u0026#34;usages\u0026#34;: [\u0026#34;signing\u0026#34;, \u0026#34;key encipherment\u0026#34;, \u0026#34;server auth\u0026#34;, \u0026#34;client auth\u0026#34;], \u0026#34;expiry\u0026#34;: \u0026#34;8760h\u0026#34; } } } } EOF 生成的文件中有下面三个后面会用到:\n ca-key.pem: CA 证书密钥 ca.pem: CA 证书 ca-config.json: 证书签发配置  csr 文件字段解释:\n CN: Common Name，apiserver 从证书中提取该字段作为请求的用户名 (User Name) Organization，apiserver 从证书中提取该字段作为请求用户所属的组 (Group)   由于这里是 CA 证书，是签发其它证书的根证书，这个证书密钥不会分发出去作为 client 证书，所有组件使用的 client 证书都是由 CA 证书签发而来，所以 CA 证书的 CN 和 O 的名称并不重要，后续其它签发出来的证书的 CN 和 O 的名称才是有用的\n "
},
{
	"uri": "https://k8s.imroc.io/best-practice/configuration-management/helm/install-helm/",
	"title": "安装 Helm",
	"tags": [],
	"description": "",
	"content": "Helm 是 Kubernetes 的包管理器，可以帮我们简化 kubernetes 的操作，一键部署应用。假如你的机器上已经安装了 kubectl 并且能够操作集群，那么你就可以安装 Helm 了。当前最新稳定版是 V2，Helm V3 还未正式发布，下面分别说下安装方法。\n安装 Helm V2 执行脚本安装 helm 客户端:\n$ curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get | bash % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 6737 100 6737 0 0 12491 0 --:--:-- --:--:-- --:--:-- 12475 Downloading https://kubernetes-helm.storage.googleapis.com/helm-v2.9.1-linux-amd64.tar.gz Preparing to install into /usr/local/bin helm installed into /usr/local/bin/helm Run \u0026#39;helm init\u0026#39; to configure helm. 查看客户端版本：\n$ helm version Client: \u0026amp;version.Version{SemVer:\u0026#34;v2.9.1\u0026#34;, GitCommit:\u0026#34;20adb27c7c5868466912eebdf6664e7390ebe710\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;} 安装 tiller 服务端到 kubernetes 集群：\n$ helm init Creating /root/.helm Creating /root/.helm/repository Creating /root/.helm/repository/cache Creating /root/.helm/repository/local Creating /root/.helm/plugins Creating /root/.helm/starters Creating /root/.helm/cache/archive Creating /root/.helm/repository/repositories.yaml Adding stable repo with URL: https://kubernetes-charts.storage.googleapis.com Adding local repo with URL: http://127.0.0.1:8879/charts $HELM_HOME has been configured at /root/.helm. Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster. Please note: by default, Tiller is deployed with an insecure \u0026#39;allow unauthenticated users\u0026#39; policy. For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation Happy Helming! 查看 tiller 是否启动成功:\n$ kubectl get pods --namespace=kube-system | grep tiller tiller-deploy-dccdb6fd9-2df4r 0/1 ImagePullBackOff 0 14h 如果状态是 ImagePullBackOff ，说明是镜像问题，一般是未拉取到镜像（国内机器拉取不到 gcr.io 下的镜像) 可以查看下是什么镜像:\n$ kubectl describe pod tiller-deploy-dccdb6fd9-2df4r --namespace=kube-system Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning Failed 36m (x5 over 12h) kubelet, k8s-node1 Failed to pull image \u0026#34;gcr.io/kubernetes-helm/tiller:v2.9.1\u0026#34;: rpc error: code = Unknown desc = Get https://gcr.io/v1/_ping: dial tcp 64.233.189.82:443: i/o timeout Normal BackOff 11m (x3221 over 14h) kubelet, k8s-node1 Back-off pulling image \u0026#34;gcr.io/kubernetes-helm/tiller:v2.9.1\u0026#34; Warning Failed 6m (x3237 over 14h) kubelet, k8s-node1 Error: ImagePullBackOff Warning Failed 1m (x15 over 14h) kubelet, k8s-node1 Failed to pull image \u0026#34;gcr.io/kubernetes-helm/tiller:v2.9.1\u0026#34;: rpc error: code = Unknown desc = Get https://gcr.io/v1/_ping: dial tcp 64.233.188.82:443: i/o timeout 把这个没拉取到镜像想办法下载到这台机器上。当我们看到状态为 Running 说明 tiller 已经成功运行了:\n$ kubectl get pods -n kube-system | grep tiller tiller-deploy-dccdb6fd9-2df4r 1/1 Running 1 41d 默认安装的 tiller 权限很小，我们执行下面的脚本给它加最大权限，这样方便我们可以用 helm 部署应用到任意 namespace 下:\nkubectl create serviceaccount --namespace=kube-system tiller kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller kubectl patch deploy --namespace=kube-system tiller-deploy -p \u0026#39;{\u0026#34;spec\u0026#34;:{\u0026#34;template\u0026#34;:{\u0026#34;spec\u0026#34;:{\u0026#34;serviceAccount\u0026#34;:\u0026#34;tiller\u0026#34;}}}}\u0026#39; 更多参考官方文档: https://helm.sh/docs/using_helm/#quickstart-guide\n安装 Helm V3 在 https://github.com/helm/helm/releases 找到对应系统的二进制包下载，比如下载 v3.0.0-beta.3 的 linux amd64 版:\n$ wget https://get.helm.sh/helm-v3.0.0-beta.3-linux-amd64.tar.gz 解压并移动到 PATH 下面:\n$ tar -zxvf helm-v3.0.0-beta.3-linux-amd64.tar.gz linux-amd64/ linux-amd64/LICENSE linux-amd64/helm linux-amd64/README.md $ cd linux-amd64/ $ ls LICENSE README.md helm $ mv helm /usr/local/bin/helm3 "
},
{
	"uri": "https://k8s.imroc.io/best-practice/",
	"title": "最佳实践",
	"tags": [],
	"description": "",
	"content": "  泛域名转发     集群配置管理    Helm    Helm V2 迁移到 V3   安装 Helm     "
},
{
	"uri": "https://k8s.imroc.io/deploy/manual/bootstrapping-etcd/",
	"title": "部署 ETCD",
	"tags": [],
	"description": "",
	"content": "为 ETCD 签发证书 这里证书可以只创建一次，所有 etcd 实例都公用这里创建的证书:\ncat \u0026gt; etcd-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;etcd\u0026#34;, \u0026#34;hosts\u0026#34;: [ \u0026#34;127.0.0.1\u0026#34;, \u0026#34;10.200.16.79\u0026#34;, \u0026#34;10.200.17.6\u0026#34;, \u0026#34;10.200.16.70\u0026#34; ], \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;SiChuan\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;Chengdu\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;etcd\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;etcd\u0026#34; } ] } EOF cfssl gencert \\  -ca=ca.pem \\  -ca-key=ca-key.pem \\  -config=ca-config.json \\  -profile=kubernetes \\  etcd-csr.json | cfssljson -bare etcd  hosts 需要包含 etcd 每个实例所在节点的内网 IP\n 会生成下面两个重要的文件:\n etcd-key.pem: kube-apiserver 证书密钥 etcd.pem: kube-apiserver 证书  下载安装 ETCD 下载 release 包:\nwget -q --show-progress --https-only --timestamping \\  \u0026#34;https://github.com/etcd-io/etcd/releases/download/v3.4.1/etcd-v3.4.1-linux-amd64.tar.gz\u0026#34; 解压安装 etcd 和 etcdctl 到 PATH:\ntar -xvf etcd-v3.4.1-linux-amd64.tar.gz sudo mv etcd-v3.4.1-linux-amd64/etcd* /usr/local/bin/ 配置 创建配置相关目录，放入证书文件:\nsudo mkdir -p /etc/etcd /var/lib/etcd sudo cp ca.pem etcd-key.pem etcd.pem /etc/etcd/ etcd 集群每个成员都需要一个名字，这里第一个成员名字用 infra0，第二个可以用 infra1，以此类推，你也可以直接用节点的 hostname:\nNAME=infra0 记当前部署 ETCD 的节点的内网 IP 为 INTERNAL_IP:\nINTERNAL_IP=10.200.16.79 记所有 ETCD 成员的名称和成员间通信的 https 监听地址为 ETCD_SERVERS (注意是 2380 端口，不是 2379):\nETCD_SERVERS=\u0026#34;infra0=https://10.200.16.79:2380,infra1=https://10.200.17.6:2380,infra2=https://10.200.16.70:2380\u0026#34; 创建 systemd 配置:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/etcd.service [Unit] Description=etcd Documentation=https://github.com/coreos [Service] Type=notify ExecStart=/usr/local/bin/etcd \\\\ --name ${NAME} \\\\ --cert-file=/etc/etcd/etcd.pem \\\\ --key-file=/etc/etcd/etcd-key.pem \\\\ --peer-cert-file=/etc/etcd/etcd.pem \\\\ --peer-key-file=/etc/etcd/etcd-key.pem \\\\ --trusted-ca-file=/etc/etcd/ca.pem \\\\ --peer-trusted-ca-file=/etc/etcd/ca.pem \\\\ --peer-client-cert-auth \\\\ --client-cert-auth \\\\ --initial-advertise-peer-urls https://${INTERNAL_IP}:2380 \\\\ --listen-peer-urls https://${INTERNAL_IP}:2380 \\\\ --listen-client-urls https://${INTERNAL_IP}:2379,https://127.0.0.1:2379 \\\\ --advertise-client-urls https://${INTERNAL_IP}:2379 \\\\ --initial-cluster-token etcd-cluster-0 \\\\ --initial-cluster ${ETCD_SERVERS} \\\\ --initial-cluster-state new \\\\ --data-dir=/var/lib/etcd Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF 启动 sudo systemctl daemon-reload sudo systemctl enable etcd sudo systemctl start etcd 验证 等所有 etcd 成员安装启动成功后，来验证下是否可用:\nsudo ETCDCTL_API=3 etcdctl member list \\  --endpoints=https://127.0.0.1:2379 \\  --cacert=/etc/etcd/ca.pem \\  --cert=/etc/etcd/etcd.pem \\  --key=/etc/etcd/etcd-key.pem 输出:\na7f995caeeaf7a59, started, infra1, https://10.200.17.6:2380, https://10.200.17.6:2379, false b90901a06e9aec53, started, infra2, https://10.200.16.70:2380, https://10.200.16.70:2379, false ba126eb695f5ba71, started, infra0, https://10.200.16.79:2380, https://10.200.16.79:2379, false "
},
{
	"uri": "https://k8s.imroc.io/deploy/manual/bootstrapping-master/",
	"title": "部署 Master",
	"tags": [],
	"description": "",
	"content": "准备证书  Master 节点的准备证书操作只需要做一次，将生成的证书拷到每个 Master 节点上以复用。\n前提条件:\n 签发证书需要用到 生成 CA 证书 时创建的 CA 证书及其密钥文件，确保它们在当前目录 确保 cfssl 在当前环境已安装，安装方法参考 这里  为 kube-apiserver 签发证书  kube-apiserver 是 k8s 的访问核心，所有 K8S 组件和用户 kubectl 操作都会请求 kube-apiserver，通常启用 tls 证书认证，证书里面需要包含 kube-apiserver 可能被访问的地址，这样 client 校验 kube-apiserver 证书时才会通过，集群内的 Pod 一般通过 kube-apiserver 的 Service 名称访问，可能的 Service 名称有:\n kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster kubernetes.default.svc.cluster.local  通过集群外也可能访问 kube-apiserver，比如使用 kubectl，或者部署在集群外的服务会连 kube-apiserver (比如部署在集群外的 Promethues 采集集群指标做监控)，这里列一下通过集群外连 kube-apiserver 有哪些可能地址:\n 127.0.0.1: 在 Master 所在机器通过 127.0.0.1 访问本机 kube-apiserver Service CIDR 的第一个 IP，比如 flanneld 以 daemonset 部署在每个节点，使用 hostNetwork 而不是集群网络，这时无法通过 service 名称访问 apiserver，因为使用 hostNetwork 无法解析 service 名称 (使用的 DNS 不是集群 DNS)，它会使用 apiserver 内部的 CLUSTER IP 去请求 apiserver。 kube-controller-manager 的 --service-cluster-ip-range 启动参数是 10.32.0.0/16，那么第一个 IP 就是 10.32.0.1 自定义域名: 配了 DNS，通过域名访问 kube-apiserver，也要将域名写入证书 LB IP: 如果 Master 节点前面挂了一个负载均衡器，外界可以通过 LB IP 来访问 kube-apiserver Master 节点 IP: 如果没有 Master 负载均衡器，管理员在节点上执行 kubectl 通常使用 Master 节点 IP 访问 kube-apiserver  准备 CSR 文件:\ncat \u0026gt; apiserver-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;kubernetes\u0026#34;, \u0026#34;hosts\u0026#34;: [ \u0026#34;127.0.0.1\u0026#34;, \u0026#34;10.32.0.1\u0026#34;, \u0026#34;10.200.16.79\u0026#34;, \u0026#34;kubernetes\u0026#34;, \u0026#34;kubernetes.default\u0026#34;, \u0026#34;kubernetes.default.svc\u0026#34;, \u0026#34;kubernetes.default.svc.cluster\u0026#34;, \u0026#34;kubernetes.default.svc.cluster.local\u0026#34; ], \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;SiChuan\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;Chengdu\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;Kubernetes\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;Kube API Server\u0026#34; } ] } EOF  hosts 这里只准备了必要的，根据需求可增加，通常 Master 节点 IP 也都要加进去，你可以执行了上面的命令后再编辑一下 apiserver-csr.json，将需要 hosts 都加进去。\n cfssl gencert \\  -ca=ca.pem \\  -ca-key=ca-key.pem \\  -config=ca-config.json \\  -profile=kubernetes \\  apiserver-csr.json | cfssljson -bare apiserver 会生成下面两个重要的文件:\n apiserver-key.pem: kube-apiserver 证书密钥 apiserver.pem: kube-apiserver 证书  为 kube-controller-manager 签发证书  cat \u0026gt; kube-controller-manager-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;system:kube-controller-manager\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;SiChuan\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;Chengdu\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;system:kube-controller-manager\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;Kube Controller Manager\u0026#34; } ] } EOF cfssl gencert \\  -ca=ca.pem \\  -ca-key=ca-key.pem \\  -config=ca-config.json \\  -profile=kubernetes \\  kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager 生成以下两个文件:\n kube-controller-manager-key.pem: kube-controller-manager 证书密钥 kube-controller-manager.pem: kube-controller-manager 证书  为 kube-scheduler 签发证书  cat \u0026gt; kube-scheduler-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;system:kube-scheduler\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;SiChuan\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;Chengdu\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;system:kube-scheduler\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;Kube Scheduler\u0026#34; } ] } EOF cfssl gencert \\  -ca=ca.pem \\  -ca-key=ca-key.pem \\  -config=ca-config.json \\  -profile=kubernetes \\  kube-scheduler-csr.json | cfssljson -bare kube-scheduler 生成以下两个文件:\n kube-scheduler-key.pem: kube-scheduler 证书密钥 kube-scheduler.pem: kube-scheduler 证书公钥  签发 Service Account 密钥对  kube-controller-manager 会使用此密钥对来给 service account 签发 token，更多详情参考官方文档: https://kubernetes.io/docs/reference/access-authn-authz/service-accounts-admin/\ncat \u0026gt; service-account-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;service-accounts\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;SiChuan\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;Chengdu\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;Kubernetes\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;Service Account\u0026#34; } ] } EOF cfssl gencert \\  -ca=ca.pem \\  -ca-key=ca-key.pem \\  -config=ca-config.json \\  -profile=kubernetes \\  service-account-csr.json | cfssljson -bare service-account 生成以下两个文件:\n service-account-key.pem: service account 证书公钥 service-account.pem: service account 证书私钥  为管理员签发证书  为最高权限管理员证书:\ncat \u0026gt; admin-csr.json \u0026lt;\u0026lt;EOF { \u0026#34;CN\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;SiChuan\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;Chengdu\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;system:masters\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;System\u0026#34; } ] } EOF cfssl gencert \\  -ca=ca.pem \\  -ca-key=ca-key.pem \\  -config=ca-config.json \\  -profile=kubernetes \\  admin-csr.json | cfssljson -bare admin 生成一下两个文件:\n admin-key.pem: 管理员证书密钥 admin.pem: 管理员证书  给用户签发证书后，用户访问 kube-apiserver 的请求就带上此证书，kube-apiserver 校验成功后表示认证成功，但还需要授权才允许访问，kube-apiserver 会提取证书中字段 CN 作为用户名，这里用户名叫 admin，但这只是个名称标识，它有什么权限呢？admin 是预置最高权限的用户名吗？不是的！不过 kube-apiserver 确实预置了一个最高权限的 ClusterRole，叫做 cluster-admin，还有个预置的 ClusterRoleBinding 将 cluster-admin 这个 ClusterRole 与 system:masters 这个用户组关联起来了，所以说我们给用户签发证书只要在 system:masters 这个用户组就拥有了最高权限。\n以此类推，我们签发证书时也可以将用户设置到其它用户组，然后为其创建 RBAC 规则来细粒度的控制权限，减少安全隐患。\n更多 K8S 预置的 Role 与 RoleBinding 请参考: https://kubernetes.io/docs/reference/access-authn-authz/rbac/#default-roles-and-role-bindings\n准备 kubeconfig  部署 Master 的准备 kubeconfig 操作只需要做一次，将生成的 kubeconfig 拷到每个 Master 节点上以复用。\nkubeconfig 主要是各组件以及用户访问 apiserver 的必要配置，包含 apiserver 地址、client 证书与 CA 证书等信息。下面介绍为各个组件生成 kubeconfig 的方法。\n前提条件:\n 我们使用 kubectl 来辅助生成 kubeconfig，确保 kubectl 已安装。 生成 kubeconfig 会用到之前准备证书时创建的证书与密钥，确保这些生成的文件在当前目录。  确定 apiserver 访问入口 所有组件都会去连 apiserver，所以首先需要确定你的 apiserver 访问入口的地址:\n 如果所有 master 组件都部署在一个节点，它们可以通过 127.0.0.1 这个 IP访问 apiserver。 如果 master 有多个节点，但 apiserver 只有一个实例，可以直接写 apiserver 所在机器的内网 IP 访问地址。 如果做了高可用，有多个 apiserver 实例，前面挂了负载均衡器，就可以写负载均衡器的访问地址。 入口地址的域名或IP必须是在之前 为 kube-apiserver 签发证书 的 hosts 列表里。  这里我们用 APISERVER 这个变量表示 apiserver 的访问地址，其它组件都需要配置这个地址，根据自身情况改下这个变量的值:\nAPISERVER=\u0026#34;https://10.200.16.79:6443\u0026#34; 为 kube-controller-manager 创建 kubeconfig  APISERVER=\u0026#34;https://10.200.16.79:6443\u0026#34; kubectl config set-cluster roc \\  --certificate-authority=ca.pem \\  --embed-certs=true \\  --server=${APISERVER} \\  --kubeconfig=kube-controller-manager.kubeconfig kubectl config set-credentials system:kube-controller-manager \\  --client-certificate=kube-controller-manager.pem \\  --client-key=kube-controller-manager-key.pem \\  --embed-certs=true \\  --kubeconfig=kube-controller-manager.kubeconfig kubectl config set-context default \\  --cluster=roc \\  --user=system:kube-controller-manager \\  --kubeconfig=kube-controller-manager.kubeconfig kubectl config use-context default --kubeconfig=kube-controller-manager.kubeconfig 生成文件:\nkube-controller-manager.kubeconfig 为 kube-scheduler 创建 kubeconfig  APISERVER=\u0026#34;https://10.200.16.79:6443\u0026#34; kubectl config set-cluster roc \\  --certificate-authority=ca.pem \\  --embed-certs=true \\  --server=${APISERVER} \\  --kubeconfig=kube-scheduler.kubeconfig kubectl config set-credentials system:kube-scheduler \\  --client-certificate=kube-scheduler.pem \\  --client-key=kube-scheduler-key.pem \\  --embed-certs=true \\  --kubeconfig=kube-scheduler.kubeconfig kubectl config set-context default \\  --cluster=roc \\  --user=system:kube-scheduler \\  --kubeconfig=kube-scheduler.kubeconfig kubectl config use-context default --kubeconfig=kube-scheduler.kubeconfig 生成文件:\nkube-scheduler.kubeconfig 为管理员创建 kubeconfig  这里为管理员生成 kubeconfig，方便使用 kubectl 来管理集群:\nAPISERVER=\u0026#34;https://10.200.16.79:6443\u0026#34; kubectl config set-cluster roc \\  --certificate-authority=ca.pem \\  --embed-certs=true \\  --server=${APISERVER} \\  --kubeconfig=admin.kubeconfig kubectl config set-credentials admin \\  --client-certificate=admin.pem \\  --client-key=admin-key.pem \\  --embed-certs=true \\  --kubeconfig=admin.kubeconfig kubectl config set-context default \\  --cluster=roc \\  --user=admin \\  --kubeconfig=admin.kubeconfig kubectl config use-context default --kubeconfig=admin.kubeconfig 生成文件:\nadmin.kubeconfig 将 admin.kubeconfig 放到需要执行 kubectl 的机器的 ~/.kube/config 这个目录，这是 kubectl 读取 kubeconfig 的默认路径，执行 kubectl 时就不需要指定 kubeconfig 路径了:\nmv admin.kubeconfig ~/.kube/config 下载安装控制面组件 wget -q --show-progress --https-only --timestamping \\  https://storage.googleapis.com/kubernetes-release/release/v1.16.1/bin/linux/amd64/kube-apiserver \\  https://storage.googleapis.com/kubernetes-release/release/v1.16.1/bin/linux/amd64/kube-controller-manager \\  https://storage.googleapis.com/kubernetes-release/release/v1.16.1/bin/linux/amd64/kube-scheduler chmod +x kube-apiserver kube-controller-manager kube-scheduler mv kube-apiserver kube-controller-manager kube-scheduler /usr/local/bin/ 配置控制面组件  准备配置相关目录:\nsudo mkdir -p /etc/kubernetes/config sudo mkdir -p /var/lib/kubernetes 确定集群的集群网段 (Pod IP 占用网段)和 serivce 网段 (service 的 cluster ip 占用网段)，它们可以没有交集。\n记集群网段为 CLUSTER_CIDR:\nCLUSTER_CIDR=10.10.0.0/16 记 service 网段为 SERVICE_CIDR:\nSERVICE_CIDR=10.32.0.0/16 配置 kube-apiserver  放入证书文件:\nsudo cp ca.pem ca-key.pem apiserver-key.pem apiserver.pem \\  service-account-key.pem service-account.pem /var/lib/kubernetes/ 记所有 ETCD 实例的访问地址为 ETCD_SERVERS (替换 IP 为所有 ETCD 节点内网 IP):\nETCD_SERVERS=\u0026#34;https://10.200.16.79:2379,https://10.200.17.6:2379,https://10.200.16.70:2379\u0026#34; 记当前节点内网 IP 为 INTERNAL_IP:\nINTERNAL_IP=10.200.16.79 配置 systemd:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/kube-apiserver.service [Unit] Description=Kubernetes API Server Documentation=https://github.com/kubernetes/kubernetes [Service] ExecStart=/usr/local/bin/kube-apiserver \\\\ --enable-bootstrap-token-auth=true \\\\ --advertise-address=${INTERNAL_IP} \\\\ --allow-privileged=true \\\\ --apiserver-count=3 \\\\ --audit-log-maxage=30 \\\\ --audit-log-maxbackup=3 \\\\ --audit-log-maxsize=100 \\\\ --audit-log-path=/var/log/audit.log \\\\ --authorization-mode=Node,RBAC \\\\ --bind-address=0.0.0.0 \\\\ --client-ca-file=/var/lib/kubernetes/ca.pem \\\\ --enable-admission-plugins=NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \\\\ --etcd-cafile=/var/lib/kubernetes/ca.pem \\\\ --etcd-certfile=/var/lib/kubernetes/apiserver.pem \\\\ --etcd-keyfile=/var/lib/kubernetes/apiserver-key.pem \\\\ --etcd-servers=${ETCD_SERVERS} \\\\ --event-ttl=1h \\\\ --kubelet-certificate-authority=/var/lib/kubernetes/ca.pem \\\\ --kubelet-client-certificate=/var/lib/kubernetes/apiserver.pem \\\\ --kubelet-client-key=/var/lib/kubernetes/apiserver-key.pem \\\\ --kubelet-https=true \\\\ --runtime-config=api/all \\\\ --service-account-key-file=/var/lib/kubernetes/service-account.pem \\\\ --service-cluster-ip-range=${SERVICE_CIDR} \\\\ --service-node-port-range=30000-32767 \\\\ --tls-cert-file=/var/lib/kubernetes/apiserver.pem \\\\ --tls-private-key-file=/var/lib/kubernetes/apiserver-key.pem \\\\ --v=2 Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF  --enable-bootstrap-token-auth=true 启用 bootstrap token 方式为 kubelet 签发证书  配置 kube-controller-manager  放入 kubeconfig:\nsudo cp kube-controller-manager.kubeconfig /var/lib/kubernetes/ 准备 systemd 配置 kube-controller-manager.service:\nCLUSTER_CIDR=10.10.0.0/16 SERVICE_CIDR=10.32.0.0/16 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/kube-controller-manager.service [Unit] Description=Kubernetes Controller Manager Documentation=https://github.com/kubernetes/kubernetes [Service] ExecStart=/usr/local/bin/kube-controller-manager \\\\ --address=0.0.0.0 \\\\ --cluster-cidr=${CLUSTER_CIDR} \\\\ --allocate-node-cidrs \\\\ --cluster-name=kubernetes \\\\ --cluster-signing-cert-file=/var/lib/kubernetes/ca.pem \\\\ --cluster-signing-key-file=/var/lib/kubernetes/ca-key.pem \\\\ --kubeconfig=/var/lib/kubernetes/kube-controller-manager.kubeconfig \\\\ --leader-elect=true \\\\ --root-ca-file=/var/lib/kubernetes/ca.pem \\\\ --service-account-private-key-file=/var/lib/kubernetes/service-account-key.pem \\\\ --service-cluster-ip-range=${SERVICE_CIDR} \\\\ --use-service-account-credentials=true \\\\ --v=2 Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF  所有 kube-controller-manager 实例都使用相同的 systemd service 文件，可以直接将这里创建好的拷贝给其它 Master 节点\n 配置 kube-scheduler  放入 kubeconfig:\nsudo cp kube-scheduler.kubeconfig /var/lib/kubernetes/ 准备启动配置文件 kube-scheduler.yaml:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/kubernetes/config/kube-scheduler.yaml apiVersion: kubescheduler.config.k8s.io/v1alpha1 kind: KubeSchedulerConfiguration clientConnection: kubeconfig: \u0026#34;/var/lib/kubernetes/kube-scheduler.kubeconfig\u0026#34; leaderElection: leaderElect: true EOF 准备 systemd 配置 kube-scheduler.service:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/kube-scheduler.service [Unit] Description=Kubernetes Scheduler Documentation=https://github.com/kubernetes/kubernetes [Service] ExecStart=/usr/local/bin/kube-scheduler \\\\ --config=/etc/kubernetes/config/kube-scheduler.yaml \\\\ --v=2 Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF 启动 sudo systemctl daemon-reload sudo systemctl enable kube-apiserver kube-controller-manager kube-scheduler sudo systemctl start kube-apiserver kube-controller-manager kube-scheduler RBAC 授权 kube-apiserver 访问 kubelet kube-apiserver 有些情况也会访问 kubelet，比如获取 metrics、查看容器日志或登录容器，这是 kubelet 作为 server， kube-apiserver 作为 client，kubelet 监听的 https，kube-apiserver 经过证书认证访问 kubelet，但还需要经过授权才能成功调用接口，我们通过创建 RBAC 规则授权 kube-apiserver 访问 kubelet:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRole metadata: annotations: rbac.authorization.kubernetes.io/autoupdate: \u0026#34;true\u0026#34; labels: kubernetes.io/bootstrapping: rbac-defaults name: system:kube-apiserver-to-kubelet rules: - apiGroups: - \u0026#34;\u0026#34; resources: - nodes/proxy - nodes/stats - nodes/log - nodes/spec - nodes/metrics verbs: - \u0026#34;*\u0026#34; EOF cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: system:kube-apiserver namespace: \u0026#34;\u0026#34; roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:kube-apiserver-to-kubelet subjects: - apiGroup: rbac.authorization.k8s.io kind: User name: kubernetes EOF RBAC 授权 kubelet 创建 CSR 与自动签发和更新证书  节点 kubelet 通过 Bootstrap Token 调用 apiserver CSR API 请求签发证书，kubelet 通过 bootstrap token 认证后会在 system:bootstrappers 用户组里，我们还需要给它授权调用 CSR API，为这个用户组绑定预定义的 system:node-bootstrapper 这个 ClusterRole 就可以:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - # enable bootstrapping nodes to create CSR apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: create-csrs-for-bootstrapping subjects: - kind: Group name: system:bootstrappers apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: system:node-bootstrapper apiGroup: rbac.authorization.k8s.io EOF  这里的 CSR API 主要用于 kubelet 发起 client 和 server 证书签发请求\n 给 kubelet 授权自动审批通过 client 证书的 CSR 请求权限以实现自动创建新的 client 证书 (之前没创建过 client 证书，通过 bootstrap token 认证后在 system:bootstrappers 用户组里):\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - # Approve all CSRs for the group \u0026#34;system:bootstrappers\u0026#34; apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: auto-approve-csrs-for-group subjects: - kind: Group name: system:bootstrappers apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: system:certificates.k8s.io:certificatesigningrequests:nodeclient apiGroup: rbac.authorization.k8s.io EOF 给已启动过的 kubelet 授权自动审批通过 server 证书的 CSR 请求权限以实现自动轮转 client 证书 (之前创建过证书，在证书还未过期前通过证书认证后在 system:nodes 用户组里):\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - # Approve renewal CSRs for the group \u0026#34;system:nodes\u0026#34; apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: auto-approve-renewals-for-nodes subjects: - kind: Group name: system:nodes apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient apiGroup: rbac.authorization.k8s.io EOF  注意上面两个授权都只是针对于 client 证书签发的自动审批权限，server 证书目前不支持自动审批，需要管理员通过 kubectl certificate approve \u0026lt;csr name\u0026gt; 来人工审批或者自己写外部 controller 来实现自动审批 (kubelet 访问 apiserver 使用 client 证书, apiserver 主动访问 kubelet 时才会用到 server 证书，通常用于获取 metrics 的场景)\n 创建 Bootstrap Token 与 bootstrap-kubeconfig  bootstrap token 用于 kubelet 自动请求签发证书，以 Secret 形式存储，不需要事先给 apiserver 配置静态 token，这样也易于管理。\n创建了 bootstrap token 后我们利用它使用它来创建 bootstrap-kubeconfig 以供后面部署 Worker 节点用 (kubelet 使用 bootstrap-kubeconfig 自动创建证书)，下面是创建方法:\nAPISERVER=\u0026#34;https://10.200.16.79:6443\u0026#34; # token id should match regex: [a-z0-9]{6} TOKEN_ID=$(head -c 16 /dev/urandom | od -An -t x | tr -d \u0026#39; \u0026#39; | head -c 6) # token secret should match regex: [a-z0-9]{16} TOKEN_SECRET=$(head -c 16 /dev/urandom | od -An -t x | tr -d \u0026#39; \u0026#39; | head -c 16) cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: Secret metadata: # Name MUST be of form \u0026#34;bootstrap-token-\u0026lt;token id\u0026gt;\u0026#34;, name: bootstrap-token-${TOKEN_ID} namespace: kube-system # Type MUST be \u0026#39;bootstrap.kubernetes.io/token\u0026#39; type: bootstrap.kubernetes.io/token stringData: # Human readable description. Optional. description: \u0026#34;The default bootstrap token used for signing certificates\u0026#34; # Token ID and secret. Required. token-id: \u0026#34;${TOKEN_ID}\u0026#34; token-secret: \u0026#34;${TOKEN_SECRET}\u0026#34; # Expiration. Optional. # expiration: 2020-03-10T03:22:11Z # Allowed usages. usage-bootstrap-authentication: \u0026#34;true\u0026#34; usage-bootstrap-signing: \u0026#34;true\u0026#34; # Extra groups to authenticate the token as. Must start with \u0026#34;system:bootstrappers:\u0026#34; # auth-extra-groups: system:bootstrappers:worker,system:bootstrappers:ingress EOF kubectl config --kubeconfig=bootstrap-kubeconfig set-cluster bootstrap --server=\u0026#34;${APISERVER}\u0026#34; --certificate-authority=ca.pem --embed-certs=true kubectl config --kubeconfig=bootstrap-kubeconfig set-credentials kubelet-bootstrap --token=${TOKEN_ID}.${TOKEN_SECRET} kubectl config --kubeconfig=bootstrap-kubeconfig set-context bootstrap --user=kubelet-bootstrap --cluster=bootstrap kubectl config --kubeconfig=bootstrap-kubeconfig use-context bootstrap  bootstrap token 的 secret 格式参考: https://kubernetes.io/docs/reference/access-authn-authz/bootstrap-tokens/#bootstrap-token-secret-format\n 生成文件:\nbootstrap-kubeconfig "
},
{
	"uri": "https://k8s.imroc.io/cluster/",
	"title": "集群方案",
	"tags": [],
	"description": "",
	"content": "  Ingress 方案    Nginx Ingress    安装 nginx ingress controller    Traefik Ingress    安装 traefik ingress controller     Metrics 方案    安装 metrics server      网络方案    Flannel    部署 Flannel    彻底理解集群网络      运行时方案    Containerd    安装 containerd     "
},
{
	"uri": "https://k8s.imroc.io/deploy/manual/bootstrapping-worker-nodes/",
	"title": "部署 Worker 节点",
	"tags": [],
	"description": "",
	"content": "Worker 节点主要安装 kubelet 来管理、运行工作负载 (Master 节点也可以部署为特殊 Worker 节点来部署关键服务)\n安装依赖 sudo apt-get update sudo apt-get -y install socat conntrack ipset 禁用 Swap 默认情况下，如果开启了 swap，kubelet 会启动失败，k8s 节点推荐禁用 swap。\n验证一下是否开启:\nsudo swapon --show 如果输出不是空的说明开启了 swap，使用下面的命令禁用 swap:\nsudo swapoff -a 为了防止开机自动挂载 swap 分区，可以注释 /etc/fstab 中相应的条目:\nsudo sed -i \u0026#39;/ swap / s/^\\(.*\\)$/#\\1/g\u0026#39; /etc/fstab 关闭 SELinux 关闭 SELinux，否则后续 K8S 挂载目录时可能报错 Permission denied：\nsudo setenforce 0 修改配置文件，永久生效:\nsudo sed -i \u0026#34;s/SELINUX=enforcing/SELINUX=disabled/g\u0026#34; /etc/selinux/config 准备目录 sudo mkdir -p \\  /etc/cni/net.d \\  /opt/cni/bin \\  /var/lib/kubelet \\  /var/lib/kubernetes \\  /var/run/kubernetes 下载安装二进制 下载二进制:\nwget -q --show-progress --https-only --timestamping \\  https://github.com/opencontainers/runc/releases/download/v1.0.0-rc8/runc.amd64 \\  https://github.com/containerd/containerd/releases/download/v1.3.0/containerd-1.3.0.linux-amd64.tar.gz \\  https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.16.1/crictl-v1.16.1-linux-amd64.tar.gz \\  https://github.com/containernetworking/plugins/releases/download/v0.8.2/cni-plugins-linux-amd64-v0.8.2.tgz \\  https://storage.googleapis.com/kubernetes-release/release/v1.16.1/bin/linux/amd64/kubelet sudo mv runc.amd64 runc 安装二进制:\nchmod +x crictl kubelet runc tar -xvf crictl-v1.16.1-linux-amd64.tar.gz mkdir containerd tar -xvf containerd-1.3.0.linux-amd64.tar.gz -C containerd sudo cp crictl kubelet runc /usr/local/bin/ sudo cp containerd/bin/* /bin/ sudo tar -xvf cni-plugins-linux-amd64-v0.8.2.tgz -C /opt/cni/bin/ 配置 配置 containerd 创建 containerd 启动配置 config.toml:\nsudo mkdir -p /etc/containerd/ cat \u0026lt;\u0026lt; EOF | sudo tee /etc/containerd/config.toml [plugins] [plugins.cri.containerd] snapshotter = \u0026#34;overlayfs\u0026#34; [plugins.cri.containerd.default_runtime] runtime_type = \u0026#34;io.containerd.runtime.v1.linux\u0026#34; runtime_engine = \u0026#34;/usr/local/bin/runc\u0026#34; runtime_root = \u0026#34;\u0026#34; EOF 创建 systemd 配置 containerd.service:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/containerd.service [Unit] Description=containerd container runtime Documentation=https://containerd.io After=network.target [Service] ExecStartPre=/sbin/modprobe overlay ExecStart=/bin/containerd Restart=always RestartSec=5 Delegate=yes KillMode=process OOMScoreAdjust=-999 LimitNOFILE=1048576 LimitNPROC=infinity LimitCORE=infinity [Install] WantedBy=multi-user.target EOF 配置 kubelet 放入 这里 创建好的 CA 证书与 这里 创建好的 bootstrap-kubeconfig:\nsudo cp ca.pem /var/lib/kubernetes/ sudo cp bootstrap-kubeconfig /var/lib/kubelet/ 事先确定好集群 DNS 的 CLUSTER IP 地址，通常可以用 service 网段的最后一个可用 IP 地址:\nDNS=10.32.0.255 创建 kubelet 启动配置 config.yaml:\ncat \u0026lt;\u0026lt;EOF | sudo tee /var/lib/kubelet/config.yaml kind: KubeletConfiguration apiVersion: kubelet.config.k8s.io/v1beta1 authentication: anonymous: enabled: false webhook: enabled: true x509: clientCAFile: \u0026#34;/var/lib/kubernetes/ca.pem\u0026#34; authorization: mode: Webhook clusterDomain: \u0026#34;cluster.local\u0026#34; clusterDNS: - \u0026#34;${DNS}\u0026#34; resolvConf: \u0026#34;/run/systemd/resolve/resolv.conf\u0026#34; runtimeRequestTimeout: \u0026#34;15m\u0026#34; rotateCertificates: true serverTLSBootstrap: true EOF 用 NODE 变量表示节点名称，kube-apiserver 所在节点需要能够通过这个名称访问到节点，这里推荐直接使用节点内网 IP，不需要配 hosts 就能访问:\nNODE=\u0026#34;10.200.16.79\u0026#34; 创建 systemd 配置 kubelet.service:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/kubelet.service [Unit] Description=Kubernetes Kubelet Documentation=https://github.com/kubernetes/kubernetes After=containerd.service Requires=containerd.service [Service] ExecStart=/usr/local/bin/kubelet \\\\ --config=/var/lib/kubelet/config.yaml \\\\ --container-runtime=remote \\\\ --container-runtime-endpoint=unix:///var/run/containerd/containerd.sock \\\\ --image-pull-progress-deadline=2m \\\\ --bootstrap-kubeconfig=/var/lib/kubelet/bootstrap-kubeconfig \\\\ --kubeconfig=/var/lib/kubelet/kubeconfig \\\\ --network-plugin=cni \\\\ --register-node=true \\\\ --hostname-override=${NODE} \\\\ --v=2 Restart=on-failure RestartSec=5 [Install] WantedBy=multi-user.target EOF 启动 sudo systemctl daemon-reload sudo systemctl enable containerd kubelet sudo systemctl start containerd kubelet 验证 配置好 kubectl，执行下 kubectl:\n$ kubectl get node NAME STATUS ROLES AGE VERSION 10.200.16.79 NotReady \u0026lt;none\u0026gt; 11m v1.16.1 没有装网络插件，节点状态会是 NotReady，带 node.kubernetes.io/not-ready:NoSchedule 这个污点，默认是无法调度普通 Pod，这个是正常的。后面会装网络插件，通常以 Daemonset 部署，使用 hostNetwork，并且容忍这个污点。\n签发 kubelet server 证书 由于之前做过 RBAC 授权 kubelet 创建 CSR 与自动签发和更新证书，kubelet 启动时可以发起 client 与 server 证书的 CSR 请求，并自动审批通过 client 证书的 CSR 请求，kube-controller-manager 在自动执行证书签发，最后 kubelet 可以获取到 client 证书并加入集群，我们可以在 /var/lib/kubelet/pki 下面看到签发出来的 client 证书:\nls -l /var/lib/kubelet/pki total 4 -rw------- 1 root root 1277 Oct 10 20:46 kubelet-client-2019-10-10-20-46-23.pem lrwxrwxrwx 1 root root 59 Oct 10 20:46 kubelet-client-current.pem -\u0026gt; /var/lib/kubelet/pki/kubelet-client-2019-10-10-20-46-23.pem  kubeconfig 中引用这里的 kubelet-client-current.pem 这个证书，是一个指向证书 bundle 的软连接，包含证书公钥与私钥\n 但 server 证书默认无法自动审批，需要管理员人工审批，下面是审批方法，首先看下未审批的 CSR:\n$ kubectl get csr NAME AGE REQUESTOR CONDITION csr-6gkn6 2m4s system:bootstrap:360483 Approved,Issued csr-vf285 103s system:node:10.200.17.6 Pending  可以看到 system:bootstrap 开头的用户的 CSR 请求已经自动 approve 并签发证书了，这就是因为 kubelet 使用 bootstrap token 认证后在 system:bootstrappers 用户组，而我们创建了对应 RBAC 为此用户组授权自动 approve CSR 的权限。下面 system:node 开头的用户的 CSR 请求状态是 Pending，需要管理员来 approve。\n $ kubectl certificate approve csr-vf285 certificatesigningrequest.certificates.k8s.io/csr-vf285 approved $ ls -l /var/lib/kubelet/pki total 8 -rw------- 1 root root 1277 Oct 10 20:46 kubelet-client-2019-10-10-20-46-23.pem lrwxrwxrwx 1 root root 59 Oct 10 20:46 kubelet-client-current.pem -\u0026gt; /var/lib/kubelet/pki/kubelet-client-2019-10-10-20-46-23.pem -rw------- 1 root root 1301 Oct 10 21:09 kubelet-server-2019-10-10-21-09-15.pem lrwxrwxrwx 1 root root 59 Oct 10 21:09 kubelet-server-current.pem -\u0026gt; /var/lib/kubelet/pki/kubelet-server-2019-10-10-21-09-15.pem  和 client 证书一样，kubelet-server-current.pem 也是一个指向证书 bundle 的软连接，包含证书公钥与私钥，用与 kubelet 监听 10250 端口\n "
},
{
	"uri": "https://k8s.imroc.io/deploy/manual/deploy-critical-addons/",
	"title": "部署关键组件",
	"tags": [],
	"description": "",
	"content": "部署 kube-proxy kube-proxy 会请求 apiserver 获取 Service 及其 Endpoint，将 Service 的 ClUSTER IP 与对应 Endpoint 的 Pod IP 映射关系转换成 iptables 或 ipvs 规则写到节点上，实现 Service 转发。\n部署方法参考 以 Daemonset 方式部署 kube-proxy\n部署网络插件 参考 部署 Flannel\n部署集群 DNS 集群 DNS 是 Kubernetes 的核心功能之一，被许多服务所依赖，用于解析集群内 Pod 的 DNS 请求，包括:\n 解析 service 名称成对应的 CLUSTER IP 解析 headless service 名称成对应 Pod IP (选取一个 endpoint 的 Pod IP 返回) 解析外部域名(代理 Pod 请求上游 DNS)  可以通过部署 kube-dns 或 CoreDNS 作为集群的必备扩展来提供命名服务，推荐使用 CoreDNS，效率更高，资源占用率更小，部署方法参考 部署 CoreDNS\n"
},
{
	"uri": "https://k8s.imroc.io/security/cert/install-cert-manger/",
	"title": "安装 cert-manager",
	"tags": [],
	"description": "",
	"content": "参考官方文档: https://docs.cert-manager.io/en/latest/getting-started/install/kubernetes.html\n介绍几种安装方式，不管是用哪种我们都先规划一下使用哪个命名空间，推荐使用 cert-manger 命名空间，如果使用其它的命名空间需要做些更改，会稍微有点麻烦，先创建好命名空间:\nkubectl create namespace cert-manager cert-manager 部署时会生成 ValidatingWebhookConfiguration 来注册 [ValidatingAdmissionWebhook])(ValidatingAdmissionWebhook) 来实现 CRD 校验，而ValidatingWebhookConfiguration 里需要写入 cert-manager 自身校验服务端的证书信息，就需要在自己命名空间创建 ClusterIssuer 和 Certificate 来自动创建证书，创建这些 CRD 资源又会被校验服务端校验，但校验服务端证书还没有创建所以校验请求无法发送到校验服务端，这就是一个鸡生蛋还是蛋生鸡的问题了，所以我们需要关闭 cert-manager 所在命名空间的 CRD 校验，通过打 label 来实现:\nkubectl label namespace cert-manager certmanager.k8s.io/disable-validation=true 使用原生 yaml 资源安装 直接执行 kubectl apply 来安装:\nkubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.11.0/cert-manager.yaml  使用 kubectl v1.15 及其以下的版本需要加上 --validate=false，否则会报错。\n 使用 Helm 安装 安装 CRD:\nkubectl apply -f https://raw.githubusercontent.com/jetstack/cert-manager/release-0.11/deploy/manifests/00-crds.yaml 添加 repo:\nhelm repo add jetstack https://charts.jetstack.io helm repo update 执行安装:\nhelm install \\  --name cert-manager \\  --namespace cert-manager \\  --version v0.11.0 \\  jetstack/cert-manager 校验是否安装成功 检查 cert-manager 相关的 pod 是否启动成功:\n$ kubectl get pods --namespace cert-manager NAME READY STATUS RESTARTS AGE cert-manager-cainjector-74bb68d67c-4vplr 1/1 Running 0 101s cert-manager-f7f8bf74d-j4hcz 1/1 Running 0 101s cert-manager-webhook-665df569b5-5p6x8 1/1 Running 0 101s "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/trick/",
	"title": "排错技巧",
	"tags": [],
	"description": "",
	"content": "  使用 Systemtap 定位疑难杂症   分析 ExitCode 定位 Pod 异常退出原因   容器内抓包定位网络问题   "
},
{
	"uri": "https://k8s.imroc.io/deploy/selection/",
	"title": "方案选型",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/deploy/",
	"title": "集群部署",
	"tags": [],
	"description": "",
	"content": "  方案选型     使用 kubespray 部署     手工部署    部署前的准备工作     部署 ETCD     部署 Master     部署 Worker 节点     部署关键组件      附加组件    以 Daemonset 方式部署 kube-proxy     部署 CoreDNS      附录    安装 kubectl      "
},
{
	"uri": "https://k8s.imroc.io/security/cert/autogenerate-certificate-with-cert-manager/",
	"title": "使用 cert-manager 自动生成证书",
	"tags": [],
	"description": "",
	"content": "确保 cert-manager 已安装，参考 安装 cert-manager\n利用 Let’s Encrypt 生成免费证书 免费证书颁发原理 Let’s Encrypt 利用 ACME 协议来校验域名是否真的属于你，校验成功后就可以自动颁发免费证书，证书有效期只有 90 天，在到期前需要再校验一次来实现续期，幸运的是 cert-manager 可以自动续期，这样就可以使用永久免费的证书了。如何校验你对这个域名属于你呢？主流的两种校验方式是 HTTP-01 和 DNS-01，下面简单介绍下校验原理:\nHTTP-01 校验原理 HTTP-01 的校验原理是给你域名指向的 HTTP 服务增加一个临时 location ，Let’s Encrypt 会发送 http 请求到 http://\u0026lt;YOUR_DOMAIN\u0026gt;/.well-known/acme-challenge/\u0026lt;TOKEN\u0026gt;，YOUR_DOMAIN 就是被校验的域名，TOKEN 是 ACME 协议的客户端负责放置的文件，在这里 ACME 客户端就是 cert-manager，它通过修改 Ingress 规则来增加这个临时校验路径并指向提供 TOKEN 的服务。Let’s Encrypt 会对比 TOKEN 是否符合预期，校验成功后就会颁发证书。此方法仅适用于给使用 Ingress 暴露流量的服务颁发证书，并且不支持泛域名证书。\nDNS-01 校验原理 DNS-01 的校验原理是利用 DNS 提供商的 API Key 拿到你的 DNS 控制权限， 在 Let’s Encrypt 为 ACME 客户端提供令牌后，ACME 客户端 (cert-manager) 将创建从该令牌和您的帐户密钥派生的 TXT 记录，并将该记录放在 _acme-challenge.\u0026lt;YOUR_DOMAIN\u0026gt;。 然后 Let’s Encrypt 将向 DNS 系统查询该记录，如果找到匹配项，就可以颁发证书。此方法不需要你的服务使用 Ingress，并且支持泛域名证书。\n创建 Issuer/ClusterIssuer 我们需要先创建一个用于签发证书的 Issuer 或 ClusterIssuer，它们唯一区别就是 Issuer 只能用来签发自己所在 namespace 下的证书，ClusterIssuer 可以签发任意 namespace 下的证书，除了名称不同之外，两者所有字段完全一致，下面给出一些示例，简单起见，我们仅以 ClusterIssuer 为例。\n创建使用 DNS-01 校验的 ClusterIssuer 假设域名是用 cloudflare 管理的，先登录 cloudflare 拿到 API Key，然后创建一个 Secret:\nkubectl -n cert-manager create secret generic cloudflare-apikey --from-literal=apikey=213807bd0fb1ca59bba24a58eac90492e6287  由于 ClusterIssuer 是 NonNamespaced 类型的资源，不在任何命名空间，它需要引用 Secret，而 Secret 必须存在某个命名空间下，所以就规定 ClusterIssuer 引用的 Secret 要与 cert-manager 在同一个命名空间下。\n 创建 DNS-01 方式校验的 ClusterIssuer:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: cert-manager.io/v1alpha2 kind: ClusterIssuer metadata: name: letsencrypt-dns01 spec: acme: # The ACME server URL server: https://acme-v02.api.letsencrypt.org/directory # Email address used for ACME registration email: roc@imroc.io # Name of a secret used to store the ACME account private key privateKeySecretRef: name: letsencrypt-dns01 solvers: - selector: {} # An empty \u0026#39;selector\u0026#39; means that this solver matches all domains dns01: # ACME DNS-01 solver configurations cloudflare: email: roc@imroc.io # A secretKeyRef to a cloudflare api key apiKeySecretRef: name: cloudflare-apikey key: apikey EOF  metadata.name: 是我们创建的签发机构的名称，后面我们创建证书的时候会引用它 acme.email: 是你自己的邮箱，证书快过期的时候会有邮件提醒，不过 cert-manager 会利用 acme 协议自动给我们重新颁发证书来续期 acme.server: 是 acme 协议的服务端，我们这里用 Let’s Encrypt，这个地址就写死成这样就行 acme.privateKeySecretRef 指示此签发机构的私钥将要存储到哪个 Secret 中，在 cert-manager 所在命名空间 solvers.dns01: 配置 DNS-01 校验方式所需的参数，最重要的是 API Key (引用提前创建好的 Secret)，不同 DNS 提供商配置不一样，具体参考官方API文档 更多字段参考 API 文档: https://docs.cert-manager.io/en/latest/reference/api-docs/index.html#clusterissuer-v1alpha2  创建使用 HTTP-01 校验的 ClusterIssuer 使用 HTTP-01 方式校验，ACME 服务端 (Let\u0026rsquo;s Encrypt) 会向客户端 (cert-manager) 提供令牌，客户端会在 web server 上特定路径上放置一个文件，该文件包含令牌以及帐户密钥的指纹。ACME 服务端会请求该路径并校验文件内容，校验成功后就会签发免费证书，更多细节参考: https://letsencrypt.org/zh-cn/docs/challenge-types/\n有个问题，ACME 服务端通过什么地址去访问 ACME 客户端的 web server 校验域名？答案是通过将被签发的证书中的域名来访问。这个机制带来的问题是:\n 不能签发泛域名证书，因为如果是泛域名，没有具体域名，ACME 服务端就不能知道该用什么地址访问 web server 去校验文件。 域名需要提前在 DNS 提供商配置好，这样 ACME 服务端通过域名请求时解析到正确 IP 才能访问成功，也就是需要提前知道你的 web server 的 IP 是什么。  cert-manager 作为 ACME 客户端，它将这个要被 ACME 服务端校验的文件通过 Ingress 来暴露，我们需要提前知道 Ingress 对外的 IP 地址是多少，这样才好配置域名。\n一些云厂商自带的 ingress controller 会给每个 Ingress 都创建一个外部地址 (通常对应一个负载均衡器)，这个时候我们需要提前创建好一个 Ingress，拿到外部 IP 并配置域名到此 IP，ACME 客户端 (cert-manager) 修改此 Ingress 的 rules，临时增加一个路径指向 cert-manager 提供的文件，ACME 服务端请求这个域名+指定路径，根据 Ingress 规则转发会返回 cert-manger 提供的这个文件，最终 ACME 服务端 (Let\u0026rsquo;s Encrypt) 校验该文件，通过后签发免费证书。\n指定 Ingress 的创建 ClusterIssuer 的示例:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: cert-manager.io/v1alpha2 kind: ClusterIssuer metadata: name: letsencrypt-http01 spec: acme: # The ACME server URL server: https://acme-v02.api.letsencrypt.org/directory # Email address used for ACME registration email: roc@imroc.io # Name of a secret used to store the ACME account private key privateKeySecretRef: name: letsencrypt-http01 solvers: - selector: {} # An empty \u0026#39;selector\u0026#39; means that this solver matches all domains http01: # ACME HTTP-01 solver configurations ingress: name: challenge EOF  solvers.http01: 配置 HTTP-01 校验方式所需的参数，ingress.name 指定提前创建好的 ingress 名称  有些自己安装的 ingress controller，所有具有相同 ingress class 的 ingress 都共用一个流量入口，通常是用 LoadBalancer 类型的 Service 暴露 ingress controller，这些具有相同 ingress class 的 ingress 的外部 IP 都是这个 Service 的外部 IP。这种情况我们创建 ClusterIssuer 时可以指定 ingress class，校验证书时，cert-manager 会直接创建新的 Ingress 资源并指定 kubernetes.io/ingress.class 这个 annotation。\n指定 ingress class 的创建 ClusterIssuer 的示例:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: cert-manager.io/v1alpha2 kind: ClusterIssuer metadata: name: letsencrypt-http01 spec: acme: # The ACME server URL server: https://acme-v02.api.letsencrypt.org/directory # Email address used for ACME registration email: roc@imroc.io # Name of a secret used to store the ACME account private key privateKeySecretRef: name: letsencrypt-http01 solvers: - selector: {} # An empty \u0026#39;selector\u0026#39; means that this solver matches all domains http01: # ACME HTTP-01 solver configurations ingress: class: nginx EOF  solvers.http01: 配置 HTTP-01 校验方式所需的参数，ingress.class 指定 ingress class 名称  创建证书 (Certificate) 有了 Issuer/ClusterIssuer，接下来我们就可以生成免费证书了，cert-manager 给我们提供了 Certificate 这个用于生成证书的自定义资源对象，它必须局限在某一个 namespace 下，证书最终会在这个 namespace 下以 Secret 的资源对象存储，假如我想在 dashboard 这个 namespace 下生成免费证书（这个 namespace 已存在)，创建一个 Certificate 资源来为我们自动生成证书，示例:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: cert-manager.io/v1alpha2 kind: Certificate metadata: name: dashboard-imroc-io namespace: kubernetes-dashboard spec: secretName: dashboard-imroc-io-tls issuerRef: name: letsencrypt-dns01 kind: ClusterIssuer dnsNames: - dashboard.imroc.io EOF  secretName: 指示证书最终存到哪个 Secret 中 issuerRef.kind: ClusterIssuer 或 Issuer，ClusterIssuer 可以被任意 namespace 的 Certificate 引用，Issuer 只能被当前 namespace 的 Certificate 引用。 issuerRef.name: 引用我们创建的 Issuer/ClusterIssuer 的名称 commonName: 对应证书的 common name 字段 dnsNames: 对应证书的 Subject Alternative Names (SANs) 字段  检查结果 创建完成等待一段时间，校验成功颁发证书后会将证书信息写入 Certificate 所在命名空间的 secretName 指定的 Secret 中，其它应用需要证书就可以直接挂载该 Secret 了。\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Generated 15s cert-manager Generated new private key Normal GenerateSelfSigned 15s cert-manager Generated temporary self signed certificate Normal OrderCreated 15s cert-manager Created Order resource \u0026#34;dashboard-imroc-io-780134401\u0026#34; Normal OrderComplete 9s cert-manager Order \u0026#34;dashboard-imroc-io-780134401\u0026#34; completed successfully Normal CertIssued 9s cert-manager Certificate issued successfully 看下我们的证书是否成功生成:\nkubectl -n dashboard get secret kubernetes-dashboard-certs -o yaml apiVersion: v1 data: ca.crt: null tls.crt: LS0***0tLQo= tls.key: LS0***0tCg== kind: Secret metadata: annotations: certmanager.k8s.io/alt-names: dashboard.imroc.io certmanager.k8s.io/certificate-name: dashboard-imroc-io certmanager.k8s.io/common-name: dashboard.imroc.io certmanager.k8s.io/ip-sans: \u0026#34;\u0026#34; certmanager.k8s.io/issuer-kind: ClusterIssuer certmanager.k8s.io/issuer-name: letsencrypt-prod creationTimestamp: 2019-09-19T13:53:55Z labels: certmanager.k8s.io/certificate-name: dashboard-imroc-io name: kubernetes-dashboard-certs namespace: dashboard resourceVersion: \u0026#34;5689447213\u0026#34; selfLink: /api/v1/namespaces/dashboard/secrets/kubernetes-dashboard-certs uid: ebfc4aec-dae4-11e9-89f7-be8690a7fdcf type: kubernetes.io/tls  tls.crt 就是颁发的证书 tls.key 是证书密钥  将 secret 挂载到需要证书的应用，通常应用也要配置下证书路径。\n"
},
{
	"uri": "https://k8s.imroc.io/deploy/kubespray/",
	"title": "使用 kubespray 部署",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/handle/",
	"title": "处理实践",
	"tags": [],
	"description": "",
	"content": "  arp_cache 溢出   inotify watch 耗尽   PID 耗尽   内存碎片化   磁盘爆满   高负载   "
},
{
	"uri": "https://k8s.imroc.io/deploy/manual/",
	"title": "手工部署",
	"tags": [],
	"description": "",
	"content": "部署详情 各组件版本:\n kubernetes 1.16.1 containerd 1.3.0 coredns v1.6.2 cni v0.8.2 flannel v0.11.0 etcd v3.4.1  特点:\n kubelet 证书自动签发并轮转 kube-proxy 以 daemonset 方式部署，无需为其手动签发管理证书 运行时没有 docker 直接使用 containerd，绕过 dockerd 的许多 bug  部署步骤  部署前的准备工作 部署 ETCD 部署 Master 部署 Worker 节点 部署关键附加组件  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/",
	"title": "排错指南",
	"tags": [],
	"description": "",
	"content": "kuernetes 问题定位手册(脑图)：https://www.processon.com/view/link/5e4662ade4b0d86ec4018e50\n目录  排错技巧    arp_cache 溢出     inotify watch 耗尽     PID 耗尽     内存碎片化     磁盘爆满     高负载      处理实践    arp_cache 溢出     inotify watch 耗尽     PID 耗尽     内存碎片化     磁盘爆满     高负载      节点排错    arp_cache: neighbor table overflow! (arp缓存溢出)     Cannot allocate memory     no space left on device     Node NotReady     soft lockup (内核软死锁)      Pod 排错    Pod Terminating 慢     Pod 一直处于 ContainerCreating 或 Waiting 状态     Pod 一直处于 Error 状态     Pod 一直处于 ImageInspectError 状态     Pod 一直处于 ImagePullBackOff 状态     Pod 一直处于 Pending 状态     Pod 一直处于 Terminating 状态     Pod 一直处于 Unknown 状态     Pod 健康检查失败     Pod 处于 CrashLoopBackOff 状态     容器进程主动退出      网络排错    DNS 解析异常     LB 健康检查失败     Service 不通     Service 无法解析     网络性能差      其它排错    APIServer 响应慢     Daemonset 没有被调度     Job 无法被删除     kubectl 执行 exec 或 logs 失败     Node 全部消失      "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/node/",
	"title": "节点排错",
	"tags": [],
	"description": "",
	"content": "本章包含各种经典报错，分析可能原因并给出相应的解决方案\n arp_cache: neighbor table overflow! (arp缓存溢出)   Cannot allocate memory   no space left on device   Node NotReady   soft lockup (内核软死锁)   "
},
{
	"uri": "https://k8s.imroc.io/avoid/",
	"title": "避坑指南",
	"tags": [],
	"description": "",
	"content": "目录  cgroup 泄露     conntrack 冲突导致丢包     tcp tw recycle 引发丢包     使用 NodeLocal DNS (缓存)     使用 oom-guard 在用户态处理 cgroup OOM     解决长连接服务扩容失效     踩坑分享    ARP 缓存爆满导致健康检查失败   DNS 5 秒延时   DNS 解析异常   kubectl edit 或者 apply 报 SchemaError   LB 压测 NodePort CPS 低   Pod 偶尔存活检查失败   Pod 访问另一个集群的 apiserver 有延时   神秘的溢出与丢包   访问 externalTrafficPolicy 为 Local 的 Service 对应 LB 有时超时   诡异的 No route to host   跨 VPC 访问 NodePort 经常超时   驱逐导致服务中断    "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/",
	"title": "Pod 排错",
	"tags": [],
	"description": "",
	"content": "本文是本书排查指南板块下问题排查章节的 Pod排错 一节，介绍 Pod 各种异常现象，可能的原因以及解决方法。\n常用命令 排查过程常用的命名如下:\n 查看 Pod 状态: kubectl get pod \u0026lt;pod-name\u0026gt; -o wide 查看 Pod 的 yaml 配置: kubectl get pod \u0026lt;pod-name\u0026gt; -o yaml 查看 Pod 事件: kubectl describe pod \u0026lt;pod-name\u0026gt; 查看容器日志: kubectl logs \u0026lt;pod-name\u0026gt; [-c \u0026lt;container-name\u0026gt;]  Pod 状态 Pod 有多种状态，这里罗列一下:\n Error: Pod 启动过程中发生错误 NodeLost: Pod 所在节点失联 Unkown: Pod 所在节点失联或其它未知异常 Waiting: Pod 等待启动 Pending: Pod 等待被调度 ContainerCreating: Pod 容器正在被创建 Terminating: Pod 正在被销毁 CrashLoopBackOff： 容器退出，kubelet 正在将它重启 InvalidImageName： 无法解析镜像名称 ImageInspectError： 无法校验镜像 ErrImageNeverPull： 策略禁止拉取镜像 ImagePullBackOff： 正在重试拉取 RegistryUnavailable： 连接不到镜像中心 ErrImagePull： 通用的拉取镜像出错 CreateContainerConfigError： 不能创建 kubelet 使用的容器配置 CreateContainerError： 创建容器失败 RunContainerError： 启动容器失败 PreStartHookError: 执行 preStart hook 报错 PostStartHookError： 执行 postStart hook 报错 ContainersNotInitialized： 容器没有初始化完毕 ContainersNotReady： 容器没有准备完毕 ContainerCreating：容器创建中 PodInitializing：pod 初始化中 DockerDaemonNotReady：docker还没有完全启动 NetworkPluginNotReady： 网络插件还没有完全启动  问题导航 有时候我们无法直接通过异常状态找到异常原因，这里我们罗列一下各种现象，点击即可进入相应的文章，帮助你分析问题，罗列各种可能的原因，进一步定位根因:\n Pod Terminating 慢   Pod 一直处于 ContainerCreating 或 Waiting 状态   Pod 一直处于 Error 状态   Pod 一直处于 ImageInspectError 状态   Pod 一直处于 ImagePullBackOff 状态   Pod 一直处于 Pending 状态   Pod 一直处于 Terminating 状态   Pod 一直处于 Unknown 状态   Pod 健康检查失败   Pod 处于 CrashLoopBackOff 状态   容器进程主动退出   "
},
{
	"uri": "https://k8s.imroc.io/deploy/addons/",
	"title": "附加组件",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/optimization/",
	"title": "集群优化",
	"tags": [],
	"description": "",
	"content": "kuernetes 问题定位手册(脑图)：https://www.processon.com/view/link/5e4662ade4b0d86ec4018e50\n目录  应用部署优化    使用 PodDisruptionBudget 避免驱逐导致服务不可用     使用 preStopHook 和 readinessProbe 保证服务平滑更新不中断     使用反亲和性避免单点故障      ETCD 优化     Master 优化     内核参数优化     "
},
{
	"uri": "https://k8s.imroc.io/security/",
	"title": "集群安全",
	"tags": [],
	"description": "",
	"content": "目录  用户管理    利用 CSR API 创建用户      集群权限控制    控制应用权限     控制用户权限      集群证书管理    安装 cert-manager     使用 cert-manager 自动生成证书      "
},
{
	"uri": "https://k8s.imroc.io/trick/",
	"title": "实用技巧",
	"tags": [],
	"description": "",
	"content": "  kubectl 高效技巧   yaml 片段   实用命令与脚本   "
},
{
	"uri": "https://k8s.imroc.io/monitoring/",
	"title": "监控告警",
	"tags": [],
	"description": "",
	"content": " 干货还在路上\u0026hellip;\n "
},
{
	"uri": "https://k8s.imroc.io/log/",
	"title": "日志搜集",
	"tags": [],
	"description": "",
	"content": " 干货还在路上\u0026hellip;\n "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/network/",
	"title": "网络排错",
	"tags": [],
	"description": "",
	"content": "  DNS 解析异常   LB 健康检查失败   Service 不通   Service 无法解析   网络性能差   "
},
{
	"uri": "https://k8s.imroc.io/ai-and-big-data/",
	"title": "AI 与大数据",
	"tags": [],
	"description": "",
	"content": "目录  Flink on Kubernetes   "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/others/",
	"title": "其它排错",
	"tags": [],
	"description": "",
	"content": "  APIServer 响应慢   Daemonset 没有被调度   Job 无法被删除   kubectl 执行 exec 或 logs 失败   Node 全部消失   "
},
{
	"uri": "https://k8s.imroc.io/dev/",
	"title": "开发指南",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/others/slow-apiserver/",
	"title": "APIServer 响应慢",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/arp-cache-overflow-causes-healthcheck-failed/",
	"title": "ARP 缓存爆满导致健康检查失败",
	"tags": [],
	"description": "",
	"content": "案例 TKE 一用户某集群节点数 1200+，用户监控方案是 daemonset 部署 node-exporter 暴露节点监控指标，使用 hostNework 方式，statefulset 部署 promethues 且仅有一个实例，落在了一个节点上，promethues 请求所有节点 node-exporter 获取节点监控指标，也就是或扫描所有节点，导致 arp cache 需要存所有 node 的记录，而节点数 1200+，大于了 net.ipv4.neigh.default.gc_thresh3 的默认值 1024，这个值是个硬限制，arp cache记录数大于这个就会强制触发 gc，所以会造成频繁gc，当有数据包发送会查本地 arp，如果本地没找到 arp 记录就会判断当前 arp cache 记录数+1是否大于 gc_thresh3，如果没有就会广播 arp 查询 mac 地址，如果大于了就直接报 arp_cache: neighbor table overflow!，并且放弃 arp 请求，无法获取 mac 地址也就无法知道探测报文该往哪儿发(即便就在本机某个 veth pair)，kubelet 对本机 pod 做存活检查发 arp 查 mac 地址，在 arp cahce 找不到，由于这时 arp cache已经满了，刚要 gc 但还没做所以就只有报错丢包，导致存活检查失败重启 pod\n解决方案 调整部分节点内核参数，将 arp cache 的 gc 阀值调高 (/etc/sysctl.conf):\nnet.ipv4.neigh.default.gc_thresh1 = 80000 net.ipv4.neigh.default.gc_thresh2 = 90000 net.ipv4.neigh.default.gc_thresh3 = 100000 并给 node 打下label，修改 pod spec，加下 nodeSelector 或者 nodeAffnity，让 pod 只调度到这部分改过内核参数的节点，更多请参考本书 处理实践: arp_cache 溢出\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/handle/arp_cache-overflow/",
	"title": "arp_cache 溢出",
	"tags": [],
	"description": "",
	"content": "如何判断 arp_cache 溢出？ 内核日志会有有下面的报错:\narp_cache: neighbor table overflow! 查看当前 arp 记录数:\n$ arp -an | wc -l 1335 查看 arp gc 阀值:\n$ sysctl -a | grep gc_thresh net.ipv4.neigh.default.gc_thresh1 = 128 net.ipv4.neigh.default.gc_thresh2 = 512 net.ipv4.neigh.default.gc_thresh3 = 1024 net.ipv6.neigh.default.gc_thresh1 = 128 net.ipv6.neigh.default.gc_thresh2 = 512 net.ipv6.neigh.default.gc_thresh3 = 1024 当前 arp 记录数接近 gc_thresh3 比较容易 overflow，因为当 arp 记录达到 gc_thresh3 时会强制触发 gc 清理，当这时又有数据包要发送，并且根据目的 IP 在 arp cache 中没找到 mac 地址，这时会判断当前 arp cache 记录数加 1 是否大于 gc_thresh3，如果没有大于就会 时就会报错: arp_cache: neighbor table overflow!\n解决方案 调整节点内核参数，将 arp cache 的 gc 阀值调高 (/etc/sysctl.conf):\nnet.ipv4.neigh.default.gc_thresh1 = 80000 net.ipv4.neigh.default.gc_thresh2 = 90000 net.ipv4.neigh.default.gc_thresh3 = 100000 分析是否只是部分业务的 Pod 的使用场景需要节点有比较大的 arp 缓存空间。\n如果不是，就需要调整所有节点内核参数。\n如果是，可以将部分 Node 打上标签，比如:\nkubectl label node host1 arp_cache=large 然后用 nodeSelector 或 nodeAffnity 让这部分需要内核有大 arp_cache 容量的 Pod 只调度到这部分节点，推荐使用 nodeAffnity，yaml 示例:\ntemplate: spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: arp_cache operator: In values: - large "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/node/arp_cache-neighbor-table-overflow/",
	"title": "arp_cache: neighbor table overflow! (arp缓存溢出)",
	"tags": [],
	"description": "",
	"content": "节点内核报这个错说明当前节点 arp 缓存满了。\n查看当前 arp 记录数:\n$ arp -an | wc -l 1335 查看 gc 阀值:\n$ sysctl -a | grep net.ipv4.neigh.default.gc_thresh net.ipv4.neigh.default.gc_thresh1 = 128 net.ipv4.neigh.default.gc_thresh2 = 512 net.ipv4.neigh.default.gc_thresh3 = 1024 当前 arp 记录数接近 gc_thresh3 比较容易 overflow，因为当 arp 记录达到 gc_thresh3 时会强制触发 gc 清理，当这时又有数据包要发送，并且根据目的 IP 在 arp cache 中没找到 mac 地址，这时会判断当前 arp cache 记录数加 1 是否大于 gc_thresh3，如果没有大于就会 时就会报错: neighbor table overflow!\n什么场景下会发生 集群规模大，node 和 pod 数量超多，参考本书避坑宝典的 案例分享: ARP 缓存爆满导致健康检查失败\n解决方案 调整部分节点内核参数，将 arp cache 的 gc 阀值调高 (/etc/sysctl.conf):\nnet.ipv4.neigh.default.gc_thresh1 = 80000 net.ipv4.neigh.default.gc_thresh2 = 90000 net.ipv4.neigh.default.gc_thresh3 = 100000 并给 node 打下label，修改 pod spec，加下 nodeSelector 或者 nodeAffnity，让 pod 只调度到这部分改过内核参数的节点\n参考资料  Scaling Kubernetes to 2,500 Nodes: https://openai.com/blog/scaling-kubernetes-to-2500-nodes/  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/node/cannot-allocate-memory/",
	"title": "Cannot allocate memory",
	"tags": [],
	"description": "",
	"content": "容器启动失败，报错 Cannot allocate memory。\nPID 耗尽 如果登录 ssh 困难，并且登录成功后执行任意命名经常报 Cannot allocate memory，多半是 PID 耗尽了。\n处理方法参考本书 处理实践: PID 耗尽\n"
},
{
	"uri": "https://k8s.imroc.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/avoid/cgroup-leaking/",
	"title": "cgroup 泄露",
	"tags": [],
	"description": "",
	"content": "内核 Bug memcg 是 Linux 内核中用于管理 cgroup 内存的模块，整个生命周期应该是跟随 cgroup 的，但是在低版本内核中(已知3.10)，一旦给某个 memory cgroup 开启 kmem accounting 中的 memory.kmem.limit_in_bytes 就可能会导致不能彻底删除 memcg 和对应的 cssid，也就是说应用即使已经删除了 cgroup (/sys/fs/cgroup/memory 下对应的 cgroup 目录已经删除), 但在内核中没有释放 cssid，导致内核认为的 cgroup 的数量实际数量不一致，我们也无法得知内核认为的 cgroup 数量是多少。\n关于 cgroup kernel memory，在 kernel.org 中有如下描述：\n2.7 Kernel Memory Extension (CONFIG_MEMCG_KMEM) ----------------------------------------------- With the Kernel memory extension, the Memory Controller is able to limit the amount of kernel memory used by the system. Kernel memory is fundamentally different than user memory, since it can't be swapped out, which makes it possible to DoS the system by consuming too much of this precious resource. Kernel memory accounting is enabled for all memory cgroups by default. But it can be disabled system-wide by passing cgroup.memory=nokmem to the kernel at boot time. In this case, kernel memory will not be accounted at all. Kernel memory limits are not imposed for the root cgroup. Usage for the root cgroup may or may not be accounted. The memory used is accumulated into memory.kmem.usage_in_bytes, or in a separate counter when it makes sense. (currently only for tcp). The main \u0026quot;kmem\u0026quot; counter is fed into the main counter, so kmem charges will also be visible from the user counter. Currently no soft limit is implemented for kernel memory. It is future work to trigger slab reclaim when those limits are reached. 这是一个 cgroup memory 的扩展，用于限制对 kernel memory 的使用，但该特性在老于 4.0 版本中是个实验特性，存在泄露问题，在 4.x 较低的版本也还有泄露问题，应该是造成泄露的代码路径没有完全修复，推荐 4.3 以上的内核。\n造成容器创建失败 这个问题可能会导致创建容器失败，因为创建容器为其需要创建 cgroup 来做隔离，而低版本内核有个限制：允许创建的 cgroup 最大数量写死为 65535 (点我跳转到 commit)，如果节点上经常创建和销毁大量容器导致创建很多 cgroup，删除容器但没有彻底删除 cgroup 造成泄露(真实数量我们无法得知)，到达 65535 后再创建容器就会报创建 cgroup 失败并报错 no space left on device，使用 kubernetes 最直观的感受就是 pod 创建之后无法启动成功。\npod 启动失败，报 event 示例:\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 15m default-scheduler Successfully assigned jenkins/jenkins-7845b9b665-nrvks to 10.10.252.4 Warning FailedCreatePodContainer 25s (x70 over 15m) kubelet, 10.10.252.4 unable to ensure pod container exists: failed to create container for [kubepods besteffort podc6eeec88-8664-11e9-9524-5254007057ba] : mkdir /sys/fs/cgroup/memory/kubepods/besteffort/podc6eeec88-8664-11e9-9524-5254007057ba: no space left on device dockerd 日志报错示例:\nDec 24 11:54:31 VM_16_11_centos dockerd[11419]: time=\u0026#34;2018-12-24T11:54:31.195900301+08:00\u0026#34; level=error msg=\u0026#34;Handler for POST /v1.31/containers/b98d4aea818bf9d1d1aa84079e1688cd9b4218e008c58a8ef6d6c3c106403e7b/start returned error: OCI runtime create failed: container_linux.go:348: starting container process caused \\\u0026#34;process_linux.go:279: applying cgroup configuration for process caused \\\\\\\u0026#34;mkdir /sys/fs/cgroup/memory/kubepods/burstable/pod79fe803c-072f-11e9-90ca-525400090c71/b98d4aea818bf9d1d1aa84079e1688cd9b4218e008c58a8ef6d6c3c106403e7b: no space left on device\\\\\\\u0026#34;\\\u0026#34;: unknown\u0026#34; kubelet 日志报错示例:\nSep 09 18:09:09 VM-0-39-ubuntu kubelet[18902]: I0909 18:09:09.449722 18902 remote_runtime.go:92] RunPodSandbox from runtime service failed: rpc error: code = Unknown desc = failed to start sandbox container for pod \u0026#34;osp-xxx-com-ljqm19-54bf7678b8-bvz9s\u0026#34;: Error response from daemon: oci runtime error: container_linux.go:247: starting container process caused \u0026#34;process_linux.go:258: applying cgroup configuration for process caused \\\u0026#34;mkdir /sys/fs/cgroup/memory/kubepods/burstable/podf1bd9e87-1ef2-11e8-afd3-fa163ecf2dce/8710c146b3c8b52f5da62e222273703b1e3d54a6a6270a0ea7ce1b194f1b5053: no space left on device\\\u0026#34;\u0026#34; 新版的内核限制为 2^31 (可以看成几乎不限制，点我跳转到代码): cgroup_idr_alloc() 传入 end 为 0 到 idr_alloc()， 再传给 idr_alloc_u32(), end 的值最终被三元运算符 end\u0026gt;0 ? end-1 : INT_MAX 转成了 INT_MAX 常量，即 2^31。所以如果新版内核有泄露问题会更难定位，表现形式会是内存消耗严重，幸运的是新版内核已经修复，推荐 4.3 以上。\n规避方案 如果你用的低版本内核(比如 CentOS 7 v3.10 的内核)并且不方便升级内核，可以通过不开启 kmem accounting 来实现规避，但会比较麻烦。\nkubelet 和 runc 都会给 memory cgroup 开启 kmem accounting，所以要规避这个问题，就要保证kubelet 和 runc 都别开启 kmem accounting，下面分别进行说明:\nrunc runc 在合并 这个PR (2017-02-27) 之后创建的容器都默认开启了 kmem accounting，后来社区也注意到这个问题，并做了比较灵活的修复， PR 1921 给 runc 增加了 \u0026ldquo;nokmem\u0026rdquo; 编译选项，缺省的 release 版本没有使用这个选项， 自己使用 nokmem 选项编译 runc 的方法:\ncd $GO_PATH/src/github.com/opencontainers/runc/ make BUILDTAGS=\u0026#34;seccomp nokmem\u0026#34; docker-ce v18.09.1 之后的 runc 默认关闭了 kmem accounting，所以也可以直接升级 docker 到这个版本之后。\nkubelet 如果是 1.14 版本及其以上，可以在编译的时候通过 build tag 来关闭 kmem accounting:\nKUBE_GIT_VERSION=v1.14.1 ./build/run.sh make kubelet GOFLAGS=\u0026#34;-tags=nokmem\u0026#34; 如果是低版本需要修改代码重新编译。kubelet 在创建 pod 对应的 cgroup 目录时，也会调用 libcontianer 中的代码对 cgroup 做设置，在 pkg/kubelet/cm/cgroup_manager_linux.go 的 Create 方法中，会调用 Manager.Apply 方法，最终调用 vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/memory.go 中的 MemoryGroup.Apply 方法，开启 kmem accounting。这里也需要进行处理，可以将这部分代码注释掉然后重新编译 kubelet。\n参考资料  一行 kubernetes 1.9 代码引发的血案（与 CentOS 7.x 内核兼容性问题）: http://dockone.io/article/4797 Cgroup泄漏\u0026ndash;潜藏在你的集群中: https://tencentcloudcontainerteam.github.io/2018/12/29/cgroup-leaking/  "
},
{
	"uri": "https://k8s.imroc.io/avoid/conntrack-conflict/",
	"title": "conntrack 冲突导致丢包",
	"tags": [],
	"description": "",
	"content": "TODO\n"
},
{
	"uri": "https://k8s.imroc.io/cluster/runtime/containerd/",
	"title": "Containerd",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/others/daemonset-not-scheduled/",
	"title": "Daemonset 没有被调度",
	"tags": [],
	"description": "",
	"content": "Daemonset 的期望实例为 0，可能原因:\n controller-manager 的 bug，重启 controller-manager 可以恢复 controller-manager 挂了  "
},
{
	"uri": "https://k8s.imroc.io/trick/yaml/deployment/",
	"title": "Deployment",
	"tags": [],
	"description": "",
	"content": "最简单的 nginx 测试服务 apiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx --- apiVersion: v1 kind: Service metadata: name: nginx labels: app: nginx spec: type: ClusterIP ports: - port: 80 protocol: TCP name: http selector: app: nginx "
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/dns-lookup-5s-delay/",
	"title": "DNS 5 秒延时",
	"tags": [],
	"description": "",
	"content": "延时现象 客户反馈从 pod 中访问服务时，总是有些请求的响应时延会达到5秒。正常的响应只需要毫秒级别的时延。\n抓包  通过 nsenter 进入 pod netns，使用节点上的 tcpdump 抓 pod 中的包 (抓包方法参考这里)，发现是有的 DNS 请求没有收到响应，超时 5 秒后，再次发送 DNS 请求才成功收到响应。 在 kube-dns pod 抓包，发现是有 DNS 请求没有到达 kube-dns pod，在中途被丢弃了。  为什么是 5 秒？ man resolv.conf 可以看到 glibc 的 resolver 的缺省超时时间是 5s:\ntimeout:n Sets the amount of time the resolver will wait for a response from a remote name server before retrying the query via a different name server. Measured in seconds, the default is RES_TIMEOUT (currently 5, see \u0026lt;resolv.h\u0026gt;). The value for this option is silently capped to 30. 丢包原因 经过搜索发现这是一个普遍问题。\n根本原因是内核 conntrack 模块的 bug，netfilter 做 NAT 时可能发生资源竞争导致部分报文丢弃。\nWeave works的工程师 Martynas Pumputis 对这个问题做了很详细的分析：Racy conntrack and DNS lookup timeouts\n相关结论：\n 只有多个线程或进程，并发从同一个 socket 发送相同五元组的 UDP 报文时，才有一定概率会发生 glibc, musl(alpine linux的libc库)都使用 \u0026ldquo;parallel query\u0026rdquo;, 就是并发发出多个查询请求，因此很容易碰到这样的冲突，造成查询请求被丢弃 由于 ipvs 也使用了 conntrack, 使用 kube-proxy 的 ipvs 模式，并不能避免这个问题  问题的根本解决 Martynas 向内核提交了两个 patch 来 fix 这个问题，不过他说如果集群中有多个DNS server的情况下，问题并没有完全解决。\n其中一个 patch 已经在 2018-7-18 被合并到 linux 内核主线中: netfilter: nf_conntrack: resolve clash for matching conntracks\n目前只有4.19.rc 版本包含这个patch。\n规避办法 规避方案一：使用TCP发送DNS请求 由于TCP没有这个问题，有人提出可以在容器的resolv.conf中增加options use-vc, 强制glibc使用TCP协议发送DNS query。下面是这个man resolv.conf中关于这个选项的说明：\nuse-vc (since glibc 2.14) Sets RES_USEVC in _res.options. This option forces the use of TCP for DNS resolutions. 笔者使用镜像\u0026quot;busybox:1.29.3-glibc\u0026rdquo; (libc 2.24) 做了试验，并没有见到这样的效果，容器仍然是通过UDP发送DNS请求。\n规避方案二：避免相同五元组DNS请求的并发 resolv.conf还有另外两个相关的参数：\n single-request-reopen (since glibc 2.9) single-request (since glibc 2.10)  man resolv.conf中解释如下：\nsingle-request-reopen (since glibc 2.9) Sets RES_SNGLKUPREOP in _res.options. The resolver uses the same socket for the A and AAAA requests. Some hardware mistakenly sends back only one reply. When that happens the client system will sit and wait for the second reply. Turning this option on changes this behavior so that if two requests from the same port are not handled correctly it will close the socket and open a new one before sending the second request. single-request (since glibc 2.10) Sets RES_SNGLKUP in _res.options. By default, glibc performs IPv4 and IPv6 lookups in parallel since version 2.9. Some appliance DNS servers cannot handle these queries properly and make the requests time out. This option disables the behavior and makes glibc perform the IPv6 and IPv4 requests sequentially (at the cost of some slowdown of the resolving process). 用自己的话解释下：\n single-request-reopen: 发送 A 类型请求和 AAAA 类型请求使用不同的源端口，这样两个请求在 conntrack 表中不占用同一个表项，从而避免冲突 single-request: 避免并发，改为串行发送 A 类型和 AAAA 类型请求，没有了并发，从而也避免了冲突  要给容器的 resolv.conf 加上 options 参数，有几个办法：\n1) 在容器的 \u0026ldquo;ENTRYPOINT\u0026rdquo; 或者 \u0026ldquo;CMD\u0026rdquo; 脚本中，执行 /bin/echo \u0026lsquo;options single-request-reopen\u0026rsquo; \u0026gt;\u0026gt; /etc/resolv.conf\n2) 在 pod 的 postStart hook 中:\nlifecycle: postStart: exec: command: - /bin/sh - -c - \u0026#34;/bin/echo \u0026#39;options single-request-reopen\u0026#39; \u0026gt;\u0026gt; /etc/resolv.conf\u0026#34; 3) 使用 template.spec.dnsConfig (k8s v1.9 及以上才支持):\ntemplate: spec: dnsConfig: options: - name: single-request-reopen 4) 使用 ConfigMap 覆盖 pod 里面的 /etc/resolv.conf:\nconfigmap:\napiVersion: v1 data: resolv.conf: | nameserver 1.2.3.4 search default.svc.cluster.local svc.cluster.local cluster.local ec2.internal options ndots:5 single-request-reopen timeout:1 kind: ConfigMap metadata: name: resolvconf pod spec:\nvolumeMounts: - name: resolv-conf mountPath: /etc/resolv.conf subPath: resolv.conf ... volumes: - name: resolv-conf configMap: name: resolvconf items: - key: resolv.conf path: resolv.conf 5) 使用 MutatingAdmissionWebhook\nMutatingAdmissionWebhook 是 1.9 引入的 Controller，用于对一个指定的 Resource 的操作之前，对这个 resource 进行变更。 istio 的自动 sidecar注入就是用这个功能来实现的。 我们也可以通过 MutatingAdmissionWebhook，来自动给所有POD，注入以上3)或者4)所需要的相关内容。\n以上方法中， 1)和2)都需要修改镜像， 3)和4)则只需要修改POD的spec， 能适用于所有镜像。不过还是有不方便的地方：\n 每个工作负载的yaml都要做修改，比较麻烦 对于通过helm创建的工作负载，需要修改helm charts  方法5)对集群使用者最省事，照常提交工作负载即可。不过初期需要一定的开发工作量。\n规避方案三：使用本地DNS缓存 容器的DNS请求都发往本地的DNS缓存服务(dnsmasq, nscd等)，不需要走DNAT，也不会发生conntrack冲突。另外还有个好处，就是避免DNS服务成为性能瓶颈。\n使用本地DNS缓存有两种方式：\n 每个容器自带一个DNS缓存服务 每个节点运行一个DNS缓存服务，所有容器都把本节点的DNS缓存作为自己的 nameserver  从资源效率的角度来考虑的话，推荐后一种方式。官方也意识到了这个问题比较常见，给出了 coredns 以 cache 模式作为 daemonset 部署的解决方案: https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/\n实施办法 条条大路通罗马，不管怎么做，最终到达上面描述的效果即可。\nPOD中要访问节点上的DNS缓存服务，可以使用节点的IP。 如果节点上的容器都连在一个虚拟bridge上， 也可以使用这个bridge的三层接口的IP(在TKE中，这个三层接口叫cbr0)。 要确保DNS缓存服务监听这个地址。\n如何把POD的/etc/resolv.conf中的nameserver设置为节点IP呢？\n一个办法，是设置 POD.spec.dnsPolicy 为 \u0026ldquo;Default\u0026rdquo;， 意思是POD里面的 /etc/resolv.conf， 使用节点上的文件。缺省使用节点上的 /etc/resolv.conf(如果kubelet通过参数\u0026ndash;resolv-conf指定了其他文件，则使用\u0026ndash;resolv-conf所指定的文件)。\n另一个办法，是给每个节点的kubelet指定不同的\u0026ndash;cluster-dns参数，设置为节点的IP，POD.spec.dnsPolicy仍然使用缺省值\u0026quot;ClusterFirst\u0026rdquo;。 kops项目甚至有个issue在讨论如何在部署集群时设置好\u0026ndash;cluster-dns指向节点IP: https://github.com/kubernetes/kops/issues/5584\n参考资料  Racy conntrack and DNS lookup timeouts: https://www.weave.works/blog/racy-conntrack-and-dns-lookup-timeouts 5 – 15s DNS lookups on Kubernetes? : https://blog.quentin-machu.fr/2018/06/24/5-15s-dns-lookups-on-kubernetes/ DNS intermittent delays of 5s: https://github.com/kubernetes/kubernetes/issues/56903 记一次Docker/Kubernetes上无法解释的连接超时原因探寻之旅: https://mp.weixin.qq.com/s/VYBs8iqf0HsNg9WAxktzYQ  "
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/dns-resolution-abnormal/",
	"title": "DNS 解析异常",
	"tags": [],
	"description": "",
	"content": "现象: 有个用户反馈域名解析有时有问题，看报错是解析超时。\n第一反应当然是看 coredns 的 log:\n[ERROR] 2 loginspub.xxxxmobile-inc.net. A: unreachable backend: read udp 172.16.0.230:43742-\u0026gt;10.225.30.181:53: i/o timeout 这是上游 DNS 解析异常了，因为解析外部域名 coredns 默认会请求上游 DNS 来查询，这里的上游 DNS 默认是 coredns pod 所在宿主机的 resolv.conf 里面的 nameserver (coredns pod 的 dnsPolicy 为 \u0026ldquo;Default\u0026rdquo;，也就是会将宿主机里的 resolv.conf 里的 nameserver 加到容器里的 resolv.conf, coredns 默认配置 proxy . /etc/resolv.conf, 意思是非 service 域名会使用 coredns 容器中 resolv.conf 文件里的 nameserver 来解析)\n确认了下，超时的上游 DNS 10.225.30.181 并不是期望的 nameserver，VPC 默认 DNS 应该是 180 开头的。看了 coredns 所在节点的 resolv.conf，发现确实多出了这个非期望的 nameserver，跟用户确认了下，这个 DNS 不是用户自己加上去的，添加节点时这个 nameserver 本身就在 resolv.conf 中。\n根据内部同学反馈， 10.225.30.181 是广州一台年久失修将被撤裁的 DNS，物理网络，没有 VIP，撤掉就没有了，所以如果 coredns 用到了这台 DNS 解析时就可能 timeout。后面我们自己测试，某些 VPC 的集群确实会有这个 nameserver，奇了怪了，哪里冒出来的？\n又试了下直接创建 CVM，不加进 TKE 节点发现没有这个 nameserver，只要一加进 TKE 节点就有了 !!!\n看起来是 TKE 的问题，将 CVM 添加到 TKE 集群会自动重装系统，初始化并加进集群成为 K8S 的 node，确认了初始化过程并不会写 resolv.conf，会不会是 TKE 的 OS 镜像问题？尝试搜一下除了 /etc/resolv.conf 之外哪里还有这个 nameserver 的 IP，最后发现 /etc/resolvconf/resolv.conf.d/base 这里面有。\n看下 /etc/resolvconf/resolv.conf.d/base 的作用：Ubuntu 的 /etc/resolv.conf 是动态生成的，每次重启都会将 /etc/resolvconf/resolv.conf.d/base 里面的内容加到 /etc/resolv.conf 里。\n经确认: 这个文件确实是 TKE 的 Ubuntu OS 镜像里自带的，可能发布 OS 镜像时不小心加进去的。\n那为什么有些 VPC 的集群的节点 /etc/resolv.conf 里面没那个 IP 呢？它们的 OS 镜像里也都有那个文件那个 IP 呀。\n请教其它部门同学发现:\n 非 dhcp 子机，cvm 的 cloud-init 会覆盖 /etc/resolv.conf 来设置 dns dhcp 子机，cloud-init 不会设置，而是通过 dhcp 动态下发 2018 年 4 月 之后创建的 VPC 就都是 dhcp 类型了的，比较新的 VPC 都是 dhcp 类型的  真相大白：/etc/resolv.conf 一开始内容都包含 /etc/resolvconf/resolv.conf.d/base 的内容，也就是都有那个不期望的 nameserver，但老的 VPC 由于不是 dhcp 类型，所以 cloud-init 会覆盖 /etc/resolv.conf，抹掉了不被期望的 nameserver，而新创建的 VPC 都是 dhcp 类型，cloud-init 不会覆盖 /etc/resolv.conf，导致不被期望的 nameserver 残留在了 /etc/resolv.conf，而 coredns pod 的 dnsPolicy 为 “Default”，也就是会将宿主机的 /etc/resolv.conf 中的 nameserver 加到容器里，coredns 解析集群外的域名默认使用这些 nameserver 来解析，当用到那个将被撤裁的 nameserver 就可能 timeout。\n临时解决: 删掉 /etc/resolvconf/resolv.conf.d/base 重启\n长期解决: 我们重新制作 TKE Ubuntu OS 镜像然后发布更新\n这下应该没问题了吧，But, 用户反馈还是会偶尔解析有问题，但现象不一样了，这次并不是 dns timeout。\n用脚本跑测试仔细分析现象:\n 请求 loginspub.xxxxmobile-inc.net 时，偶尔提示域名无法解析 请求 accounts.google.com 时，偶尔提示连接失败  进入 dns 解析偶尔异常的容器的 netns 抓包:\n dns 请求会并发请求 A 和 AAAA 记录 测试脚本发请求打印序号，抓包然后 wireshark 分析对比异常时请求序号偏移量，找到异常时的 dns 请求报文，发现异常时 A 和 AAAA 记录的请求 id 冲突，并且 AAAA 响应先返回  正常情况下id不会冲突，这里冲突了也就能解释这个 dns 解析异常的现象了:\n loginspub.xxxxmobile-inc.net 没有 AAAA (ipv6) 记录，它的响应先返回告知 client 不存在此记录，由于请求 id 跟 A 记录请求冲突，后面 A 记录响应返回了 client 发现 id 重复就忽略了，然后认为这个域名无法解析 accounts.google.com 有 AAAA 记录，响应先返回了，client 就拿这个记录去尝试请求，但当前容器环境不支持 ipv6，所以会连接失败  那为什么 dns 请求 id 会冲突?\n继续观察发现: 其它节点上的 pod 不会复现这个问题，有问题这个节点上也不是所有 pod 都有这个问题，只有基于 alpine 镜像的容器才有这个问题，在此节点新起一个测试的 alpine:latest 的容器也一样有这个问题。\n为什么 alpine 镜像的容器在这个节点上有问题在其它节点上没问题？ 为什么其他镜像的容器都没问题？它们跟 alpine 的区别是什么？\n发现一点区别: alpine 使用的底层 c 库是 musl libc，其它镜像基本都是 glibc\n翻 musl libc 源码, 构造 dns 请求时，请求 id 的生成没加锁，而且跟当前时间戳有关 (network/res_mkquery.c):\n/* Make a reasonably unpredictable id */ clock_gettime(CLOCK_REALTIME, \u0026amp;ts); id = ts.tv_nsec + ts.tv_nsec/65536UL \u0026amp; 0xffff; 看注释，作者应该认为这样id基本不会冲突，事实证明，绝大多数情况确实不会冲突，我在网上搜了很久没有搜到任何关于 musl libc 的 dns 请求 id 冲突的情况。这个看起来取决于硬件，可能在某种类型硬件的机器上运行，短时间内生成的 id 就可能冲突。我尝试跟用户在相同地域的集群，添加相同配置相同机型的节点，也复现了这个问题，但后来删除再添加时又不能复现了，看起来后面新建的 cvm 又跑在了另一种硬件的母机上了。\nOK，能解释通了，再底层的细节就不清楚了，我们来看下解决方案:\n 换基础镜像 (不用alpine) 完全静态编译业务程序(不依赖底层c库)，比如go语言程序编译时可以关闭 cgo (CGO_ENABLED=0)，并告诉链接器要静态链接 (go build 后面加 -ldflags '-d')，但这需要语言和编译工具支持才可以  最终建议用户基础镜像换成另一个比较小的镜像: debian:stretch-slim。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/network/dns/",
	"title": "DNS 解析异常",
	"tags": [],
	"description": "",
	"content": "5 秒延时 如果DNS查询经常延时5秒才返回，通常是遇到内核 conntrack 冲突导致的丢包，详见 案例分享: DNS 5秒延时\n解析超时 如果容器内报 DNS 解析超时，先检查下集群 DNS 服务 (kube-dns/coredns) 的 Pod 是否 Ready，如果不是，请参考本章其它小节定位原因。如果运行正常，再具体看下超时现象。\n解析外部域名超时 可能原因:\n 上游 DNS 故障 上游 DNS 的 ACL 或防火墙拦截了报文  所有解析都超时 如果集群内某个 Pod 不管解析 Service 还是外部域名都失败，通常是 Pod 与集群 DNS 之间通信有问题。\n可能原因:\n 节点防火墙没放开集群网段，导致如果 Pod 跟集群 DNS 的 Pod 不在同一个节点就无法通信，DNS 请求也就无法被收到  "
},
{
	"uri": "https://k8s.imroc.io/optimization/etcd/",
	"title": "ETCD 优化",
	"tags": [],
	"description": "",
	"content": "高可用部署 部署一个高可用ETCD集群可以参考官方文档: https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/clustering.md\n 如果是 self-host 方式部署的集群，可以用 etcd-operator 部署 etcd 集群；也可以使用另一个小集群专门部署 etcd (使用 etcd-operator)\n 提高磁盘 IO 性能 ETCD 对磁盘写入延迟非常敏感，对于负载较重的集群建议磁盘使用 SSD 固态硬盘。可以使用 diskbench 或 fio 测量磁盘实际顺序 IOPS。\n提高 ETCD 的磁盘 IO 优先级 由于 ETCD 必须将数据持久保存到磁盘日志文件中，因此来自其他进程的磁盘活动可能会导致增加写入时间，结果导致 ETCD 请求超时和临时 leader 丢失。当给定高磁盘优先级时，ETCD 服务可以稳定地与这些进程一起运行:\nsudo ionice -c2 -n0 -p $(pgrep etcd) 提高存储配额 默认 ETCD 空间配额大小为 2G，超过 2G 将不再写入数据。通过给 ETCD 配置 --quota-backend-bytes 参数增大空间配额，最大支持 8G。\n分离 events 存储 集群规模大的情况下，集群中包含大量节点和服务，会产生大量的 event，这些 event 将会对 etcd 造成巨大压力并占用大量 etcd 存储空间，为了在大规模集群下提高性能，可以将 events 存储在单独的 ETCD 集群中。\n配置 kube-apiserver：\n--etcd-servers=\u0026#34;http://etcd1:2379,http://etcd2:2379,http://etcd3:2379\u0026#34; --etcd-servers-overrides=\u0026#34;/events#http://etcd4:2379,http://etcd5:2379,http://etcd6:2379\u0026#34; 减小网络延迟 如果有大量并发客户端请求 ETCD leader 服务，则可能由于网络拥塞而延迟处理 follower 对等请求。在 follower 节点上的发送缓冲区错误消息：\ndropped MsgProp to 247ae21ff9436b2d since streamMsg\u0026#39;s sending buffer is full dropped MsgAppResp to 247ae21ff9436b2d since streamMsg\u0026#39;s sending buffer is full 可以通过在客户端提高 ETCD 对等网络流量优先级来解决这些错误。在 Linux 上，可以使用 tc 对对等流量进行优先级排序：\n$ tc qdisc add dev eth0 root handle 1: prio bands 3 $ tc filter add dev eth0 parent 1: protocol ip prio 1 u32 match ip sport 2380 0xffff flowid 1:1 $ tc filter add dev eth0 parent 1: protocol ip prio 1 u32 match ip dport 2380 0xffff flowid 1:1 $ tc filter add dev eth0 parent 1: protocol ip prio 2 u32 match ip sport 2379 0xffff flowid 1:1 $ tc filter add dev eth0 parent 1: protocol ip prio 2 u32 match ip dport 2379 0xffff flowid 1:1 "
},
{
	"uri": "https://k8s.imroc.io/cluster/network/flannel/",
	"title": "Flannel",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/ai-and-big-data/flink-on-kubernetes/",
	"title": "Flink on Kubernetes",
	"tags": [],
	"description": "",
	"content": "Flink 简介 Flink 是一款近年来流行的流式大数据处理框架。Storm 是流式处理框架的先锋，实时处理能做到低延迟，但很难实现高吞吐，也不能保证精确一致性(exactly-once)，即保证执行一次并且只能执行一次；后基于批处理框架 Spark 推出 Spark Streaming，将批处理数据分割的足够小，也实现了流失处理，并且可以做到高吞吐，能实现 exactly-once，但难以做到低时延，因为分割的任务之间需要有间隔时间，无法做到真实时；最后 Flink 诞生了，同时做到了低延迟、高吞吐、exactly-once，并且还支持丰富的时间类型和窗口计算。\nFlink 主要由两个部分组件构成：JobManager 和 TaskManager。如何理解这两个组件的作用？JobManager 负责资源申请和任务分发，TaskManager 负责任务的执行。跟 k8s 本身类比，JobManager 相当于 Master，TaskManager 相当于 Worker；跟 Spark 类比，JobManager 相当于 Driver，TaskManager 相当于 Executor。\n与 Kubernetes 集成 在 flink 1.10 之前，在 k8s 上运行 flink 任务都是需要事先指定 TaskManager 的个数以及CPU和内存的，存在一个问题：大多数情况下，你在任务启动前根本无法精确的预估这个任务需要多少个TaskManager，如果指定多了，会导致资源浪费，指定少了，会导致任务调度不起来。本质原因是在 Kubernetes 上运行的 Flink 任务并没有直接向 Kubernetes 集群去申请资源。\n在 2020-02-11 发布了 flink 1.10，该版本完成了与 k8s 集成的第一阶段，实现了向 k8s 动态申请资源，就像跟 yarn 或 mesos 集成那样。\n确定 flink 部署的 namespace，这里我选 \u0026ldquo;flink\u0026rdquo;，确保 namespace 已创建:\nkubectl create ns flink 创建 RBAC (创建 ServiceAccount 绑定 flink 需要的对 k8s 集群操作的权限):\napiVersion: v1 kind: ServiceAccount metadata: name: flink namespace: flink --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: flink-role-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: edit subjects: - kind: ServiceAccount name: flink namespace: flink 利用 job 运行启动 flink 的引导程序 (请求 k8s 创建 jobmanager 相关的资源: service, deployment, configmap):\napiVersion: batch/v1 kind: Job metadata: name: boot-flink namespace: flink spec: template: spec: serviceAccount: flink restartPolicy: OnFailure containers: - name: start image: flink:1.10 workingDir: /opt/flink command: [\u0026#34;bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;$FLINK_HOME/bin/kubernetes-session.sh \\ -Dkubernetes.cluster-id=roc \\ -Dkubernetes.jobmanager.service-account=flink \\ -Dtaskmanager.memory.process.size=1024m \\ -Dkubernetes.taskmanager.cpu=1 \\ -Dtaskmanager.numberOfTaskSlots=1 \\ -Dkubernetes.container.image=flink:1.10 \\ -Dkubernetes.namespace=flink\u0026#34;]  kubernetes.cluster-id: 指定 flink 集群的名称，后续自动创建的 k8s 资源会带上这个作为前缀或后缀 kubernetes.namespace: 指定 flink 相关的资源创建在哪个命名空间，这里我们用 flink 命名空间 kubernetes.jobmanager.service-account: 指定我们刚刚为 flink 创建的 ServiceAccount kubernetes.container.image: 指定 flink 需要用的镜像，这里我们部署的 1.10 版本，所以镜像用 flink:1.10  部署完成后，我们可以看到有刚刚运行完成的 job 的 pod 和被这个 job 拉起的 flink jobmanager 的 pod，前缀与配置 kubernetes.cluster-id 相同:\n$ kubectl -n flink get pod NAME READY STATUS RESTARTS AGE roc-cf9f6b5df-csk9z 1/1 Running 0 84m boot-flink-nc2qx 0/1 Completed 0 84m 还有 jobmanager 的 service:\n$ kubectl -n flink get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE roc ClusterIP 172.16.255.152 \u0026lt;none\u0026gt; 8081/TCP,6123/TCP,6124/TCP 88m roc-rest LoadBalancer 172.16.255.11 150.109.27.251 8081:31240/TCP 88m 访问 http://150.109.27.251:8081 即可进入此 flink 集群的 ui 界面。\n参考资料  Active Kubernetes integration phase 2 - Advanced Features: https://issues.apache.org/jira/browse/FLINK-14460 Apache Flink 1.10.0 Release Announcement: https://flink.apache.org/news/2020/02/11/release-1.10.0.html Native Kubernetes Setup Beta (flink与kubernetes集成的官方教程): https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/deployment/native_kubernetes.html  "
},
{
	"uri": "https://k8s.imroc.io/dev/golang-build/",
	"title": "Go 语言编译原理与优化",
	"tags": [],
	"description": "",
	"content": "编译阶段 (Compilation) debug 参数 -m 打印编译器更多想法的细节\n-gcflags \u0026#39;-m\u0026#39; -S 打印汇编\n-gcflags \u0026#39;-S\u0026#39; 优化和内联 默认开启了优化和内联，但是debug的时候开启可能会出现一些奇怪的问题，通过下面的参数可以禁止任何优化\n-gcflags \u0026#39;-N -l\u0026#39; 内联级别：\n -gcflags='-l -l' 内联级别2，更积极，可能更快，可能会制作更大的二进制文件。 -gcflags='-l -l -l' 内联级别3，再次更加激进，二进制文件肯定更大，也许更快，但也许会有 bug。 -gcflags=-l=4 (4个-l)在 Go 1.11 中将支持实验性的中间栈内联优化。  逃逸分析  如果一个局部变量值超越了函数调用的生命周期，编译器自动将它逃逸到堆 如果一个通过new或make来分配的对象，在函数内即使将指针传递给了其它函数，其它函数会被内联到当前函数，相当于指针不会逃逸出本函数，最终不返回指针的话，该指针对应的值也都会分配在栈上，而不是在堆  链接阶段 (Linking)  Go 支持 internal 和 external 两种链接方式: internal 使用 go 自身实现的 linker，external 需要启动外部的 linker linker 的主要工作是将 .o (object file) 链接成最终可执行的二进制 对应命令: go tool link，对应源码: $GOROOT/src/cmd/link 通过 -ldflags 给链接器传参，参数详见: go tool link --help  关于 CGO  启用cgo可以调用外部依赖的c库 go的编译器会判断环境变量 CGO_ENABLED 来决定是否启用cgo，默认 CGO_ENABLED=1 即启用cgo 源码文件头部的 build tag 可以根据cgo是否启用决定源码是否被编译(// +build cgo 表示希望cgo启用时被编译，相反的是 // +build !cgo) 标准库中有部分实现有两份源码，比如: $GOROOT/src/os/user/lookup_unix.go 和 $GOROOT/src/os/user/cgo_lookup_unix.go ，它们有相同的函数，但实现不一样，前者是纯go实现，后者是使用cgo调用外部依赖来实现，标准库中使用cgo比较常见的是 net 包。  internal linking  link 默认使用 internal 方式 直接使用 go 本身的实现的 linker 来链接代码， 功能比较简单，仅仅是将 .o 和预编译的 .a 写到最终二进制文件中(.a文件在 $GOROOT/pkg 和 $GOPATH/pkg 中，其实就是.o文件打包的压缩包，通过 tar -zxvf 可以解压出来查看)  external linking  会启动外部 linker (gcc/clang)，通过 -ldflags '-linkmode \u0026quot;external\u0026quot;' 启用 external linking 通过 -extldflags 给外部 linker 传参，比如： -ldflags '-linkmode \u0026quot;external\u0026quot; -extldflags \u0026quot;-static\u0026quot;'  static link go编译出来就是一个二进制，自带runtime，不需要解释器，但并不意味着就不需要任何依赖，但也可以通过静态链接来做到完全不用任何依赖，全部”揉“到一个二进制文件中。实现静态链接的方法：\n 如果是 external linking，可以这样: -ldflags '-linkmode external -extldflags -static' 如果用默认的 internal linking，可以这样: -ldflags '-d'  ldflags 其它常用参数  -s -w 是去除符号表和DWARF调试信息(可以减小二进制体积，但不利于调试，可在用于生产环境)，示例: -ldflags '-s -w' -X 可以给变量注入值，比如编译时用脚本动态注入当前版本和 commit id 到代码的变量中，通常程序的 version 子命令或参数输出当前版本信息时就用这种方式实现，示例：-ldflags '-X myapp/pkg/version/version=v1.0.0'  使用 Docker 编译 使用 Docker 编译可以不用依赖本机 go 环境，将编译环境标准化，特别在有外部动态链接库依赖的情况下很有用，可以直接 run 一个容器来编译，给它挂载源码目录和二进制输出目录，这样我们就可以拿到编译出来的二进制了，这里以编译cfssl为例:\nROOT_PKG=github.com/cloudflare/cfssl CMD_PKG=$ROOT_PKG/cmd LOCAL_SOURCE_PATH=/Users/roc/go/src/$ROOT_PKG LOCAL_OUTPUT_PATH=$PWD GOPATH=/go/src ROOT_PATH=$GOPATH/$ROOT_PKG CMD_PATH=$GOPATH/$CMD_PKG docker run --rm \\  -v $LOCAL_SOURCE_PATH:$ROOT_PATH \\  -v $LOCAL_OUTPUT_PATH:/output \\  -w $ROOT_PATH \\  golang:1.13 \\  go build -v \\  -ldflags \u0026#39;-d\u0026#39; \\  -o /output/ \\  $CMD_PATH/... 编译镜像可以参考下面示例（使用docker多阶段构建，完全静态编译，没有外部依赖）:\nFROMgolang:1.12-stretch as builderMAINTAINERrockerchen@tencent.comENV BUILD_DIR /go/src/cloud.tencent.com/qc_container_cluster/hpa-metrics-serverWORKDIR$BUILD_DIRCOPY ./ $BUILD_DIRRUN CGO_ENABLED=0 go build -v -o /hpa-metrics-server \\  -ldflags \u0026#39;-d\u0026#39; \\  ./FROMubuntu:16.04MAINTAINERrockerchen@tencent.comRUN apt-get update -yRUN DEBIAN_FRONTEND=noninteractive apt-get install -y curl iproute2 inetutils-tools telnet inetutils-pingRUN apt-get install --no-install-recommends --no-install-suggests ca-certificates -yCOPY --from=builder /hpa-metrics-server /hpa-metrics-serverRUN chmod a+x /hpa-metrics-server参考资料  Go 性能调优之 —— 编译优化: https://segmentfault.com/a/1190000016354799  "
},
{
	"uri": "https://k8s.imroc.io/best-practice/configuration-management/helm/",
	"title": "Helm",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/cluster/ingress/",
	"title": "Ingress 方案",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/handle/runnig-out-of-inotify-watches/",
	"title": "inotify watch 耗尽",
	"tags": [],
	"description": "",
	"content": "每个 linux 进程可以持有多个 fd，每个 inotify 类型的 fd 可以 watch 多个目录，每个用户下所有进程 inotify 类型的 fd 可以 watch 的总目录数有个最大限制，这个限制可以通过内核参数配置: fs.inotify.max_user_watches\n查看最大 inotify watch 数:\n$ cat /proc/sys/fs/inotify/max_user_watches 8192 使用下面的脚本查看当前有 inotify watch 类型 fd 的进程以及每个 fd watch 的目录数量，降序输出，带总数统计:\n#!/usr/bin/env bash # # Copyright 2019 (c) roc # # This script shows processes holding the inotify fd, alone with HOW MANY directories each inotify fd watches(0 will be ignored). total=0 result=\u0026#34;EXE PID FD-INFO INOTIFY-WATCHES\\n\u0026#34; while read pid fd; do \\  exe=\u0026#34;$(readlink -f /proc/$pid/exe || echo n/a)\u0026#34;; \\  fdinfo=\u0026#34;/proc/$pid/fdinfo/$fd\u0026#34; ; \\  count=\u0026#34;$(grep -c inotify \u0026#34;$fdinfo\u0026#34; || true)\u0026#34;; \\  if [ $((count)) != 0 ]; then total=$((total+count)); \\  result+=\u0026#34;$exe$pid$fdinfo$count\\n\u0026#34;; \\  fi done \u0026lt;\u0026lt;\u0026lt; \u0026#34;$(lsof +c 0 -n -P -u root|awk \u0026#39;/inotify$/ { gsub(/[urw]$/,\u0026#34;\u0026#34;,$4); print $2\u0026#34; \u0026#34;$4 }\u0026#39;)\u0026#34; \u0026amp;\u0026amp; echo \u0026#34;total $totalinotify watches\u0026#34; \u0026amp;\u0026amp; result=\u0026#34;$(echo -e $result|column -t)\\n\u0026#34; \u0026amp;\u0026amp; echo -e \u0026#34;$result\u0026#34; | head -1 \u0026amp;\u0026amp; echo -e \u0026#34;$result\u0026#34; | sed \u0026#34;1d\u0026#34; | sort -k 4rn; 示例输出:\ntotal 7882 inotify watches EXE PID FD-INFO INOTIFY-WATCHES /usr/local/qcloud/YunJing/YDEyes/YDService 25813 /proc/25813/fdinfo/8 7077 /usr/bin/kubelet 1173 /proc/1173/fdinfo/22 665 /usr/bin/ruby2.3 13381 /proc/13381/fdinfo/14 54 /usr/lib/policykit-1/polkitd 1458 /proc/1458/fdinfo/9 14 /lib/systemd/systemd-udevd 450 /proc/450/fdinfo/9 13 /usr/sbin/nscd 7935 /proc/7935/fdinfo/3 6 /usr/bin/kubelet 1173 /proc/1173/fdinfo/28 5 /lib/systemd/systemd 1 /proc/1/fdinfo/17 4 /lib/systemd/systemd 1 /proc/1/fdinfo/18 4 /lib/systemd/systemd 1 /proc/1/fdinfo/26 4 /lib/systemd/systemd 1 /proc/1/fdinfo/28 4 /usr/lib/policykit-1/polkitd 1458 /proc/1458/fdinfo/8 4 /usr/local/bin/sidecar-injector 4751 /proc/4751/fdinfo/3 3 /usr/lib/accountsservice/accounts-daemon 1178 /proc/1178/fdinfo/7 2 /usr/local/bin/galley 8228 /proc/8228/fdinfo/10 2 /usr/local/bin/galley 8228 /proc/8228/fdinfo/9 2 /lib/systemd/systemd 1 /proc/1/fdinfo/11 1 /sbin/agetty 1437 /proc/1437/fdinfo/4 1 /sbin/agetty 1440 /proc/1440/fdinfo/4 1 /usr/bin/kubelet 1173 /proc/1173/fdinfo/10 1 /usr/local/bin/envoy 4859 /proc/4859/fdinfo/5 1 /usr/local/bin/envoy 5427 /proc/5427/fdinfo/5 1 /usr/local/bin/envoy 6058 /proc/6058/fdinfo/3 1 /usr/local/bin/envoy 6893 /proc/6893/fdinfo/3 1 /usr/local/bin/envoy 6950 /proc/6950/fdinfo/3 1 /usr/local/bin/galley 8228 /proc/8228/fdinfo/3 1 /usr/local/bin/pilot-agent 3819 /proc/3819/fdinfo/5 1 /usr/local/bin/pilot-agent 4244 /proc/4244/fdinfo/5 1 /usr/local/bin/pilot-agent 5901 /proc/5901/fdinfo/3 1 /usr/local/bin/pilot-agent 6789 /proc/6789/fdinfo/3 1 /usr/local/bin/pilot-agent 6808 /proc/6808/fdinfo/3 1 /usr/local/bin/pilot-discovery 6231 /proc/6231/fdinfo/3 1 /usr/local/bin/sidecar-injector 4751 /proc/4751/fdinfo/5 1 /usr/sbin/acpid 1166 /proc/1166/fdinfo/6 1 /usr/sbin/dnsmasq 7572 /proc/7572/fdinfo/8 1 如果看到总 watch 数比较大，接近最大限制，可以修改内核参数调高下这个限制。\n临时调整:\nsudo sysctl fs.inotify.max_user_watches=524288 永久生效:\necho \u0026#34;fs.inotify.max_user_watches=524288\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf \u0026amp;\u0026amp; sysctl -p 打开 inotify_add_watch 跟踪，进一步 debug inotify watch 耗尽的原因:\necho 1 \u0026gt;\u0026gt; /sys/kernel/debug/tracing/events/syscalls/sys_exit_inotify_add_watch/enable "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/others/job-cannot-delete/",
	"title": "Job 无法被删除",
	"tags": [],
	"description": "",
	"content": "原因  可能是 k8s 的一个bug: https://github.com/kubernetes/kubernetes/issues/43168 本质上是脏数据问题，Running+Succeed != 期望Completions 数量，低版本 kubectl 不容忍，delete job 的时候打开debug(加-v=8)，会看到kubectl不断在重试，直到达到timeout时间。新版kubectl会容忍这些，删除job时会删除关联的pod  解决方法  升级 kubectl 版本，1.12 以上 低版本 kubectl 删除 job 时带 --cascade=false 参数(如果job关联的pod没删完，加这个参数不会删除关联的pod)  kubectl delete job --cascade=false \u0026lt;job name\u0026gt; "
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/schemaerror-when-using-kubectl-apply-or-edit/",
	"title": "kubectl edit 或者 apply 报 SchemaError",
	"tags": [],
	"description": "",
	"content": "问题现象 kubectl edit 或 apply 资源报如下错误:\nerror: SchemaError(io.k8s.apimachinery.pkg.apis.meta.v1.APIGroup): invalid object doesn't have additional properties 集群版本：v1.10\n排查过程  使用 kubectl apply -f tmp.yaml --dry-run -v8 发现请求 /openapi/v2 这个 api 之后，kubectl在 validate 过程报错。 换成 kubectl 1.12 之后没有再报错。 kubectl get --raw '/openapi/v2' 发现返回的 json 内容与正常集群有差异，刚开始返回的 json title 为 Kubernetes metrics-server，正常的是 Kubernetes。 怀疑是 metrics-server 的问题，发现集群内确实安装了 k8s 官方的 metrics-server，询问得知之前是 0.3.1，后面升级为了 0.3.5。 将 metrics-server 回滚之后恢复正常。  原因分析 初步怀疑，新版本的 metrics-server 使用了新的 openapi-generator，生成的 openapi 格式和之前 k8s 版本生成的有差异。导致旧版本的 kubectl 在解析 openapi 的 schema 时发生异常，查看代码发现1.10 和 1.12 版本在解析 openapi 的 schema 时，实现确实有差异。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/others/kubectl-exec-or-logs-failed/",
	"title": "kubectl 执行 exec 或 logs 失败",
	"tags": [],
	"description": "",
	"content": "通常是 apiserver \u0026ndash;\u0026gt; kubelet:10250 之间的网络不通，10250 是 kubelet 提供接口的端口，kubectl exec 和 kubectl logs 的原理就是 apiserver 调 kubelet，kubelet 再调运行时 (比如 dockerd) 来实现的，所以要保证 kubelet 10250 端口对 apiserver 放通。检查防火墙、iptables 规则是否对 10250 端口或某些 IP 进行了拦截。\n"
},
{
	"uri": "https://k8s.imroc.io/trick/efficient-kubectl/",
	"title": "kubectl 高效技巧",
	"tags": [],
	"description": "",
	"content": "k 命令 是否有过因为使用 kubectl 经常需要重复输入命名空间而苦恼？是否觉得应该要有个记住命名空间的功能，自动记住上次使用的命名空间，不需要每次都输入？可惜没有这种功能，但是，本文会教你一个非常巧妙的方法完美帮你解决这个痛点。\n将如下脚本粘贴到当前shell(注册k命令到当前终端session):\nfunction k() { cmdline=`HISTTIMEFORMAT=\u0026#34;\u0026#34; history | awk \u0026#39;$2 == \u0026#34;kubectl\u0026#34; \u0026amp;\u0026amp; (/-n/ || /--namespace/) {for(i=2;i\u0026lt;=NF;i++)printf(\u0026#34;%s \u0026#34;,$i);print \u0026#34;\u0026#34;}\u0026#39; | tail -n 1` regs=(\u0026#39;\\-n [\\w\\-\\d]+\u0026#39; \u0026#39;\\-n=[\\w\\-\\d]+\u0026#39; \u0026#39;\\-\\-namespace [\\w\\-\\d]+\u0026#39; \u0026#39;\\-\\-namespace=[\\w\\-\\d]+\u0026#39;) for i in \u0026#34;${!regs[@]}\u0026#34;; do reg=${regs[i]} nsarg=`echo $cmdline | grep -o -P \u0026#34;$reg\u0026#34;` if [[ \u0026#34;$nsarg\u0026#34; == \u0026#34;\u0026#34; ]]; then continue fi cmd=\u0026#34;kubectl $nsarg$@\u0026#34; echo \u0026#34;$cmd\u0026#34; $cmd return done cmd=\u0026#34;kubectl $@\u0026#34; echo \u0026#34;$cmd\u0026#34; $cmd } mac 用户可以使用 dash 的 snippets 功能快速将上面的函数粘贴，使用 kk. 作为触发键 (dash snippets可以全局监听键盘输入，使用指定的输入作为触发而展开配置的内容，相当于是全局代码片段)，以后在某个终端想使用 k 的时候按下 kk. 就可以将 k 命令注册到当前终端，dash snippets 配置如图所示：\n将 k 当作 kubectl 来用，只是不需要输入命名空间，它会调用 kubectl 并自动加上上次使用的非默认的命名空间，如果想切换命名空间，再常规的使用一次 kubectl 就行，下面是示范：\n哈哈，是否感觉可以少输入很多字符，提高 kubectl 使用效率了？这是目前我探索解决 kubectl 重复输入命名空间的最好方案，一开始是受 fuck命令 的启发，想用 go 语言开发个 k 命令，但是发现两个缺点：\n 需要安装二进制才可以使用（对于需要在多个地方用kubectl管理多个集群的人来说实在太麻烦） 如果当前 shell 默认没有将历史输入记录到 history 文件( bash 的 history 文件默认是 ~/.bash_history)，那么将无法准确知道上一次 kubectl 使用的哪个命名空间  这里解释下第二个缺点的原因：ssh 连上服务器会启动一个 shell 进程，通常是 bash，大多 bash 默认配置会实时将历史输入追加到 ~/.bash_history里，所以开多个ssh使用history命令看到的历史输入是一样的，但有些默认不会实时记录历史到~/.bash_history，而是记在当前 shell 进程的内存中，在 shell 退出时才会写入到文件。这种情况新起的进程是无法知道当前 shell 的最近历史输入的，fuck命令 也不例外。\n所以最完美的解决方案就是注册函数到当前shell来调用，配合 dash 的 snippets 功能可以实现快速注册，解决复制粘贴的麻烦\n"
},
{
	"uri": "https://k8s.imroc.io/",
	"title": "Kubernetes 实践指南",
	"tags": [],
	"description": "",
	"content": "Roadmap 本书正在起草初期，内容将包含大量 Kubernetes 实践干货，大量规划内容还正在路上，可以点击的表示是已经可以在左侧导航栏中找到的并预览的文章，但不代表已经完善，还会不断的补充和优化。\n目录  注：不能点击的标题是还正在路上的内容\n  集群部署    方案选型     使用 kubespray 部署     手工部署    部署前的准备工作     部署 ETCD     部署 Master     部署 Worker 节点     部署关键组件      附加组件    以 Daemonset 方式部署 kube-proxy     部署 CoreDNS      附录    安装 kubectl       排错指南    排错技巧    使用 Systemtap 定位疑难杂症     分析 ExitCode 定位 Pod 异常退出原因     容器内抓包定位网络问题      处理实践    arp_cache 溢出     inotify watch 耗尽     PID 耗尽     内存碎片化     磁盘爆满     高负载      节点排错    arp_cache: neighbor table overflow! (arp缓存溢出)     Cannot allocate memory     no space left on device     Node NotReady     soft lockup (内核软死锁)      Pod 排错    Pod Terminating 慢     Pod 一直处于 ContainerCreating 或 Waiting 状态     Pod 一直处于 Error 状态     Pod 一直处于 ImageInspectError 状态     Pod 一直处于 ImagePullBackOff 状态     Pod 一直处于 Pending 状态     Pod 一直处于 Terminating 状态     Pod 一直处于 Unknown 状态     Pod 健康检查失败     Pod 处于 CrashLoopBackOff 状态     容器进程主动退出      网络排错    DNS 解析异常     LB 健康检查失败     Service 不通     Service 无法解析     网络性能差      其它排错    APIServer 响应慢     Daemonset 没有被调度     Job 无法被删除     kubectl 执行 exec 或 logs 失败     Node 全部消失       避坑指南    cgroup 泄露     conntrack 冲突导致丢包     tcp tw recycle 引发丢包     使用 NodeLocal DNS (缓存)     使用 oom-guard 在用户态处理 cgroup OOM     解决长连接服务扩容失效     踩坑分享    ARP 缓存爆满导致健康检查失败     DNS 5 秒延时     DNS 解析异常     kubectl edit 或者 apply 报 SchemaError     LB 压测 NodePort CPS 低     Pod 偶尔存活检查失败     Pod 访问另一个集群的 apiserver 有延时     神秘的溢出与丢包     访问 externalTrafficPolicy 为 Local 的 Service 对应 LB 有时超时     诡异的 No route to host     跨 VPC 访问 NodePort 经常超时     驱逐导致服务中断       集群优化    应用部署优化    使用 PodDisruptionBudget 避免驱逐导致服务不可用     使用 preStopHook 和 readinessProbe 保证服务平滑更新不中断     使用反亲和性避免单点故障      ETCD 优化     Master 优化     内核参数优化      集群安全    用户管理    利用 CSR API 创建用户      集群权限控制    控制应用权限     控制用户权限      集群证书管理    安装 cert-manager     使用 cert-manager 自动生成证书       实用技巧    kubectl 高效技巧     yaml 片段    Deployment      实用命令与脚本    Pod 相关脚本     网络调试相关脚本     节点相关脚本       监控告警     日志搜集     AI 与大数据    Flink on Kubernetes      开发指南    Go 语言编译原理与优化     使用 client-go 开发 k8s 应用      在线阅读 本书将支持中英文两个语言版本，通常文章会先用中文起草并更新，等待其内容较为成熟完善，更新不再频繁的时候才会翻译成英文，点击左上角切换语言。\n 中文: https://k8s.imroc.io English: https://k8s.imroc.io/en  项目源码 项目源码存放于 Github 上: https://github.com/imroc/kubernetes-practice-guide\n贡献 欢迎参与贡献和完善内容，贡献方法参考 CONTRIBUTING\nLicense 署名-非商业性使用-相同方式共享 4.0 (CC BY-NC-SA 4.0)\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/network/lb-healthcheck-failed/",
	"title": "LB 健康检查失败",
	"tags": [],
	"description": "",
	"content": "可能原因:\n 节点防火墙规则没放开 nodeport 区间端口 (默认 30000-32768) 检查iptables和云主机安全组 LB IP 绑到 kube-ipvs0 导致丢源 IP为 LB IP 的包: https://github.com/kubernetes/kubernetes/issues/79783  TODO: 完善\n"
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/low-cps-from-lb-to-nodeport/",
	"title": "LB 压测 NodePort CPS 低",
	"tags": [],
	"description": "",
	"content": "现象: LoadBalancer 类型的 Service，直接压测 NodePort CPS 比较高，但如果压测 LB CPS 就很低。\n环境说明: 用户使用的黑石TKE，不是公有云TKE，黑石的机器是物理机，LB的实现也跟公有云不一样，但 LoadBalancer 类型的 Service 的实现同样也是 LB 绑定各节点的 NodePort，报文发到 LB 后转到节点的 NodePort， 然后再路由到对应 pod，而测试在公有云 TKE 环境下没有这个问题。\n client 抓包: 大量SYN重传。 server 抓包: 抓 NodePort 的包，发现当 client SYN 重传时 server 能收到 SYN 包但没有响应。  又是 SYN 收到但没响应，难道又是开启 tcp_tw_recycle 导致的？检查节点的内核参数发现并没有开启，除了这个原因，还会有什么情况能导致被丢弃？\nconntrack -S 看到 insert_failed 数量在不断增加，也就是 conntrack 在插入很多新连接的时候失败了，为什么会插入失败？什么情况下会插入失败？\n挖内核源码: netfilter conntrack 模块为每个连接创建 conntrack 表项时，表项的创建和最终插入之间还有一段逻辑，没有加锁，是一种乐观锁的过程。conntrack 表项并发刚创建时五元组不冲突的话可以创建成功，但中间经过 NAT 转换之后五元组就可能变成相同，第一个可以插入成功，后面的就会插入失败，因为已经有相同的表项存在。比如一个 SYN 已经做了 NAT 但是还没到最终插入的时候，另一个 SYN 也在做 NAT，因为之前那个 SYN 还没插入，这个 SYN 做 NAT 的时候就认为这个五元组没有被占用，那么它 NAT 之后的五元组就可能跟那个还没插入的包相同。\n在我们这个问题里实际就是 netfilter 做 SNAT 时源端口选举冲突了，黑石 LB 会做 SNAT，SNAT 时使用了 16 个不同 IP 做源，但是短时间内源 Port 却是集中一致的，并发两个 SYN a 和SYN b，被 LB SNAT 后源 IP 不同但源 Port 很可能相同，这里就假设两个报文被 LB SNAT 之后它们源 IP 不同源 Port 相同，报文同时到了节点的 NodePort 会再次做 SNAT 再转发到对应的 Pod，当报文到了 NodePort 时，这时它们五元组不冲突，netfilter 为它们分别创建了 conntrack 表项，SYN a 被节点 SNAT 时默认行为是 从 port_range 范围的当前源 Port 作为起始位置开始循环遍历，选举出没有被占用的作为源 Port，因为这两个 SYN 源 Port 相同，所以它们源 Port 选举的起始位置相同，当 SYN a 选出源 Port 但还没将 conntrack 表项插入时，netfilter 认为这个 Port 没被占用就很可能给 SYN b 也选了相同的源 Port，这时他们五元组就相同了，当 SYN a 的 conntrack 表项插入后再插入 SYN b 的 conntrack 表项时，发现已经有相同的记录就将 SYN b 的 conntrack 表项丢弃了。\n解决方法探索: 不使用源端口选举，在 iptables 的 MASQUERADE 规则如果加 --random-fully 这个 flag 可以让端口选举完全随机，基本上能避免绝大多数的冲突，但也无法完全杜绝。最终决定开发 LB 直接绑 Pod IP，不基于 NodePort，从而避免 netfilter 的 SNAT 源端口冲突问题。\n"
},
{
	"uri": "https://k8s.imroc.io/optimization/master/",
	"title": "Master 优化",
	"tags": [],
	"description": "",
	"content": "Kubernetes 自 v1.6 以来，官方就宣称单集群最大支持 5000 个节点。不过这只是理论上，在具体实践中从 0 到 5000，还是有很长的路要走，需要见招拆招。\n官方标准如下：\n 不超过 5000 个节点 不超过 150000 个 pod 不超过 300000 个容器 每个节点不超过 100 个 pod  Master 节点配置优化 GCE 推荐配置：\n 1-5 节点: n1-standard-1 6-10 节点: n1-standard-2 11-100 节点: n1-standard-4 101-250 节点: n1-standard-8 251-500 节点: n1-standard-16 超过 500 节点: n1-standard-32  AWS 推荐配置：\n 1-5 节点: m3.medium 6-10 节点: m3.large 11-100 节点: m3.xlarge 101-250 节点: m3.2xlarge 251-500 节点: c4.4xlarge 超过 500 节点: c4.8xlarge  对应 CPU 和内存为：\n 1-5 节点: 1vCPU 3.75G内存 6-10 节点: 2vCPU 7.5G内存 11-100 节点: 4vCPU 15G内存 101-250 节点: 8vCPU 30G内存 251-500 节点: 16vCPU 60G内存 超过 500 节点: 32vCPU 120G内存  kube-apiserver 优化 高可用  方式一: 启动多个 kube-apiserver 实例通过外部 LB 做负载均衡。 方式二: 设置 --apiserver-count 和 --endpoint-reconciler-type，可使得多个 kube-apiserver 实例加入到 Kubernetes Service 的 endpoints 中，从而实现高可用。  不过由于 TLS 会复用连接，所以上述两种方式都无法做到真正的负载均衡。为了解决这个问题，可以在服务端实现限流器，在请求达到阀值时告知客户端退避或拒绝连接，客户端则配合实现相应负载切换机制。\n控制连接数 kube-apiserver 以下两个参数可以控制连接数:\n--max-mutating-requests-inflight int The maximum number of mutating requests in flight at a given time. When the server exceeds this, it rejects requests. Zero for no limit. (default 200) --max-requests-inflight int The maximum number of non-mutating requests in flight at a given time. When the server exceeds this, it rejects requests. Zero for no limit. (default 400) 节点数量在 1000 - 3000 之间时，推荐：\n--max-requests-inflight=1500 --max-mutating-requests-inflight=500 节点数量大于 3000 时，推荐：\n--max-requests-inflight=3000 --max-mutating-requests-inflight=1000 kube-scheduler 与 kube-controller-manager 优化 高可用 kube-controller-manager 和 kube-scheduler 是通过 leader election 实现高可用，启用时需要添加以下参数:\n--leader-elect=true --leader-elect-lease-duration=15s --leader-elect-renew-deadline=10s --leader-elect-resource-lock=endpoints --leader-elect-retry-period=2s 控制 QPS 与 kube-apiserver 通信的 qps 限制，推荐为：\n--kube-api-qps=100 集群 DNS 高可用 设置反亲和，让集群 DNS (kube-dns 或 coredns) 分散在不同节点，避免单点故障:\naffinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - weight: 100 labelSelector: matchExpressions: - key: k8s-app operator: In values: - kube-dns topologyKey: kubernetes.io/hostname "
},
{
	"uri": "https://k8s.imroc.io/cluster/metrics/",
	"title": "Metrics 方案",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/cluster/ingress/nginx/",
	"title": "Nginx Ingress",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/node/no-space-left-on-device/",
	"title": "no space left on device",
	"tags": [],
	"description": "",
	"content": " 有时候节点 NotReady， kubelet 日志报 no space left on device 有时候创建 Pod 失败，describe pod 看 event 报 no space left on device  出现这种错误有很多中可能原因，下面我们来根据现象找对应原因。\ninotify watch 耗尽 节点 NotReady，kubelet 启动失败，看 kubelet 日志:\nJul 18 15:20:58 VM_16_16_centos kubelet[11519]: E0718 15:20:58.280275 11519 raw.go:140] Failed to watch directory \u0026#34;/sys/fs/cgroup/memory/kubepods\u0026#34;: inotify_add_watch /sys/fs/cgroup/memory/kubepods/burstable/pod926b7ff4-7bff-11e8-945b-52540048533c/6e85761a30707b43ed874e0140f58839618285fc90717153b3cbe7f91629ef5a: no space left on device 系统调用 inotify_add_watch 失败，提示 no space left on device， 这是因为系统上进程 watch 文件目录的总数超出了最大限制，可以修改内核参数调高限制，详细请参考本书 处理实践: inotify watch 耗尽\ncgroup 泄露 查看当前 cgroup 数量:\n$ cat /proc/cgroups | column -t #subsys_name hierarchy num_cgroups enabled cpuset 5 29 1 cpu 7 126 1 cpuacct 7 126 1 memory 9 127 1 devices 4 126 1 freezer 2 29 1 net_cls 6 29 1 blkio 10 126 1 perf_event 3 29 1 hugetlb 11 29 1 pids 8 126 1 net_prio 6 29 1 cgroup 子系统目录下面所有每个目录及其子目录都认为是一个独立的 cgroup，所以也可以在文件系统中统计目录数来获取实际 cgroup 数量，通常跟 /proc/cgroups 里面看到的应该一致:\n$ find -L /sys/fs/cgroup/memory -type d | wc -l 127 当 cgroup 泄露发生时，这里的数量就不是真实的了，低版本内核限制最大 65535 个 cgroup，并且开启 kmem 删除 cgroup 时会泄露，大量创建删除容器后泄露了许多 cgroup，最终总数达到 65535，新建容器创建 cgroup 将会失败，报 no space left on device\n详细请参考本书 案例分享: cgroup 泄露\n磁盘被写满(TODO) Pod 启动失败，状态 CreateContainerError:\ncsi-cephfsplugin-27znb 0/2 CreateContainerError 167 17h Pod 事件报错:\nWarning Failed 5m1s (x3397 over 17h) kubelet, ip-10-0-151-35.us-west-2.compute.internal (combined from similar events): Error: container create failed: container_linux.go:336: starting container process caused \u0026#34;process_linux.go:399: container init caused \\\u0026#34;rootfs_linux.go:58: mounting \\\\\\\u0026#34;/sys\\\\\\\u0026#34; to rootfs \\\\\\\u0026#34;/var/lib/containers/storage/overlay/051e985771cc69f3f699895a1dada9ef6483e912b46a99e004af7bb4852183eb/merged\\\\\\\u0026#34; at \\\\\\\u0026#34;/var/lib/containers/storage/overlay/051e985771cc69f3f699895a1dada9ef6483e912b46a99e004af7bb4852183eb/merged/sys\\\\\\\u0026#34; caused \\\\\\\u0026#34;no space left on device\\\\\\\u0026#34;\\\u0026#34;\u0026#34; "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/node/not-ready/",
	"title": "Node NotReady",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/others/node-all-gone/",
	"title": "Node 全部消失",
	"tags": [],
	"description": "",
	"content": "Rancher 清除 Node 导致集群异常 现象 安装了 rancher 的用户，在卸载 rancher 的时候，可能会手动执行 kubectl delete ns local 来删除这个 rancher 创建的 namespace，但直接这样做会导致所有 node 被清除，通过 kubectl get node 获取不到 node。\n原因 看了下 rancher 源码，rancher 通过 nodes.management.cattle.io 这个 CRD 存储和管理 node，会给所有 node 创建对应的这个 CRD 资源，metadata 中加入了两个 finalizer，其中 user-node-remove_local 对应的 finalizer 处理逻辑就是删除对应的 k8s node 资源，也就是 delete ns local 时，会尝试删除 nodes.management.cattle.io 这些 CRD 资源，进而触发 rancher 的 finalizer 逻辑去删除对应的 k8s node 资源，从而清空了 node，所以 kubectl get node 就看不到 node 了，集群里的服务就无法被调度。\n规避方案 不要在 rancher 组件卸载完之前手动 delete ns local。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/handle/pid-full/",
	"title": "PID 耗尽",
	"tags": [],
	"description": "",
	"content": "如何判断 PID 耗尽 首先要确认当前的 PID 限制，检查全局 PID 最大限制:\ncat /proc/sys/kernel/pid_max 也检查下线程数限制：\ncat /proc/sys/kernel/threads-max 再检查下当前用户是否还有 ulimit 限制最大进程数。\n确认当前实际 PID 数量，检查当前用户的 PID 数量:\nps -eLf | wc -l 如果发现实际 PID 数量接近最大限制说明 PID 就可能会爆满导致经常有进程无法启动，低版本内核可能报错: Cannot allocate memory，这个报错信息不准确，在内核 4.1 以后改进了: https://github.com/torvalds/linux/commit/35f71bc0a09a45924bed268d8ccd0d3407bc476f\n如何解决 临时调大 PID 和线程数限制：\necho 65535 \u0026gt; /proc/sys/kernel/pid_max echo 65535 \u0026gt; /proc/sys/kernel/threads-max 永久调大 PID 和线程数限制:\necho \u0026#34;kernel.pid_max=65535 \u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf \u0026amp;\u0026amp; sysctl -p echo \u0026#34;kernel.threads-max=65535 \u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf \u0026amp;\u0026amp; sysctl -p k8s 1.14 支持了限制 Pod 的进程数量: https://kubernetes.io/blog/2019/04/15/process-id-limiting-for-stability-improvements-in-kubernetes-1.14/\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/slow-terminating/",
	"title": "Pod Terminating 慢",
	"tags": [],
	"description": "",
	"content": "可能原因  进程通过 bash -c 启动导致 kill 信号无法透传给业务进程  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-containercreating-or-waiting/",
	"title": "Pod 一直处于 ContainerCreating 或 Waiting 状态",
	"tags": [],
	"description": "",
	"content": "Pod 配置错误  检查是否打包了正确的镜像 检查配置了正确的容器参数  挂载 Volume 失败 Volume 挂载失败也分许多种情况，先列下我这里目前已知的。\nPod 漂移没有正常解挂之前的磁盘 在云尝试托管的 K8S 服务环境下，默认挂载的 Volume 一般是块存储类型的云硬盘，如果某个节点挂了，kubelet 无法正常运行或与 apiserver 通信，到达时间阀值后会触发驱逐，自动在其它节点上启动相同的副本 (Pod 漂移)，但是由于被驱逐的 Node 无法正常运行并不知道自己被驱逐了，也就没有正常执行解挂，cloud-controller-manager 也在等解挂成功后再调用云厂商的接口将磁盘真正从节点上解挂，通常会等到一个时间阀值后 cloud-controller-manager 会强制解挂云盘，然后再将其挂载到 Pod 最新所在节点上，这种情况下 ContainerCreating 的时间相对长一点，但一般最终是可以启动成功的，除非云厂商的 cloud-controller-manager 逻辑有 bug。\n命中 K8S 挂载 configmap/secret 的 subpath 的 bug 最近发现如果 Pod 挂载了 configmap 或 secret， 如果后面修改了 configmap 或 secret 的内容，Pod 里的容器又原地重启了(比如存活检查失败被 kill 然后重启拉起)，就会触发 K8S 的这个 bug，团队的小伙伴已提 PR: https://github.com/kubernetes/kubernetes/pull/82784\n如果是这种情况，容器会一直启动不成功，可以看到类似以下的报错:\n$ kubectl -n prod get pod -o yaml manage-5bd487cf9d-bqmvm ... lastState: terminated containerID: containerd://e6746201faa1dfe7f3251b8c30d59ebf613d99715f3b800740e587e681d2a903 exitCode: 128 finishedAt: 2019-09-15T00:47:22Z message: \u0026#39;failed to create containerd task: OCI runtime create failed: container_linux.go:345: starting container process caused \u0026#34;process_linux.go:424: container init caused \\\u0026#34;rootfs_linux.go:58: mounting \\\\\\\u0026#34;/var/lib/kubelet/pods/211d53f4-d08c-11e9-b0a7-b6655eaf02a6/volume-subpaths/manage-config-volume/manage/0\\\\\\\u0026#34; to rootfs \\\\\\\u0026#34;/run/containerd/io.containerd.runtime.v1.linux/k8s.io/e6746201faa1dfe7f3251b8c30d59ebf613d99715f3b800740e587e681d2a903/rootfs\\\\\\\u0026#34; at \\\\\\\u0026#34;/run/containerd/io.containerd.runtime.v1.linux/k8s.io/e6746201faa1dfe7f3251b8c30d59ebf613d99715f3b800740e587e681d2a903/rootfs/app/resources/application.properties\\\\\\\u0026#34; caused \\\\\\\u0026#34;no such file or directory\\\\\\\u0026#34;\\\u0026#34;\u0026#34;: unknown\u0026#39; 磁盘爆满 启动 Pod 会调 CRI 接口创建容器，容器运行时创建容器时通常会在数据目录下为新建的容器创建一些目录和文件，如果数据目录所在的磁盘空间满了就会创建失败并报错:\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedCreatePodSandBox 2m (x4307 over 16h) kubelet, 10.179.80.31 (combined from similar events): Failed create pod sandbox: rpc error: code = Unknown desc = failed to create a sandbox for pod \u0026#34;apigateway-6dc48bf8b6-l8xrw\u0026#34;: Error response from daemon: mkdir /var/lib/docker/aufs/mnt/1f09d6c1c9f24e8daaea5bf33a4230de7dbc758e3b22785e8ee21e3e3d921214-init: no space left on device 解决方法参考本书 处理实践：磁盘爆满\n节点内存碎片化 如果节点上内存碎片化严重，缺少大页内存，会导致即使总的剩余内存较多，但还是会申请内存失败，参考 处理实践: 内存碎片化\nlimit 设置太小或者单位不对 如果 limit 设置过小以至于不足以成功运行 Sandbox 也会造成这种状态，常见的是因为 memory limit 单位设置不对造成的 limit 过小，比如误将 memory 的 limit 单位像 request 一样设置为小 m，这个单位在 memory 不适用，会被 k8s 识别成 byte， 应该用 Mi 或 M。，\n举个例子: 如果 memory limit 设为 1024m 表示限制 1.024 Byte，这么小的内存， pause 容器一起来就会被 cgroup-oom kill 掉，导致 pod 状态一直处于 ContainerCreating。\n这种情况通常会报下面的 event:\nPod sandbox changed, it will be killed and re-created。 kubelet 报错:\nto start sandbox container for pod ... Error response from daemon: OCI runtime create failed: container_linux.go:348: starting container process caused \u0026#34;process_linux.go:301: running exec setns process for init caused \\\u0026#34;signal: killed\\\u0026#34;\u0026#34;: unknown 拉取镜像失败 镜像拉取失败也分很多情况，这里列举下:\n 配置了错误的镜像 Kubelet 无法访问镜像仓库（比如默认 pause 镜像在 gcr.io 上，国内环境访问需要特殊处理） 拉取私有镜像的 imagePullSecret 没有配置或配置有误 镜像太大，拉取超时（可以适当调整 kubelet 的 \u0026ndash;image-pull-progress-deadline 和 \u0026ndash;runtime-request-timeout 选项）  CNI 网络错误 如果发生 CNI 网络错误通常需要检查下网络插件的配置和运行状态，如果没有正确配置或正常运行通常表现为:\n 无法配置 Pod 网络 无法分配 Pod IP  controller-manager 异常 查看 master 上 kube-controller-manager 状态，异常的话尝试重启。\n安装 docker 没删干净旧版本 如果节点上本身有 docker 或者没删干净，然后又安装 docker，比如在 centos 上用 yum 安装:\nyum install -y docker 这样可能会导致 dockerd 创建容器一直不成功，从而 Pod 状态一直 ContainerCreating，查看 event 报错:\n Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedCreatePodSandBox 18m (x3583 over 83m) kubelet, 192.168.4.5 (combined from similar events): Failed create pod sandbox: rpc error: code = Unknown desc = failed to start sandbox container for pod \u0026quot;nginx-7db9fccd9b-2j6dh\u0026quot;: Error response from daemon: ttrpc: client shutting down: read unix @-\u0026gt;@/containerd-shim/moby/de2bfeefc999af42783115acca62745e6798981dff75f4148fae8c086668f667/shim.sock: read: connection reset by peer: unknown Normal SandboxChanged 3m12s (x4420 over 83m) kubelet, 192.168.4.5 Pod sandbox changed, it will be killed and re-created. 可能是因为重复安装 docker 版本不一致导致一些组件之间不兼容，从而导致 dockerd 无法正常创建容器。\n存在同名容器 如果节点上已有同名容器，创建 sandbox 就会失败，event:\n Warning FailedCreatePodSandBox 2m kubelet, 10.205.8.91 Failed create pod sandbox: rpc error: code = Unknown desc = failed to create a sandbox for pod \u0026quot;lomp-ext-d8c8b8c46-4v8tl\u0026quot;: operation timeout: context deadline exceeded Warning FailedCreatePodSandBox 3s (x12 over 2m) kubelet, 10.205.8.91 Failed create pod sandbox: rpc error: code = Unknown desc = failed to create a sandbox for pod \u0026quot;lomp-ext-d8c8b8c46-4v8tl\u0026quot;: Error response from daemon: Conflict. The container name \u0026quot;/k8s_POD_lomp-ext-d8c8b8c46-4v8tl_default_65046a06-f795-11e9-9bb6-b67fb7a70bad_0\u0026quot; is already in use by container \u0026quot;30aa3f5847e0ce89e9d411e76783ba14accba7eb7743e605a10a9a862a72c1e2\u0026quot;. You have to remove (or rename) that container to be able to reuse that name. 关于什么情况下会产生同名容器，这个有待研究。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-error/",
	"title": "Pod 一直处于 Error 状态",
	"tags": [],
	"description": "",
	"content": "TODO: 展开优化\n通常处于 Error 状态说明 Pod 启动过程中发生了错误。常见的原因包括：\n 依赖的 ConfigMap、Secret 或者 PV 等不存在 请求的资源超过了管理员设置的限制，比如超过了 LimitRange 等 违反集群的安全策略，比如违反了 PodSecurityPolicy 等 容器无权操作集群内的资源，比如开启 RBAC 后，需要为 ServiceAccount 配置角色绑定  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-imageinspecterror/",
	"title": "Pod 一直处于 ImageInspectError 状态",
	"tags": [],
	"description": "",
	"content": "通常是镜像文件损坏了，可以尝试删除损坏的镜像重新拉取\nTODO: 完善\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-imagepullbackoff/",
	"title": "Pod 一直处于 ImagePullBackOff 状态",
	"tags": [],
	"description": "",
	"content": "http 类型 registry，地址未加入到 insecure-registry dockerd 默认从 https 类型的 registry 拉取镜像，如果使用 https 类型的 registry，则必须将它添加到 insecure-registry 参数中，然后重启或 reload dockerd 生效。\nhttps 自签发类型 resitry，没有给节点添加 ca 证书 如果 registry 是 https 类型，但证书是自签发的，dockerd 会校验 registry 的证书，校验成功才能正常使用镜像仓库，要想校验成功就需要将 registry 的 ca 证书放置到 /etc/docker/certs.d/\u0026lt;registry:port\u0026gt;/ca.crt 位置。\n私有镜像仓库认证失败 如果 registry 需要认证，但是 Pod 没有配置 imagePullSecret，配置的 Secret 不存在或者有误都会认证失败。\n镜像文件损坏 如果 push 的镜像文件损坏了，下载下来也用不了，需要重新 push 镜像文件。\n镜像拉取超时 如果节点上新起的 Pod 太多就会有许多可能会造成容器镜像下载排队，如果前面有许多大镜像需要下载很长时间，后面排队的 Pod 就会报拉取超时。\nkubelet 默认串行下载镜像:\n--serialize-image-pulls Pull images one at a time. We recommend *not* changing the default value on nodes that run docker daemon with version \u0026lt; 1.9 or an Aufs storage backend. Issue #10959 has more details. (default true) 也可以开启并行下载并控制并发:\n--registry-qps int32 If \u0026gt; 0, limit registry pull QPS to this value. If 0, unlimited. (default 5) --registry-burst int32 Maximum size of a bursty pulls, temporarily allows pulls to burst to this number, while still not exceeding registry-qps. Only used if --registry-qps \u0026gt; 0 (default 10) 镜像不不存在 kubelet 日志:\nPullImage \u0026#34;imroc/test:v0.2\u0026#34; from image service failed: rpc error: code = Unknown desc = Error response from daemon: manifest for imroc/test:v0.2 not found "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-pending/",
	"title": "Pod 一直处于 Pending 状态",
	"tags": [],
	"description": "",
	"content": "Pending 状态说明 Pod 还没有被调度到某个节点上，需要看下 Pod 事件进一步判断原因，比如:\n$ kubectl describe pod tikv-0 ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 3m (x106 over 33m) default-scheduler 0/4 nodes are available: 1 node(s) had no available volume zone, 2 Insufficient cpu, 3 Insufficient memory. 下面列举下可能原因和解决方法。\n节点资源不够 节点资源不够有以下几种情况:\n CPU 负载过高 剩余可以被分配的内存不够 剩余可用 GPU 数量不够 (通常在机器学习场景，GPU 集群环境)  如果判断某个 Node 资源是否足够？ 通过 kubectl describe node \u0026lt;node-name\u0026gt; 查看 node 资源情况，关注以下信息：\n Allocatable: 表示此节点能够申请的资源总和 Allocated resources: 表示此节点已分配的资源 (Allocatable 减去节点上所有 Pod 总的 Request)  前者与后者相减，可得出剩余可申请的资源。如果这个值小于 Pod 的 request，就不满足 Pod 的资源要求，Scheduler 在 Predicates (预选) 阶段就会剔除掉这个 Node，也就不会调度上去。\n不满足 nodeSelector 与 affinity 如果 Pod 包含 nodeSelector 指定了节点需要包含的 label，调度器将只会考虑将 Pod 调度到包含这些 label 的 Node 上，如果没有 Node 有这些 label 或者有这些 label 的 Node 其它条件不满足也将会无法调度。参考官方文档：https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\n如果 Pod 包含 affinity（亲和性）的配置，调度器根据调度算法也可能算出没有满足条件的 Node，从而无法调度。affinity 有以下几类:\n nodeAffinity: 节点亲和性，可以看成是增强版的 nodeSelector，用于限制 Pod 只允许被调度到某一部分 Node。 podAffinity: Pod 亲和性，用于将一些有关联的 Pod 调度到同一个地方，同一个地方可以是指同一个节点或同一个可用区的节点等。 podAntiAffinity: Pod 反亲和性，用于避免将某一类 Pod 调度到同一个地方避免单点故障，比如将集群 DNS 服务的 Pod 副本都调度到不同节点，避免一个节点挂了造成整个集群 DNS 解析失败，使得业务中断。  Node 存在 Pod 没有容忍的污点 如果节点上存在污点 (Taints)，而 Pod 没有响应的容忍 (Tolerations)，Pod 也将不会调度上去。通过 describe node 可以看下 Node 有哪些 Taints:\n$ kubectl describe nodes host1 ... Taints: special=true:NoSchedule ... 污点既可以是手动添加也可以是被自动添加，下面来深入分析一下。\n手动添加的污点 通过类似以下方式可以给节点添加污点:\n$ kubectl taint node host1 special=true:NoSchedule node \u0026#34;host1\u0026#34; tainted 另外，有些场景下希望新加的节点默认不调度 Pod，直到调整完节点上某些配置才允许调度，就给新加的节点都加上 node.kubernetes.io/unschedulable 这个污点。\n自动添加的污点 如果节点运行状态不正常，污点也可以被自动添加，从 v1.12 开始，TaintNodesByCondition 特性进入 Beta 默认开启，controller manager 会检查 Node 的 Condition，如果命中条件就自动为 Node 加上相应的污点，这些 Condition 与 Taints 的对应关系如下:\nConditon Value Taints -------- ----- ------ OutOfDisk True node.kubernetes.io/out-of-disk Ready False node.kubernetes.io/not-ready Ready Unknown node.kubernetes.io/unreachable MemoryPressure True node.kubernetes.io/memory-pressure PIDPressure True node.kubernetes.io/pid-pressure DiskPressure True node.kubernetes.io/disk-pressure NetworkUnavailable True node.kubernetes.io/network-unavailable 解释下上面各种条件的意思:\n OutOfDisk 为 True 表示节点磁盘空间不够了 Ready 为 False 表示节点不健康 Ready 为 Unknown 表示节点失联，在 node-monitor-grace-period 这么长的时间内没有上报状态 controller-manager 就会将 Node 状态置为 Unknown (默认 40s) MemoryPressure 为 True 表示节点内存压力大，实际可用内存很少 PIDPressure 为 True 表示节点上运行了太多进程，PID 数量不够用了 DiskPressure 为 True 表示节点上的磁盘可用空间太少了 NetworkUnavailable 为 True 表示节点上的网络没有正确配置，无法跟其它 Pod 正常通信  另外，在云环境下，比如腾讯云 TKE，添加新节点会先给这个 Node 加上 node.cloudprovider.kubernetes.io/uninitialized 的污点，等 Node 初始化成功后才自动移除这个污点，避免 Pod 被调度到没初始化好的 Node 上。\n低版本 kube-scheduler 的 bug 可能是低版本 kube-scheduler 的 bug, 可以升级下调度器版本。\nkube-scheduler 没有正常运行 检查 maser 上的 kube-scheduler 是否运行正常，异常的话可以尝试重启临时恢复。\n驱逐后其它可用节点与当前节点有状态应用不在同一个可用区 有时候服务部署成功运行过，但在某个时候节点突然挂了，此时就会触发驱逐，创建新的副本调度到其它节点上，对于已经挂载了磁盘的 Pod，它通常需要被调度到跟当前节点和磁盘在同一个可用区，如果集群中同一个可用区的节点不满足调度条件，即使其它可用区节点各种条件都满足，但不跟当前节点在同一个可用区，也是不会调度的。为什么需要限制挂载了磁盘的 Pod 不能漂移到其它可用区的节点？试想一下，云上的磁盘虽然可以被动态挂载到不同机器，但也只是相对同一个数据中心，通常不允许跨数据中心挂载磁盘设备，因为网络时延会极大的降低 IO 速率。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-terminating/",
	"title": "Pod 一直处于 Terminating 状态",
	"tags": [],
	"description": "",
	"content": "磁盘爆满 如果 docker 的数据目录所在磁盘被写满，docker 无法正常运行，无法进行删除和创建操作，所以 kubelet 调用 docker 删除容器没反应，看 event 类似这样：\nNormal Killing 39s (x735 over 15h) kubelet, 10.179.80.31 Killing container with id docker://apigateway:Need to kill Pod 处理建议是参考本书 处理实践：磁盘爆满\n存在 \u0026ldquo;i\u0026rdquo; 文件属性 如果容器的镜像本身或者容器启动后写入的文件存在 \u0026ldquo;i\u0026rdquo; 文件属性，此文件就无法被修改删除，而删除 Pod 时会清理容器目录，但里面包含有不可删除的文件，就一直删不了，Pod 状态也将一直保持 Terminating，kubelet 报错:\nSep 27 14:37:21 VM_0_7_centos kubelet[14109]: E0927 14:37:21.922965 14109 remote_runtime.go:250] RemoveContainer \u0026quot;19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\u0026quot; from runtime service failed: rpc error: code = Unknown desc = failed to remove container \u0026quot;19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\u0026quot;: Error response from daemon: container 19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257: driver \u0026quot;overlay2\u0026quot; failed to remove root filesystem: remove /data/docker/overlay2/b1aea29c590aa9abda79f7cf3976422073fb3652757f0391db88534027546868/diff/usr/bin/bash: operation not permitted Sep 27 14:37:21 VM_0_7_centos kubelet[14109]: E0927 14:37:21.923027 14109 kuberuntime_gc.go:126] Failed to remove container \u0026quot;19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\u0026quot;: rpc error: code = Unknown desc = failed to remove container \u0026quot;19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257\u0026quot;: Error response from daemon: container 19d837c77a3c294052a99ff9347c520bc8acb7b8b9a9dc9fab281fc09df38257: driver \u0026quot;overlay2\u0026quot; failed to remove root filesystem: remove /data/docker/overlay2/b1aea29c590aa9abda79f7cf3976422073fb3652757f0391db88534027546868/diff/usr/bin/bash: operation not permitted 通过 man chattr 查看 \u0026ldquo;i\u0026rdquo; 文件属性描述:\nA file with the \u0026#39;i\u0026#39; attribute cannot be modified: it cannot be deleted or renamed, no link can be created to this file and no data can be written to the file. Only the superuser or a process possessing the CAP_LINUX_IMMUTABLE capability can set or clear this attribute. 彻底解决当然是不要在容器镜像中或启动后的容器设置 \u0026ldquo;i\u0026rdquo; 文件属性，临时恢复方法： 复制 kubelet 日志报错提示的文件路径，然后执行 chattr -i \u0026lt;file\u0026gt;:\nchattr -i /data/docker/overlay2/b1aea29c590aa9abda79f7cf3976422073fb3652757f0391db88534027546868/diff/usr/bin/bash 执行完后等待 kubelet 自动重试，Pod 就可以被自动删除了。\ndocker 17 的 bug docker hang 住，没有任何响应，看 event:\nWarning FailedSync 3m (x408 over 1h) kubelet, 10.179.80.31 error determining status: rpc error: code = DeadlineExceeded desc = context deadline exceeded 怀疑是17版本dockerd的BUG。可通过 kubectl -n cn-staging delete pod apigateway-6dc48bf8b6-clcwk --force --grace-period=0 强制删除pod，但 docker ps 仍看得到这个容器\n处置建议：\n 升级到docker 18. 该版本使用了新的 containerd，针对很多bug进行了修复。 如果出现terminating状态的话，可以提供让容器专家进行排查，不建议直接强行删除，会可能导致一些业务上问题。  存在 Finalizers k8s 资源的 metadata 里如果存在 finalizers，那么该资源一般是由某程序创建的，并且在其创建的资源的 metadata 里的 finalizers 加了一个它的标识，这意味着这个资源被删除时需要由创建资源的程序来做删除前的清理，清理完了它需要将标识从该资源的 finalizers 中移除，然后才会最终彻底删除资源。比如 Rancher 创建的一些资源就会写入 finalizers 标识。\n处理建议：kubectl edit 手动编辑资源定义，删掉 finalizers，这时再看下资源，就会发现已经删掉了\n低版本 kubelet list-watch 的 bug 之前遇到过使用 v1.8.13 版本的 k8s，kubelet 有时 list-watch 出问题，删除 pod 后 kubelet 没收到事件，导致 kubelet 一直没做删除操作，所以 pod 状态一直是 Terminating\ndockerd 与 containerd 的状态不同步 判断 dockerd 与 containerd 某个容器的状态不同步的方法：\n describe pod 拿到容器 id docker ps 查看的容器状态是 dockerd 中保存的状态 通过 docker-container-ctr 查看容器在 containerd 中的状态，比如: $ docker-container-ctr --namespace moby --address /var/run/docker/containerd/docker-containerd.sock task ls |grep a9a1785b81343c3ad2093ad973f4f8e52dbf54823b8bb089886c8356d4036fe0 a9a1785b81343c3ad2093ad973f4f8e52dbf54823b8bb089886c8356d4036fe0 30639 STOPPED   containerd 看容器状态是 stopped 或者已经没有记录，而 docker 看容器状态却是 runing，说明 dockerd 与 containerd 之间容器状态同步有问题，目前发现了 docker 在 aufs 存储驱动下如果磁盘爆满可能发生内核 panic :\naufs au_opts_verify:1597:dockerd[5347]: dirperm1 breaks the protection by the permission bits on the lower branch 如果磁盘爆满过，dockerd 一般会有下面类似的日志:\nSep 18 10:19:49 VM-1-33-ubuntu dockerd[4822]: time=\u0026quot;2019-09-18T10:19:49.903943652+08:00\u0026quot; level=error msg=\u0026quot;Failed to log msg \\\u0026quot;\\\u0026quot; for logger json-file: write /opt/docker/containers/54922ec8b1863bcc504f6dac41e40139047f7a84ff09175d2800100aaccbad1f/54922ec8b1863bcc504f6dac41e40139047f7a84ff09175d2800100aaccbad1f-json.log: no space left on device\u0026quot; 随后可能发生状态不同步，已提issue: https://github.com/docker/for-linux/issues/779\n 临时恢复: 执行 docker prune 或重启 dockerd 长期方案: 运行时推荐直接使用 containerd，绕过 dockerd 避免 docker 本身的各种 BUG  Daemonset Controller 的 BUG 有个 k8s 的 bug 会导致 daemonset pod 无限 terminating，1.10 和 1.11 版本受影响，原因是 daemonset controller 复用 scheduler 的 predicates 逻辑，里面将 nodeAffinity 的 nodeSelector 数组做了排序（传的指针），spec 就会跟 apiserver 中的不一致，daemonset controller 又会为 rollingUpdate类型计算 hash (会用到spec)，用于版本控制，造成不一致从而无限启动和停止的循环。\n issue: https://github.com/kubernetes/kubernetes/issues/66298 修复的PR: https://github.com/kubernetes/kubernetes/pull/66480  升级集群版本可以彻底解决，临时规避可以给 rollingUpdate 类型 daemonset 不使用 nodeAffinity，改用 nodeSelector。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-unkown/",
	"title": "Pod 一直处于 Unknown 状态",
	"tags": [],
	"description": "",
	"content": "TODO: 完善\n通常是节点失联，没有上报状态给 apiserver，到达阀值后 controller-manager 认为节点失联并将其状态置为 Unknown。\n可能原因:\n 节点高负载导致无法上报 节点宕机 节点被关机 网络不通  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/healthcheck-failed/",
	"title": "Pod 健康检查失败",
	"tags": [],
	"description": "",
	"content": " Kubernetes 健康检查包含就绪检查(readinessProbe)和存活检查(livenessProbe) pod 如果就绪检查失败会将此 pod ip 从 service 中摘除，通过 service 访问，流量将不会被转发给就绪检查失败的 pod pod 如果存活检查失败，kubelet 将会杀死容器并尝试重启  健康检查失败的可能原因有多种，除了业务程序BUG导致不能响应健康检查导致 unhealthy，还能有有其它原因，下面我们来逐个排查。\n健康检查配置不合理 initialDelaySeconds 太短，容器启动慢，导致容器还没完全启动就开始探测，如果 successThreshold 是默认值 1，检查失败一次就会被 kill，然后 pod 一直这样被 kill 重启。\n节点负载过高 cpu 占用高（比如跑满）会导致进程无法正常发包收包，通常会 timeout，导致 kubelet 认为 pod 不健康。参考本书 处理实践: 高负载 一节。\n容器进程被木马进程杀死 参考本书 处理实践: 使用 systemtap 定位疑难杂症 进一步定位。\n容器内进程端口监听挂掉 使用 netstat -tunlp 检查端口监听是否还在，如果不在了，抓包可以看到会直接 reset 掉健康检查探测的连接:\n20:15:17.890996 IP 172.16.2.1.38074 \u0026gt; 172.16.2.23.8888: Flags [S], seq 96880261, win 14600, options [mss 1424,nop,nop,sackOK,nop,wscale 7], length 0 20:15:17.891021 IP 172.16.2.23.8888 \u0026gt; 172.16.2.1.38074: Flags [R.], seq 0, ack 96880262, win 0, length 0 20:15:17.906744 IP 10.0.0.16.54132 \u0026gt; 172.16.2.23.8888: Flags [S], seq 1207014342, win 14600, options [mss 1424,nop,nop,sackOK,nop,wscale 7], length 0 20:15:17.906766 IP 172.16.2.23.8888 \u0026gt; 10.0.0.16.54132: Flags [R.], seq 0, ack 1207014343, win 0, length 0 连接异常，从而健康检查失败。发生这种情况的原因可能在一个节点上启动了多个使用 hostNetwork 监听相同宿主机端口的 Pod，只会有一个 Pod 监听成功，但监听失败的 Pod 的业务逻辑允许了监听失败，并没有退出，Pod 又配了健康检查，kubelet 就会给 Pod 发送健康检查探测报文，但 Pod 由于没有监听所以就会健康检查失败。\nSYN backlog 设置过小 SYN backlog 大小即 SYN 队列大小，如果短时间内新建连接比较多，而 SYN backlog 设置太小，就会导致新建连接失败，通过 netstat -s | grep TCPBacklogDrop 可以看到有多少是因为 backlog 满了导致丢弃的新连接。\n如果确认是 backlog 满了导致的丢包，建议调高 backlog 的值，内核参数为 net.ipv4.tcp_max_syn_backlog。\n"
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/livenesprobe-failed-occasionally/",
	"title": "Pod 偶尔存活检查失败",
	"tags": [],
	"description": "",
	"content": "现象: Pod 偶尔会存活检查失败，导致 Pod 重启，业务偶尔连接异常。\n之前从未遇到这种情况，在自己测试环境尝试复现也没有成功，只有在用户这个环境才可以复现。这个用户环境流量较大，感觉跟连接数或并发量有关。\n用户反馈说在友商的环境里没这个问题。\n对比友商的内核参数发现有些区别，尝试将节点内核参数改成跟友商的一样，发现问题没有复现了。\n再对比分析下内核参数差异，最后发现是 backlog 太小导致的，节点的 net.ipv4.tcp_max_syn_backlog 默认是 1024，如果短时间内并发新建 TCP 连接太多，SYN 队列就可能溢出，导致部分新连接无法建立。\n解释一下:\nTCP 连接建立会经过三次握手，server 收到 SYN 后会将连接加入 SYN 队列，当收到最后一个 ACK 后连接建立，这时会将连接从 SYN 队列中移动到 ACCEPT 队列。在 SYN 队列中的连接都是没有建立完全的连接，处于半连接状态。如果 SYN 队列比较小，而短时间内并发新建的连接比较多，同时处于半连接状态的连接就多，SYN 队列就可能溢出，tcp_max_syn_backlog 可以控制 SYN 队列大小，用户节点的 backlog 大小默认是 1024，改成 8096 后就可以解决问题。\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/keep-crashloopbackoff/",
	"title": "Pod 处于 CrashLoopBackOff 状态",
	"tags": [],
	"description": "",
	"content": "Pod 如果处于 CrashLoopBackOff 状态说明之前是启动了，只是又异常退出了，只要 Pod 的 restartPolicy 不是 Never 就可能被重启拉起，此时 Pod 的 RestartCounts 通常是大于 0 的，可以先看下容器进程的退出状态码来缩小问题范围，参考本书 排错技巧: 分析 ExitCode 定位 Pod 异常退出原因\n容器进程主动退出 如果是容器进程主动退出，退出状态码一般在 0-128 之间，除了可能是业务程序 BUG，还有其它许多可能原因，参考: 容器进程主动退出\n系统 OOM 如果发生系统 OOM，可以看到 Pod 中容器退出状态码是 137，表示被 SIGKILL 信号杀死，同时内核会报错: Out of memory: Kill process ...。大概率是节点上部署了其它非 K8S 管理的进程消耗了比较多的内存，或者 kubelet 的 --kube-reserved 和 --system-reserved 配的比较小，没有预留足够的空间给其它非容器进程，节点上所有 Pod 的实际内存占用总量不会超过 /sys/fs/cgroup/memory/kubepods 这里 cgroup 的限制，这个限制等于 capacity - \u0026quot;kube-reserved\u0026quot; - \u0026quot;system-reserved\u0026quot;，如果预留空间设置合理，节点上其它非容器进程（kubelet, dockerd, kube-proxy, sshd 等) 内存占用没有超过 kubelet 配置的预留空间是不会发生系统 OOM 的，可以根据实际需求做合理的调整。\ncgroup OOM 如果是 cgrou OOM 杀掉的进程，从 Pod 事件的下 Reason 可以看到是 OOMKilled，说明容器实际占用的内存超过 limit 了，同时内核日志会报: ``。 可以根据需求调整下 limit。\n节点内存碎片化 如果节点上内存碎片化严重，缺少大页内存，会导致即使总的剩余内存较多，但还是会申请内存失败，参考 处理实践: 内存碎片化\n健康检查失败 参考 Pod 健康检查失败 进一步定位。\n"
},
{
	"uri": "https://k8s.imroc.io/trick/shell/pod/",
	"title": "Pod 相关脚本",
	"tags": [],
	"description": "",
	"content": "清理 Evicted 的 pod kubectl get pod -o wide --all-namespaces | awk \u0026#39;{if($4==\u0026#34;Evicted\u0026#34;){cmd=\u0026#34;kubectl -n \u0026#34;$1\u0026#34; delete pod \u0026#34;$2; system(cmd)}}\u0026#39; 清理非 Running 的 pod kubectl get pod -o wide --all-namespaces | awk \u0026#39;{if($4!=\u0026#34;Running\u0026#34;){cmd=\u0026#34;kubectl -n \u0026#34;$1\u0026#34; delete pod \u0026#34;$2; system(cmd)}}\u0026#39; 升级镜像 NAMESPACE=\u0026#34;kube-system\u0026#34; WORKLOAD_TYPE=\u0026#34;daemonset\u0026#34; WORKLOAD_NAME=\u0026#34;ip-masq-agent\u0026#34; CONTAINER_NAME=\u0026#34;ip-masq-agent\u0026#34; IMAGE=\u0026#34;ccr.ccs.tencentyun.com/library/ip-masq-agent:v2.5.0\u0026#34; kubectl -n $NAMESPACE patch $WORKLOAD_TYPE $WORKLOAD_NAME --patch \u0026#39;{\u0026#34;spec\u0026#34;: {\u0026#34;template\u0026#34;: {\u0026#34;spec\u0026#34;: {\u0026#34;containers\u0026#34;: [{\u0026#34;name\u0026#34;: \u0026#34;$CONTAINER_NAME\u0026#34;,\u0026#34;image\u0026#34;: \u0026#34;$IMAGE\u0026#34; }]}}}}\u0026#39; "
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/high-legacy-from-pod-to-another-apiserver/",
	"title": "Pod 访问另一个集群的 apiserver 有延时",
	"tags": [],
	"description": "",
	"content": "现象：集群 a 的 Pod 内通过 kubectl 访问集群 b 的内网地址，偶尔出现延时的情况，但直接在宿主机上用同样的方法却没有这个问题。\n提炼环境和现象精髓:\n 在 pod 内将另一个集群 apiserver 的 ip 写到了 hosts，因为 TKE apiserver 开启内网集群外内网访问创建的内网 LB 暂时没有支持自动绑内网 DNS 域名解析，所以集群外的内网访问 apiserver 需要加 hosts pod 内执行 kubectl 访问另一个集群偶尔延迟 5s，有时甚至10s  观察到 5s 延时，感觉跟之前 conntrack 的丢包导致 DNS 解析 5S 延时 有关，但是加了 hosts 呀，怎么还去解析域名？\n进入 pod netns 抓包: 执行 kubectl 时确实有 dns 解析，并且发生延时的时候 dns 请求没有响应然后做了重试。\n看起来延时应该就是之前已知 conntrack 丢包导致 dns 5s 超时重试导致的。但是为什么会去解析域名? 明明配了 hosts 啊，正常情况应该是优先查找 hosts，没找到才去请求 dns 呀，有什么配置可以控制查找顺序?\n搜了一下发现: /etc/nsswitch.conf 可以控制，但看有问题的 pod 里没有这个文件。然后观察到有问题的 pod 用的 alpine 镜像，试试其它镜像后发现只有基于 alpine 的镜像才会有这个问题。\n再一搜发现: musl libc 并不会使用 /etc/nsswitch.conf ，也就是说 alpine 镜像并没有实现用这个文件控制域名查找优先顺序，瞥了一眼 musl libc 的 gethostbyname 和 getaddrinfo 的实现，看起来也没有读这个文件来控制查找顺序，写死了先查 hosts，没找到再查 dns。\n这么说，那还是该先查 hosts 再查 dns 呀，为什么这里抓包看到是先查的 dns? (如果是先查 hosts 就能命中查询，不会再发起dns请求)\n访问 apiserver 的 client 是 kubectl，用 go 写的，会不会是 go 程序解析域名时压根没调底层 c 库的 gethostbyname 或 getaddrinfo?\n搜一下发现果然是这样: go runtime 用 go 实现了 glibc 的 getaddrinfo 的行为来解析域名，减少了 c 库调用 (应该是考虑到减少 cgo 调用带来的的性能损耗)\nissue: net: replicate DNS resolution behaviour of getaddrinfo(glibc) in the go dns resolver\n翻源码验证下:\nUnix 系的 OS 下，除了 openbsd， go runtime 会读取 /etc/nsswitch.conf (net/conf.go):\nif runtime.GOOS != \u0026#34;openbsd\u0026#34; { confVal.nss = parseNSSConfFile(\u0026#34;/etc/nsswitch.conf\u0026#34;) } hostLookupOrder 函数决定域名解析顺序的策略，Linux 下，如果没有 nsswitch.conf 文件就 dns 比 hosts 文件优先 (net/conf.go):\n// hostLookupOrder determines which strategy to use to resolve hostname. // The provided Resolver is optional. nil means to not consider its options. func (c *conf) hostLookupOrder(r *Resolver, hostname string) (ret hostLookupOrder) { ...... // If /etc/nsswitch.conf doesn\u0026#39;t exist or doesn\u0026#39;t specify any \t// sources for \u0026#34;hosts\u0026#34;, assume Go\u0026#39;s DNS will work fine. \tif os.IsNotExist(nss.err) || (nss.err == nil \u0026amp;\u0026amp; len(srcs) == 0) { ...... if c.goos == \u0026#34;linux\u0026#34; { // glibc says the default is \u0026#34;dns [!UNAVAIL=return] files\u0026#34; \t// https://www.gnu.org/software/libc/manual/html_node/Notes-on-NSS-Configuration-File.html. \treturn hostLookupDNSFiles } return hostLookupFilesDNS } 可以看到 hostLookupDNSFiles 的意思是 dns first (net/dnsclient_unix.go):\n// hostLookupOrder specifies the order of LookupHost lookup strategies. // It is basically a simplified representation of nsswitch.conf. // \u0026#34;files\u0026#34; means /etc/hosts. type hostLookupOrder int const ( // hostLookupCgo means defer to cgo. \thostLookupCgo hostLookupOrder = iota hostLookupFilesDNS // files first \thostLookupDNSFiles // dns first \thostLookupFiles // only files \thostLookupDNS // only DNS ) var lookupOrderName = map[hostLookupOrder]string{ hostLookupCgo: \u0026#34;cgo\u0026#34;, hostLookupFilesDNS: \u0026#34;files,dns\u0026#34;, hostLookupDNSFiles: \u0026#34;dns,files\u0026#34;, hostLookupFiles: \u0026#34;files\u0026#34;, hostLookupDNS: \u0026#34;dns\u0026#34;, } 所以虽然 alpine 用的 musl libc 不是 glibc，但 go 程序解析域名还是一样走的 glibc 的逻辑，而 alpine 没有 /etc/nsswitch.conf 文件，也就解释了为什么 kubectl 访问 apiserver 先做 dns 解析，没解析到再查的 hosts，导致每次访问都去请求 dns，恰好又碰到 conntrack 那个丢包问题导致 dns 5s 延时，在用户这里表现就是 pod 内用 kubectl 访问 apiserver 偶尔出现 5s 延时，有时出现 10s 是因为重试的那次 dns 请求刚好也遇到 conntrack 丢包导致延时又叠加了 5s 。\n解决方案:\n 换基础镜像，不用 alpine 挂载 nsswitch.conf 文件 (可以用 hostPath)  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/network/service-unrecheable/",
	"title": "Service 不通",
	"tags": [],
	"description": "",
	"content": "集群 dns 故障 TODO\n节点防火墙没放开集群容器网络 (iptables/安全组) TODO\nkube-proxy 没有工作，命中 netlink deadlock 的 bug  issue: https://github.com/kubernetes/kubernetes/issues/71071 1.14 版本已修复，修复的 PR: https://github.com/kubernetes/kubernetes/pull/72361  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/network/service-cannot-resolve/",
	"title": "Service 无法解析",
	"tags": [],
	"description": "",
	"content": "集群 DNS 没有正常运行(kube-dns或CoreDNS) 检查集群 DNS 是否运行正常:\n kubelet 启动参数 --cluster-dns 可以看到 dns 服务的 cluster ip:  $ ps -ef | grep kubelet ... /usr/bin/kubelet --cluster-dns=172.16.14.217 ...  找到 dns 的 service:  $ kubectl get svc -n kube-system | grep 172.16.14.217 kube-dns ClusterIP 172.16.14.217 \u0026lt;none\u0026gt; 53/TCP,53/UDP 47d  看是否存在 endpoint:  $ kubectl -n kube-system describe svc kube-dns | grep -i endpoints Endpoints: 172.16.0.156:53,172.16.0.167:53 Endpoints: 172.16.0.156:53,172.16.0.167:53  检查 endpoint 的 对应 pod 是否正常:  $ kubectl -n kube-system get pod -o wide | grep 172.16.0.156 kube-dns-898dbbfc6-hvwlr 3/3 Running 0 8d 172.16.0.156 10.0.0.3 Pod 与 DNS 服务之间网络不通 检查下 pod 是否连不上 dns 服务，可以在 pod 里 telnet 一下 dns 的 53 端口:\n# 连 dns service 的 cluster ip $ telnet 172.16.14.217 53 如果检查到是网络不通，就需要排查下网络设置:\n 检查节点的安全组设置，需要放开集群的容器网段 检查是否还有防火墙规则，检查 iptables  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/node/kernel-solft-lockup/",
	"title": "soft lockup (内核软死锁)",
	"tags": [],
	"description": "",
	"content": "内核报错 Oct 14 15:13:05 VM_1_6_centos kernel: NMI watchdog: BUG: soft lockup - CPU#5 stuck for 22s! [runc:[1:CHILD]:2274] 原因 发生这个报错通常是内核繁忙 (扫描、释放或分配大量对象)，分不出时间片给用户态进程导致的，也伴随着高负载，如果负载降低报错则会消失。\n什么情况下会导致内核繁忙  短时间内创建大量进程 (可能是业务需要，也可能是业务bug或用法不正确导致创建大量进程)  参考资料  What are all these \u0026ldquo;Bug: soft lockup\u0026rdquo; messages about : https://www.suse.com/support/kb/doc/?id=7017652  "
},
{
	"uri": "https://k8s.imroc.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/avoid/tcp_tw_recycle-causes-packet-loss/",
	"title": "tcp tw recycle 引发丢包",
	"tags": [],
	"description": "",
	"content": "tcp_tw_recycle 这个内核参数用来快速回收 TIME_WAIT 连接，不过如果在 NAT 环境下会引发问题。\nRFC1323 中有如下一段描述：\nAn additional mechanism could be added to the TCP, a per-host cache of the last timestamp received from any connection. This value could then be used in the PAWS mechanism to reject old duplicate segments from earlier incarnations of the connection, if the timestamp clock can be guaranteed to have ticked at least once since the old connection was open. This would require that the TIME-WAIT delay plus the RTT together must be at least one tick of the sender’s timestamp clock. Such an extension is not part of the proposal of this RFC.\n 大概意思是说TCP有一种行为，可以缓存每个连接最新的时间戳，后续请求中如果时间戳小于缓存的时间戳，即视为无效，相应的数据包会被丢弃。 Linux是否启用这种行为取决于tcp_timestamps和tcp_tw_recycle，因为tcp_timestamps缺省就是开启的，所以当tcp_tw_recycle被开启后，实际上这种行为就被激活了，当客户端或服务端以NAT方式构建的时候就可能出现问题，下面以客户端NAT为例来说明： 当多个客户端通过NAT方式联网并与服务端交互时，服务端看到的是同一个IP，也就是说对服务端而言这些客户端实际上等同于一个，可惜由于这些客户端的时间戳可能存在差异，于是乎从服务端的视角看，便可能出现时间戳错乱的现象，进而直接导致时间戳小的数据包被丢弃。如果发生了此类问题，具体的表现通常是是客户端明明发送的SYN，但服务端就是不响应ACK。 在4.12之后的内核已移除tcp_tw_recycle内核参数: https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4396e46187ca5070219b81773c4e65088dac50cc https://github.com/torvalds/linux/commit/4396e46187ca5070219b81773c4e65088dac50cc  "
},
{
	"uri": "https://k8s.imroc.io/cluster/ingress/traefik/",
	"title": "Traefik Ingress",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/trick/yaml/",
	"title": "yaml 片段",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/deploy/addons/kube-proxy/",
	"title": "以 Daemonset 方式部署 kube-proxy",
	"tags": [],
	"description": "",
	"content": "kube-proxy 可以用二进制部署，也可以用 kubelet 的静态 Pod 部署，但最简单使用 DaemonSet 部署。直接使用 ServiceAccount 的 token 认证，不需要签发证书，也就不用担心证书过期问题。\n先在终端设置下面的变量:\nAPISERVER=\u0026#34;https://10.200.16.79:6443\u0026#34; CLUSTER_CIDR=\u0026#34;10.10.0.0/16\u0026#34;  APISERVER 替换为 apiserver 对外暴露的访问地址。有同学想问为什么不直接用集群内的访问地址(kubernetes.default 或对应的 CLUSTER IP)，这是一个鸡生蛋还是蛋生鸡的问题，CLSUTER IP 本身就是由 kube-proxy 来生成 iptables 或 ipvs 规则转发 Service 对应 Endpoint 的 Pod IP，kube-proxy 刚启动还没有生成这些转发规则，生成规则的前提是 kube-proxy 需要访问 apiserver 获取 Service 与 Endpoint，而由于还没有转发规则，kube-proxy 访问 apiserver 的 CLUSTER IP 的请求无法被转发到 apiserver。 CLUSTER_CIDR 替换为集群 Pod IP 的 CIDR 范围，这个在部署 kube-controller-manager 时也设置过  为 kube-proxy 创建 RBAC 权限和配置文件:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: ServiceAccount metadata: name: kube-proxy namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: system:kube-proxy roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:node-proxier subjects: - kind: ServiceAccount name: kube-proxy namespace: kube-system --- kind: ConfigMap apiVersion: v1 metadata: name: kube-proxy namespace: kube-system labels: app: kube-proxy data: kubeconfig.conf: |- apiVersion: v1 kind: Config clusters: - cluster: certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt server: ${APISERVER} name: default contexts: - context: cluster: default namespace: default user: default name: default current-context: default users: - name: default user: tokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token config.conf: |- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration bindAddress: 0.0.0.0 clientConnection: acceptContentTypes: \u0026#34;\u0026#34; burst: 10 contentType: application/vnd.kubernetes.protobuf kubeconfig: /var/lib/kube-proxy/kubeconfig.conf qps: 5 # 集群中 Pod IP 的 CIDR 范围 clusterCIDR: ${CLUSTER_CIDR} configSyncPeriod: 15m0s conntrack: # 每个核心最大能跟踪的NAT连接数，默认32768 maxPerCore: 32768 min: 131072 tcpCloseWaitTimeout: 1h0m0s tcpEstablishedTimeout: 24h0m0s enableProfiling: false healthzBindAddress: 0.0.0.0:10256 iptables: # SNAT 所有 Service 的 CLUSTER IP masqueradeAll: false masqueradeBit: 14 minSyncPeriod: 0s syncPeriod: 30s ipvs: minSyncPeriod: 0s # ipvs 调度类型，默认是 rr，支持的所有类型: # rr: round-robin # lc: least connection # dh: destination hashing # sh: source hashing # sed: shortest expected delay # nq: never queue scheduler: rr syncPeriod: 30s metricsBindAddress: 0.0.0.0:10249 # 使用 ipvs 模式转发 service mode: ipvs # 设置 kube-proxy 进程的 oom-score-adj 值，范围 [-1000,1000] # 值越低越不容易被杀死，这里设置为 —999 防止发生系统OOM时将 kube-proxy 杀死 oomScoreAdj: -999 EOF 在终端设置下面的变量:\nARCH=\u0026#34;amd64\u0026#34; VERSION=\u0026#34;v1.16.1\u0026#34;  VERSION 是 K8S 版本 ARCH 是节点的 cpu 架构，大多数用的 amd64，即 x86_64。其它常见的还有: arm64, arm, ppc64le, s390x，如果你的集群有不同 cpu 架构的节点，可以分别指定 ARCH 部署多个 daemonset (每个节点不会有多个 kube-proxy，nodeSelector 会根据 cpu 架构来选中节点)  使用 hostNetwork 以 Daemonset 方式部署 kube-proxy 到每个节点:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: apps/v1 kind: DaemonSet metadata: labels: k8s-app: kube-proxy-ds-${ARCH} name: kube-proxy-ds-${ARCH} namespace: kube-system spec: selector: matchLabels: k8s-app: kube-proxy-ds-${ARCH} updateStrategy: type: RollingUpdate template: metadata: labels: k8s-app: kube-proxy-ds-${ARCH} spec: priorityClassName: system-node-critical containers: - name: kube-proxy image: k8s.gcr.io/kube-proxy-${ARCH}:${VERSION} imagePullPolicy: IfNotPresent command: - /usr/local/bin/kube-proxy - --config=/var/lib/kube-proxy/config.conf - --hostname-override=\\$(NODE_NAME) securityContext: privileged: true volumeMounts: - mountPath: /var/lib/kube-proxy name: kube-proxy - mountPath: /run/xtables.lock name: xtables-lock readOnly: false - mountPath: /lib/modules name: lib-modules readOnly: true env: - name: NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName hostNetwork: true serviceAccountName: kube-proxy volumes: - name: kube-proxy configMap: name: kube-proxy - name: xtables-lock hostPath: path: /run/xtables.lock type: FileOrCreate - name: lib-modules hostPath: path: /lib/modules tolerations: - key: CriticalAddonsOnly operator: Exists - operator: Exists nodeSelector: beta.kubernetes.io/arch: ${ARCH} EOF "
},
{
	"uri": "https://k8s.imroc.io/dev/client-go/",
	"title": "使用 client-go 开发 k8s 应用",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/avoid/nodelocal-dns/",
	"title": "使用 NodeLocal DNS (缓存)",
	"tags": [],
	"description": "",
	"content": "为什么需要本地 DNS 缓存   减轻集群 DNS 解析压力，提高 DNS 性能\n  避免 netfilter 做 DNAT 导致 conntrack 冲突引发 DNS 5 秒延时\n 镜像底层库 DNS 解析行为默认使用 UDP 在同一个 socket 并发 A 和 AAAA 记录请求，由于 UDP 无状态，两个请求可能会并发创建 conntrack 表项，如果最终 DNAT 成同一个集群 DNS 的 Pod IP 就会导致 conntrack 冲突，由于 conntrack 的创建和插入是不加锁的，最终后面插入的 conntrack 表项就会被丢弃，从而请求超时，默认 5s 后重试，造成现象就是 DNS 5 秒延时; 底层库是 glibc 的容器镜像可以通过配 resolv.conf 参数来控制 DNS 解析行为，不用 TCP 或者避免相同五元组并发(使用串行解析 A 和 AAAA 避免并发或者使用不同 socket 发请求避免相同源端口)，但像基于 alpine 镜像的容器由于底层库是 musl libc，不支持这些 resolv.conf 参数，也就无法规避，所以最佳方案还是使用本地 DNS 缓存。\n   原理 本地 DNS 缓存以 DaemonSet 方式在每个节点部署一个使用 hostNetwork 的 Pod，创建一个网卡绑上本地 DNS 的 IP，本机的 Pod 的 DNS 请求路由到本地 DNS，然后取缓存或者继续使用 TCP 请求上游集群 DNS 解析 (由于使用 TCP，同一个 socket 只会做一遍三次握手，不存在并发创建 conntrack 表项，也就不会有 conntrack 冲突)\nIPVS 模式下需要修改 kubelet 参数 有两点需要注意下:\n ipvs 模式下需要改 kubelet --cluster-dns 参数，指向一个非 kube-dns service 的 IP，通常用 169.254.20.10，Daemonset 会在每个节点创建一个网卡绑这个 IP，Pod 向本节点这个 IP 发 DNS 请求，本机 DNS 再代理到上游集群 DNS iptables 模式下不需要改 kubelet --cluster-dns 参数，Pod 还是向原来的集群 DNS 请求，节点上有这个 IP 监听，被本机拦截，再请求集群上游 DNS (使用集群 DNS 的另一个 CLUSTER IP，来自事先创建好的 Service，跟原集群 DNS 的 Service 有相同的 selector 和 endpoint)  ipvs 模式下必须修改 kubelet 参数的原因是：如果不修改，DaemonSet Pod 在本机创建了网卡，会绑跟集群 DNS 的 CLUSTER IP， 但 kube-ipvs0 这个 dummy interface 上也会绑这个 IP (这是 ipvs 的机制，为了能让报文到达 INPUT 链被 ipvs 处理)，所以 Pod 请求集群 DNS 的报文最终还是会被 ipvs 处理, DNAT 成集群 DNS 的 Pod IP，最终路由到集群 DNS，相当于本机 DNS 就没有作用了。\nIPVS 模式下部署方法 这里我们假设是 ipvs 模式，下面给出本地 DNS 缓存部署方法。\n创建 ServiceAccount 与集群上游 DNS 的 Service:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: ServiceAccount metadata: name: node-local-dns namespace: kube-system labels: kubernetes.io/cluster-service: \u0026#34;true\u0026#34; addonmanager.kubernetes.io/mode: Reconcile --- apiVersion: v1 kind: Service metadata: name: kube-dns-upstream namespace: kube-system labels: k8s-app: kube-dns kubernetes.io/cluster-service: \u0026#34;true\u0026#34; addonmanager.kubernetes.io/mode: Reconcile kubernetes.io/name: \u0026#34;KubeDNSUpstream\u0026#34; spec: ports: - name: dns port: 53 protocol: UDP targetPort: 53 - name: dns-tcp port: 53 protocol: TCP targetPort: 53 selector: k8s-app: kube-dns EOF 获取 kube-dns-upstream 的 CLUSTER IP:\nUPSTREAM_CLUSTER_IP=$(kubectl -n kube-system get services kube-dns-upstream -o jsonpath=\u0026#34;{.spec.clusterIP}\u0026#34;) 部署 DaemonSet:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: ConfigMap metadata: name: node-local-dns namespace: kube-system labels: addonmanager.kubernetes.io/mode: Reconcile data: Corefile: | cluster.local:53 { errors cache { success 9984 30 denial 9984 5 } reload loop bind 169.254.20.10 forward . ${UPSTREAM_CLUSTER_IP} { force_tcp } prometheus :9253 health 169.254.20.10:8080 } in-addr.arpa:53 { errors cache 30 reload loop bind 169.254.20.10 forward . ${UPSTREAM_CLUSTER_IP} { force_tcp } prometheus :9253 } ip6.arpa:53 { errors cache 30 reload loop bind 169.254.20.10 forward . ${UPSTREAM_CLUSTER_IP} { force_tcp } prometheus :9253 } .:53 { errors cache 30 reload loop bind 169.254.20.10 forward . /etc/resolv.conf { force_tcp } prometheus :9253 } --- apiVersion: apps/v1 kind: DaemonSet metadata: name: node-local-dns namespace: kube-system labels: k8s-app: node-local-dns kubernetes.io/cluster-service: \u0026#34;true\u0026#34; addonmanager.kubernetes.io/mode: Reconcile spec: updateStrategy: rollingUpdate: maxUnavailable: 10% selector: matchLabels: k8s-app: node-local-dns template: metadata: labels: k8s-app: node-local-dns spec: priorityClassName: system-node-critical serviceAccountName: node-local-dns hostNetwork: true dnsPolicy: Default # Don\u0026#39;t use cluster DNS. tolerations: - key: \u0026#34;CriticalAddonsOnly\u0026#34; operator: \u0026#34;Exists\u0026#34; containers: - name: node-cache image: k8s.gcr.io/k8s-dns-node-cache:1.15.7 resources: requests: cpu: 25m memory: 5Mi args: [ \u0026#34;-localip\u0026#34;, \u0026#34;169.254.20.10\u0026#34;, \u0026#34;-conf\u0026#34;, \u0026#34;/etc/Corefile\u0026#34;, \u0026#34;-upstreamsvc\u0026#34;, \u0026#34;kube-dns-upstream\u0026#34; ] securityContext: privileged: true ports: - containerPort: 53 name: dns protocol: UDP - containerPort: 53 name: dns-tcp protocol: TCP - containerPort: 9253 name: metrics protocol: TCP livenessProbe: httpGet: host: 169.254.20.10 path: /health port: 8080 initialDelaySeconds: 60 timeoutSeconds: 5 volumeMounts: - mountPath: /run/xtables.lock name: xtables-lock readOnly: false - name: config-volume mountPath: /etc/coredns - name: kube-dns-config mountPath: /etc/kube-dns volumes: - name: xtables-lock hostPath: path: /run/xtables.lock type: FileOrCreate - name: kube-dns-config configMap: name: kube-dns optional: true - name: config-volume configMap: name: node-local-dns items: - key: Corefile path: Corefile.base EOF 验证是否启动:\n$ kubectl -n kube-system get pod -o wide | grep node-local-dns node-local-dns-2m9b6 1/1 Running 0 15m 10.0.0.28 10.0.0.28 node-local-dns-qgrwl 1/1 Running 0 15m 10.0.0.186 10.0.0.186 node-local-dns-s5mhw 1/1 Running 0 51s 10.0.0.76 10.0.0.76 我们需要替换 kubelet 的 --cluster-dns 参数，指向 169.254.20.10 这个 IP。\n在TKE上，对于存量节点，登录节点执行以下命令:\nsed -i \u0026#39;/CLUSTER_DNS/c\\CLUSTER_DNS=\u0026#34;--cluster-dns=169.254.20.10\u0026#34;\u0026#39; /etc/kubernetes/kubelet systemctl restart kubelet 对于增量节点，可以将上述命令放入新增节点的 user-data，以便加入节点后自动执行。\n后续新增才会用到本地 DNS 缓存，对于存量 Pod 可以销毁重建，比如改下 Deployment 中 template 里的 annotation，触发 Deployment 所有 Pod 滚动更新，如果怕滚动更新造成部分流量异常，可以参考 使用 preStopHook 和 readinessProbe 保证服务平滑更新不中断\n参考资料  https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns https://github.com/kubernetes/enhancements/blob/master/keps/sig-network/20190424-NodeLocalDNS-beta-proposal.md  "
},
{
	"uri": "https://k8s.imroc.io/avoid/handle-cgroup-oom-in-userspace-with-oom-guard/",
	"title": "使用 oom-guard 在用户态处理 cgroup OOM",
	"tags": [],
	"description": "",
	"content": "背景 由于 linux 内核对 cgroup OOM 的处理，存在很多 bug，经常有由于频繁 cgroup OOM 导致节点故障(卡死， 重启， 进程异常但无法杀死)，于是 TKE 团队开发了 oom-guard，在用户态处理 cgroup OOM 规避了内核 bug。\n原理 核心思想是在发生内核 cgroup OOM kill 之前，在用户空间杀掉超限的容器， 减少走到内核 cgroup 内存回收失败后的代码分支从而触发各种内核故障的机会。\nthreshold notify 参考文档: https://lwn.net/Articles/529927/\noom-guard 会给 memory cgroup 设置 threshold notify， 接受内核的通知。\n以一个例子来说明阀值计算通知原理: 一个 pod 设置的 memory limit 是 1000M， oom-guard 会根据配置参数计算出 margin:\nmargin = 1000M * margin_ratio = 20M // 缺省margin_ratio是0.02 margin 最小不小于 mim_margin(缺省1M)， 最大不大于 max_margin(缺省为30M)。如果超出范围，则取 mim_margin 或 max_margin。计算 threshold = limit - margin ，也就是 1000M - 20M = 980M，把 980M 作为阈值设置给内核。当这个 pod 的内存使用量达到 980M 时， oom-guard 会收到内核的通知。\n在触发阈值之前，oom-gurad 会先通过 memory.force_empty 触发相关 cgroup 的内存回收。 另外，如果触发阈值时，相关 cgroup 的 memory.stat 显示还有较多 cache， 则不会触发后续处理策略，这样当 cgroup 内存达到 limit 时，会内核会触发内存回收。 这个策略也会造成部分容器内存增长太快时，还是会触发内核 cgroup OOM\n达到阈值后的处理策略 通过 --policy 参数来控制处理策略。目前有三个策略， 缺省策略是 process。\n process: 采用跟内核cgroup OOM killer相同的策略，在该cgroup内部，选择一个 oom_score 得分最高的进程杀掉。 通过 oom-guard 发送 SIGKILL 来杀掉进程 container: 在该cgroup下选择一个 docker 容器，杀掉整个容器 noop: 只记录日志，并不采取任何措施  事件上报 通过 webhook reporter 上报 k8s event，便于分析统计，使用kubectl get event 可以看到:\nLAST SEEN FIRST SEEN COUNT NAME KIND SUBOBJECT TYPE REASON SOURCE MESSAGE 14s 14s 1 172.21.16.23.158b732d352bcc31 Node Warning OomGuardKillContainer oom-guard, 172.21.16.23 {\u0026#34;hostname\u0026#34;:\u0026#34;172.21.16.23\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;2019-03-13T07:12:14.561650646Z\u0026#34;,\u0026#34;oomcgroup\u0026#34;:\u0026#34;/sys/fs/cgroup/memory/kubepods/burstable/pod3d6329e5-455f-11e9-a7e5-06925242d7ea/223d4795cc3b33e28e702f72e0497e1153c4a809de6b4363f27acc12a6781cdb\u0026#34;,\u0026#34;proccgroup\u0026#34;:\u0026#34;/sys/fs/cgroup/memory/kubepods/burstable/pod3d6329e5-455f-11e9-a7e5-06925242d7ea/223d4795cc3b33e28e702f72e0497e1153c4a809de6b4363f27acc12a6781cdb\u0026#34;,\u0026#34;threshold\u0026#34;:205520896,\u0026#34;usage\u0026#34;:206483456,\u0026#34;killed\u0026#34;:\u0026#34;16481(fakeOOM) \u0026#34;,\u0026#34;stats\u0026#34;:\u0026#34;cache 20480|rss 205938688|rss_huge 199229440|mapped_file 0|dirty 0|writeback 0|pgpgin 1842|pgpgout 104|pgfault 2059|pgmajfault 0|inactive_anon 8192|active_anon 203816960|inactive_file 0|active_file 0|unevictable 0|hierarchical_memory_limit 209715200|total_cache 20480|total_rss 205938688|total_rss_huge 199229440|total_mapped_file 0|total_dirty 0|total_writeback 0|total_pgpgin 1842|total_pgpgout 104|total_pgfault 2059|total_pgmajfault 0|total_inactive_anon 8192|total_active_anon 203816960|total_inactive_file 0|total_active_file 0|total_unevictable 0|\u0026#34;,\u0026#34;policy\u0026#34;:\u0026#34;Container\u0026#34;} 使用方法 部署 保存部署 yaml: oom-guard.yaml:\napiVersion: v1 kind: ServiceAccount metadata: name: oomguard namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: system:oomguard roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: oomguard namespace: kube-system --- apiVersion: apps/v1 kind: DaemonSet metadata: name: oom-guard namespace: kube-system labels: app: oom-guard spec: selector: matchLabels: app: oom-guard template: metadata: annotations: scheduler.alpha.kubernetes.io/critical-pod: \u0026#34;\u0026#34; labels: app: oom-guard spec: serviceAccountName: oomguard hostPID: true hostNetwork: true dnsPolicy: ClusterFirst containers: - name: k8s-event-writer image: ccr.ccs.tencentyun.com/paas/k8s-event-writer:v1.6 resources: limits: cpu: 10m memory: 60Mi requests: cpu: 10m memory: 30Mi args: - --logtostderr - --unix-socket=true env: - name: NODE_NAME valueFrom: fieldRef: fieldPath: status.hostIP volumeMounts: - name: unix mountPath: /unix - name: oomguard image: ccr.ccs.tencentyun.com/paas/oomguard:nosoft-v2 imagePullPolicy: Always securityContext: privileged: true resources: limits: cpu: 10m memory: 60Mi requests: cpu: 10m memory: 30Mi volumeMounts: - name: cgroupdir mountPath: /sys/fs/cgroup/memory - name: unix mountPath: /unix - name: kmsg mountPath: /dev/kmsg readOnly: true command: [\u0026#34;/oom-guard\u0026#34;] args: - --v=2 - --logtostderr - --root=/sys/fs/cgroup/memory - --walkIntervalSeconds=277 - --inotifyResetSeconds=701 - --port=0 - --margin-ratio=0.02 - --min-margin=1 - --max-margin=30 - --guard-ms=50 - --policy=container - --openSoftLimit=false - --webhook-url=http://localhost/message env: - name: NODE_NAME valueFrom: fieldRef: fieldPath: status.hostIP volumes: - name: cgroupdir hostPath: path: /sys/fs/cgroup/memory - name: unix emptyDir: {} - name: kmsg hostPath: path: /dev/kmsg 一键部署:\nkubectl apply -f oom-guard.yaml 检查是否部署成功：\n$ kubectl -n kube-system get ds oom-guard NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE oom-guard 2 2 2 2 2 \u0026lt;none\u0026gt; 6m 其中 AVAILABLE 数量跟节点数一致，说明所有节点都已经成功运行了 oom-guard。\n查看 oom-guard 日志 kubectl -n kube-system logs oom-guard-xxxxx oomguard 查看 oom 相关事件 kubectl get events |grep CgroupOOM kubectl get events |grep SystemOOM kubectl get events |grep OomGuardKillContainer kubectl get events |grep OomGuardKillProcess 卸载 kubectl delete -f oom-guard.yaml 这个操作可能有点慢，如果一直不返回 (有节点 NotReady 时可能会卡住)，ctrl+C 终止，然后执行下面的脚本:\nfor pod in `kubectl get pod -n kube-system | grep oom-guard | awk \u0026#39;{print $1}\u0026#39;` do kubectl delete pod $pod -n kube-system --grace-period=0 --force done 检查删除操作是否成功\nkubectl -n kube-system get ds oom-guard 提示 ...not found 就说明删除成功了\n关于开源 当前 oom-gaurd 暂未开源，正在做大量生产试验，后面大量反馈效果统计比较好的时候会考虑开源出来。\n"
},
{
	"uri": "https://k8s.imroc.io/optimization/deploy/use-pdb-to-avoid-service-unavailable-during-eviction/",
	"title": "使用 PodDisruptionBudget 避免驱逐导致服务不可用",
	"tags": [],
	"description": "",
	"content": "驱逐节点是一种有损操作，驱逐的原理:\n 封锁节点 (设为不可调度，避免新的 Pod 调度上来)。 将该节点上的 Pod 删除。 ReplicaSet 控制器检测到 Pod 减少，会重新创建一个 Pod，调度到新的节点上。  这个过程是先删除，再创建，并非是滚动更新，因此更新过程中，如果一个服务的所有副本都在被驱逐的节点上，则可能导致该服务不可用。\n我们再来下什么情况下驱逐会导致服务不可用:\n 服务存在单点故障，所有副本都在同一个节点，驱逐该节点时，就可能造成服务不可用。 服务在多个节点，但这些节点都被同时驱逐，所以这个服务的所有服务同时被删，也可能造成服务不可用。  针对第一点，我们可以 使用反亲和性避免单点故障。\n针对第二点，我们可以通过配置 PDB (PodDisruptionBudget) 来避免所有副本同时被删除，下面给出示例。\n示例一 (保证驱逐时 zookeeper 至少有两个副本可用):\napiVersion: policy/v1beta1 kind: PodDisruptionBudget metadata: name: zk-pdb spec: minAvailable: 2 selector: matchLabels: app: zookeeper 示例二 (保证驱逐时 zookeeper 最多有一个副本不可用，相当于逐个删除并在其它节点重建):\napiVersion: policy/v1beta1 kind: PodDisruptionBudget metadata: name: zk-pdb spec: maxUnavailable: 1 selector: matchLabels: app: zookeeper 更多请参考官方文档: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n"
},
{
	"uri": "https://k8s.imroc.io/optimization/deploy/smooth-update-using-prestophook-and-readinessprobe/",
	"title": "使用 preStopHook 和 readinessProbe 保证服务平滑更新不中断",
	"tags": [],
	"description": "",
	"content": "如果服务不做配置优化，默认情况下更新服务期间可能会导致部分流量异常，下面我们来分析并给出最佳实践。\n服务更新场景 我们先看下服务更新有哪些场景:\n 手动调整服务的副本数量 手动删除 Pod 触发重新调度 驱逐节点 (主动或被动驱逐，Pod会先删除再在其它节点重建) 触发滚动更新 (比如修改镜像 tag 升级程序版本) HPA (HorizontalPodAutoscaler) 自动对服务进行水平伸缩 VPA (VerticalPodAutoscaler) 自动对服务进行垂直伸缩  更新过程连接异常的原因 滚动更新时，Service 对应的 Pod 会被创建或销毁，Service 对应的 Endpoint 也会新增或移除相应的 Pod IP:Port，然后 kube-proxy 会根据 Service 的 Endpoint 里的 Pod IP:Port 列表更新节点上的转发规则，而这里 kube-proxy 更新节点转发规则的动作并不是那么及时，主要是由于 K8S 的设计理念，各个组件的逻辑是解耦的，各自使用 Controller 模式 listAndWatch 感兴趣的资源并做出相应的行为，所以从 Pod 创建或销毁到 Endpoint 更新再到节点上的转发规则更新，这个过程是异步的，所以会造成转发规则更新不及时，从而导致服务更新期间部分连接异常。\n我们分别分析下 Pod 创建和销毁到规则更新期间的过程:\n Pod 被创建，但启动速度没那么快，还没等到 Pod 完全启动就被 Endpoint Controller 加入到 Service 对应 Endpoint 的 Pod IP:Port 列表，然后 kube-proxy watch 到更新也同步更新了节点上的 Service 转发规则 (iptables/ipvs)，如果这个时候有请求过来就可能被转发到还没完全启动完全的 Pod，这时 Pod 还不能正常处理请求，就会导致连接被拒绝。 Pod 被销毁，但是从 Endpoint Controller watch 到变化并更新 Service 对应 Endpoint 再到 kube-proxy 更新节点转发规则这期间是异步的，有个时间差，Pod 可能已经完全被销毁了，但是转发规则还没来得及更新，就会造成新来的请求依旧还能被转发到已经被销毁的 Pod，导致连接被拒绝。  平滑更新最佳实践   针对第一种情况，可以给 Pod 里的 container 加 readinessProbe (就绪检查)，通常是容器完全启动后监听一个 HTTP 端口，kubelet 发就绪检查探测包，正常响应说明容器已经就绪，然后修改容器状态为 Ready，当 Pod 中所有容器都 Ready 了这个 Pod 才会被 Endpoint Controller 加进 Service 对应 Endpoint IP:Port 列表，然后 kube-proxy 再更新节点转发规则，更新完了即便立即有请求被转发到的新的 Pod 也能保证能够正常处理连接，避免了连接异常。 针对第二种情况，可以给 Pod 里的 container 加 preStop hook，让 Pod 真正销毁前先 sleep 等待一段时间，留点时间给 Endpoint controller 和 kube-proxy 更新 Endpoint 和转发规则，这段时间 Pod 处于 Terminating 状态，即便在转发规则更新完全之前有请求被转发到这个 Terminating 的 Pod，依然可以被正常处理，因为它还在 sleep，没有被真正销毁。  最佳实践 yaml 示例:\napiVersion: extensions/v1beta1 kind: Deployment metadata: name: nginx spec: replicas: 1 selector: matchLabels: component: nginx template: metadata: labels: component: nginx spec: containers: - name: nginx image: \u0026#34;nginx\u0026#34; ports: - name: http hostPort: 80 containerPort: 80 protocol: TCP readinessProbe: httpGet: path: /healthz port: 80 httpHeaders: - name: X-Custom-Header value: Awesome initialDelaySeconds: 15 timeoutSeconds: 1 lifecycle: preStop: exec: command: [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;sleep 30\u0026#34;] 参考资料  Container probes: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes Container Lifecycle Hooks: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/trick/use-systemtap-to-locate-problems/",
	"title": "使用 Systemtap 定位疑难杂症",
	"tags": [],
	"description": "",
	"content": "安装 Ubuntu 安装 systemtap:\napt install -y systemtap 运行 stap-prep 检查还有什么需要安装:\n$ stap-prep Please install linux-headers-4.4.0-104-generic You need package linux-image-4.4.0-104-generic-dbgsym but it does not seem to be available Ubuntu -dbgsym packages are typically in a separate repository Follow https://wiki.ubuntu.com/DebuggingProgramCrash to add this repository apt install -y linux-headers-4.4.0-104-generic 提示需要 dbgsym 包但当前已有软件源中并不包含，需要使用第三方软件源安装，下面是 dbgsym 安装方法(参考官方wiki: https://wiki.ubuntu.com/Kernel/Systemtap):\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys C8CAB6595FDFF622 codename=$(lsb_release -c | awk \u0026#39;{print $2}\u0026#39;) sudo tee /etc/apt/sources.list.d/ddebs.list \u0026lt;\u0026lt; EOF deb http://ddebs.ubuntu.com/ ${codename} main restricted universe multiverse deb http://ddebs.ubuntu.com/ ${codename}-security main restricted universe multiverse deb http://ddebs.ubuntu.com/ ${codename}-updates main restricted universe multiverse deb http://ddebs.ubuntu.com/ ${codename}-proposed main restricted universe multiverse EOF sudo apt-get update 配置好源后再运行下 stap-prep:\n$ stap-prep Please install linux-headers-4.4.0-104-generic Please install linux-image-4.4.0-104-generic-dbgsym 提示需要装这两个包，我们安装一下:\napt install -y linux-image-4.4.0-104-generic-dbgsym apt install -y linux-headers-4.4.0-104-generic CentOS 安装 systemtap:\nyum install -y systemtap 默认没装 debuginfo，我们需要装一下，添加软件源 /etc/yum.repos.d/CentOS-Debug.repo:\n[debuginfo] name=CentOS-$releasever - DebugInfo baseurl=http://debuginfo.centos.org/$releasever/$basearch/ gpgcheck=0 enabled=1 protect=1 priority=1 执行 stap-prep (会安装 kernel-debuginfo)\n最后检查确保 kernel-debuginfo 和 kernel-devel 均已安装并且版本跟当前内核版本相同，如果有多个版本，就删除跟当前内核版本不同的包(通过uname -r查看当前内核版本)。\n重点检查是否有多个版本的 kernel-devel:\n$ rpm -qa | grep kernel-devel kernel-devel-3.10.0-327.el7.x86_64 kernel-devel-3.10.0-514.26.2.el7.x86_64 kernel-devel-3.10.0-862.9.1.el7.x86_64 如果存在多个，保证只留跟当前内核版本相同的那个，假设当前内核版本是 3.10.0-862.9.1.el7.x86_64，那么使用 rpm 删除多余的版本:\nrpm -e kernel-devel-3.10.0-327.el7.x86_64 kernel-devel-3.10.0-514.26.2.el7.x86_64 使用 systemtap 揪出杀死容器的真凶 Pod 莫名其妙被杀死? 可以使用 systemtap 来监视进程的信号发送，原理是 systemtap 将脚本翻译成 C 代码然后调用 gcc 编译成 linux 内核模块，再通过 modprobe 加载到内核，根据脚本内容在内核做各种 hook，在这里我们就 hook 一下信号的发送，找出是谁 kill 掉了容器进程。\n首先，找到被杀死的 pod 又自动重启的容器的当前 pid，describe 一下 pod:\n...... Container ID: docker://5fb8adf9ee62afc6d3f6f3d9590041818750b392dff015d7091eaaf99cf1c945 ...... Last State: Terminated Reason: Error Exit Code: 137 Started: Thu, 05 Sep 2019 19:22:30 +0800 Finished: Thu, 05 Sep 2019 19:33:44 +0800 拿到容器 id 反查容器的主进程 pid:\n$ docker inspect -f \u0026#34;{{.State.Pid}}\u0026#34; 5fb8adf9ee62afc6d3f6f3d9590041818750b392dff015d7091eaaf99cf1c945 7942 通过 Exit Code 可以看出容器上次退出的状态码，如果进程是被外界中断信号杀死的，退出状态码将在 129-255 之间，137 表示进程是被 SIGKILL 信号杀死的，但我们从这里并不能看出是被谁杀死的。\n如果问题可以复现，我们可以使用下面的 systemtap 脚本来监视容器是被谁杀死的(保存为sg.stp):\nglobal target_pid = 7942 probe signal.send{ if (sig_pid == target_pid) { printf(\u0026#34;%s(%d) send %s to %s(%d)\\n\u0026#34;, execname(), pid(), sig_name, pid_name, sig_pid); printf(\u0026#34;parent of sender: %s(%d)\\n\u0026#34;, pexecname(), ppid()) printf(\u0026#34;task_ancestry:%s\\n\u0026#34;, task_ancestry(pid2task(pid()), 1)); } }  变量 pid 的值替换为查到的容器主进程 pid  运行脚本:\nstap sg.stp 当容器进程被杀死时，脚本捕捉到事件，执行输出:\npkill(23549) send SIGKILL to server(7942) parent of sender: bash(23495) task_ancestry:swapper/0(0m0.000000000s)=\u0026gt;systemd(0m0.080000000s)=\u0026gt;vGhyM0(19491m2.579563677s)=\u0026gt;sh(33473m38.074571885s)=\u0026gt;bash(33473m38.077072025s)=\u0026gt;bash(33473m38.081028267s)=\u0026gt;bash(33475m4.817798337s)=\u0026gt;pkill(33475m5.202486630s) 通过观察 task_ancestry 可以看到杀死进程的所有父进程，在这里可以看到有个叫 vGhyM0 的奇怪进程名，通常是中了木马，需要安全专家介入继续排查。\n"
},
{
	"uri": "https://k8s.imroc.io/optimization/deploy/use-antiaffinity-to-avoid-single-points-of-failure/",
	"title": "使用反亲和性避免单点故障",
	"tags": [],
	"description": "",
	"content": "k8s 的设计就是假设节点是不可靠的，节点越多，发生软硬件故障导致节点不可用的几率就越高，所以我们通常需要给服务部署多个副本，根据实际情况调整 replicas 的值，如果值为 1 就必然存在单点故障，如果大于 1 但所有副本都调度到同一个节点，那还是有单点故障，所以我们不仅要有合理的副本数量，还需要让这些不同副本调度到不同的节点，打散开来避免单点故障，这个可以利用反亲和性来实现，示例:\naffinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - weight: 100 labelSelector: matchExpressions: - key: k8s-app operator: In values: - kube-dns topologyKey: kubernetes.io/hostname  requiredDuringSchedulingIgnoredDuringExecution 调度时必须满足该反亲和性条件，如果没有节点满足条件就不调度到任何节点 (Pending)。如果不用这种硬性条件可以使用 preferredDuringSchedulingIgnoredDuringExecution 来指示调度器尽量满足反亲和性条件，如果没有满足条件的也可以调度到某个节点。 labelSelector.matchExpressions 写该服务对应 pod 中 labels 的 key 与 value。 topologyKey 这里用 kubernetes.io/hostname 表示避免 pod 调度到同一节点，如果你有更高的要求，比如避免调度到同一个可用区，实现异地多活，可以用 failure-domain.beta.kubernetes.io/zone。通常不会去避免调度到同一个地域，因为一般同一个集群的节点都在一个地域，如果跨地域，即使用专线时延也会很大，所以 topologyKey 一般不至于用 failure-domain.beta.kubernetes.io/region。  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/handle/memory-fragmentation/",
	"title": "内存碎片化",
	"tags": [],
	"description": "",
	"content": "判断是否内存碎片化严重 内存页分配失败，内核日志报类似下面的错：\nmysqld: page allocation failure. order:4, mode:0x10c0d0  mysqld 是被分配的内存的程序 order 表示需要分配连续页的数量(2^order)，这里 4 表示 2^4=16 个连续的页 mode 是内存分配模式的标识，定义在内核源码文件 include/linux/gfp.h 中，通常是多个标识相与运算的结果，不同版本内核可能不一样，比如在新版内核中 GFP_KERNEL 是 __GFP_RECLAIM | __GFP_IO | __GFP_FS 的运算结果，而 __GFP_RECLAIM 又是 ___GFP_DIRECT_RECLAIM|___GFP_KSWAPD_RECLAIM 的运算结果  当 order 为 0 时，说明系统以及完全没有可用内存了，order 值比较大时，才说明内存碎片化了，无法分配连续的大页内存。\n内存碎片化造成的问题 容器启动失败 K8S 会为每个 pod 创建 netns 来隔离 network namespace，内核初始化 netns 时会为其创建 nf_conntrack 表的 cache，需要申请大页内存，如果此时系统内存已经碎片化，无法分配到足够的大页内存内核就会报错(v2.6.33 - v4.6):\nrunc:[1:CHILD]: page allocation failure: order:6, mode:0x10c0d0 Pod 状态将会一直在 ContainerCreating，dockerd 启动容器失败，日志报错:\nJan 23 14:15:31 dc05 dockerd: time=\u0026#34;2019-01-23T14:15:31.288446233+08:00\u0026#34; level=error msg=\u0026#34;containerd: start container\u0026#34; error=\u0026#34;oci runtime error: container_linux.go:247: starting container process caused \\\u0026#34;process_linux.go:245: running exec setns process for init caused \\\\\\\u0026#34;exit status 6\\\\\\\u0026#34;\\\u0026#34;\\n\u0026#34; id=5b9be8c5bb121264899fac8d9d36b02150269d41ce96ba6ad36d70b8640cb01c Jan 23 14:15:31 dc05 dockerd: time=\u0026#34;2019-01-23T14:15:31.317965799+08:00\u0026#34; level=error msg=\u0026#34;Create container failed with error: invalid header field value \\\u0026#34;oci runtime error: container_linux.go:247: starting container process caused \\\\\\\u0026#34;process_linux.go:245: running exec setns process for init caused \\\\\\\\\\\\\\\u0026#34;exit status 6\\\\\\\\\\\\\\\u0026#34;\\\\\\\u0026#34;\\\\n\\\u0026#34;\u0026#34; kubelet 日志报错:\nJan 23 14:15:31 dc05 kubelet: E0123 14:15:31.352386 26037 remote_runtime.go:91] RunPodSandbox from runtime service failed: rpc error: code = 2 desc = failed to start sandbox container for pod \u0026#34;matchdataserver-1255064836-t4b2w\u0026#34;: Error response from daemon: {\u0026#34;message\u0026#34;:\u0026#34;invalid header field value \\\u0026#34;oci runtime error: container_linux.go:247: starting container process caused \\\\\\\u0026#34;process_linux.go:245: running exec setns process for init caused \\\\\\\\\\\\\\\u0026#34;exit status 6\\\\\\\\\\\\\\\u0026#34;\\\\\\\u0026#34;\\\\n\\\u0026#34;\u0026#34;} Jan 23 14:15:31 dc05 kubelet: E0123 14:15:31.352496 26037 kuberuntime_sandbox.go:54] CreatePodSandbox for pod \u0026#34;matchdataserver-1255064836-t4b2w_basic(485fd485-1ed6-11e9-8661-0a587f8021ea)\u0026#34; failed: rpc error: code = 2 desc = failed to start sandbox container for pod \u0026#34;matchdataserver-1255064836-t4b2w\u0026#34;: Error response from daemon: {\u0026#34;message\u0026#34;:\u0026#34;invalid header field value \\\u0026#34;oci runtime error: container_linux.go:247: starting container process caused \\\\\\\u0026#34;process_linux.go:245: running exec setns process for init caused \\\\\\\\\\\\\\\u0026#34;exit status 6\\\\\\\\\\\\\\\u0026#34;\\\\\\\u0026#34;\\\\n\\\u0026#34;\u0026#34;} Jan 23 14:15:31 dc05 kubelet: E0123 14:15:31.352518 26037 kuberuntime_manager.go:618] createPodSandbox for pod \u0026#34;matchdataserver-1255064836-t4b2w_basic(485fd485-1ed6-11e9-8661-0a587f8021ea)\u0026#34; failed: rpc error: code = 2 desc = failed to start sandbox container for pod \u0026#34;matchdataserver-1255064836-t4b2w\u0026#34;: Error response from daemon: {\u0026#34;message\u0026#34;:\u0026#34;invalid header field value \\\u0026#34;oci runtime error: container_linux.go:247: starting container process caused \\\\\\\u0026#34;process_linux.go:245: running exec setns process for init caused \\\\\\\\\\\\\\\u0026#34;exit status 6\\\\\\\\\\\\\\\u0026#34;\\\\\\\u0026#34;\\\\n\\\u0026#34;\u0026#34;} Jan 23 14:15:31 dc05 kubelet: E0123 14:15:31.352580 26037 pod_workers.go:182] Error syncing pod 485fd485-1ed6-11e9-8661-0a587f8021ea (\u0026#34;matchdataserver-1255064836-t4b2w_basic(485fd485-1ed6-11e9-8661-0a587f8021ea)\u0026#34;), skipping: failed to \u0026#34;CreatePodSandbox\u0026#34; for \u0026#34;matchdataserver-1255064836-t4b2w_basic(485fd485-1ed6-11e9-8661-0a587f8021ea)\u0026#34; with CreatePodSandboxError: \u0026#34;CreatePodSandbox for pod \\\u0026#34;matchdataserver-1255064836-t4b2w_basic(485fd485-1ed6-11e9-8661-0a587f8021ea)\\\u0026#34; failed: rpc error: code = 2 desc = failed to start sandbox container for pod \\\u0026#34;matchdataserver-1255064836-t4b2w\\\u0026#34;: Error response from daemon: {\\\u0026#34;message\\\u0026#34;:\\\u0026#34;invalid header field value \\\\\\\u0026#34;oci runtime error: container_linux.go:247: starting container process caused \\\\\\\\\\\\\\\u0026#34;process_linux.go:245: running exec setns process for init caused \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\u0026#34;exit status 6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\u0026#34;\\\\\\\\\\\\\\\u0026#34;\\\\\\\\n\\\\\\\u0026#34;\\\u0026#34;}\u0026#34; Jan 23 14:15:31 dc05 kubelet: I0123 14:15:31.372181 26037 kubelet.go:1916] SyncLoop (PLEG): \u0026#34;matchdataserver-1255064836-t4b2w_basic(485fd485-1ed6-11e9-8661-0a587f8021ea)\u0026#34;, event: \u0026amp;pleg.PodLifecycleEvent{ID:\u0026#34;485fd485-1ed6-11e9-8661-0a587f8021ea\u0026#34;, Type:\u0026#34;ContainerDied\u0026#34;, Data:\u0026#34;5b9be8c5bb121264899fac8d9d36b02150269d41ce96ba6ad36d70b8640cb01c\u0026#34;} Jan 23 14:15:31 dc05 kubelet: W0123 14:15:31.372225 26037 pod_container_deletor.go:77] Container \u0026#34;5b9be8c5bb121264899fac8d9d36b02150269d41ce96ba6ad36d70b8640cb01c\u0026#34; not found in pod\u0026#39;s containers Jan 23 14:15:31 dc05 kubelet: I0123 14:15:31.678211 26037 kuberuntime_manager.go:383] No ready sandbox for pod \u0026#34;matchdataserver-1255064836-t4b2w_basic(485fd485-1ed6-11e9-8661-0a587f8021ea)\u0026#34; can be found. Need to start a new one 查看slab (后面的0多表示伙伴系统没有大块内存了)：\n$ cat /proc/buddyinfo Node 0, zone DMA 1 0 1 0 2 1 1 0 1 1 3 Node 0, zone DMA32 2725 624 489 178 0 0 0 0 0 0 0 Node 0, zone Normal 1163 1101 932 222 0 0 0 0 0 0 0 系统 OOM 内存碎片化会导致即使当前系统总内存比较多，但由于无法分配足够的大页内存导致给进程分配内存失败，就认为系统内存不够用，需要杀掉一些进程来释放内存，从而导致系统 OOM\n解决方法  周期性地或者在发现大块内存不足时，先进行drop_cache操作:  echo 3 \u0026gt; /proc/sys/vm/drop_caches  必要时候进行内存整理，开销会比较大，会造成业务卡住一段时间(慎用):  echo 1 \u0026gt; /proc/sys/vm/compact_memory 如何防止内存碎片化 TODO\n附录 相关链接：\n https://huataihuang.gitbooks.io/cloud-atlas/content/os/linux/kernel/memory/drop_caches_and_compact_memory.html  "
},
{
	"uri": "https://k8s.imroc.io/optimization/kernel/",
	"title": "内核参数优化",
	"tags": [],
	"description": "",
	"content": "# 允许的最大跟踪连接条目，是在内核内存中 netfilter 可以同时处理的“任务”（连接跟踪条目） net.netfilter.nf_conntrack_max=10485760 net.netfilter.nf_conntrack_tcp_timeout_established=300 # 哈希表大小（只读）（64位系统、8G内存默认 65536，16G翻倍，如此类推） net.netfilter.nf_conntrack_buckets=655360 # 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目 net.core.netdev_max_backlog=10000 # 表示socket监听(listen)的backlog上限，也就是就是socket的监听队列(accept queue)，当一个tcp连接尚未被处理或建立时(半连接状态)，会保存在这个监听队列，默认为 128，在高并发场景下偏小，优化到 32768。参考 https://imroc.io/posts/kubernetes-overflow-and-drop/ net.core.somaxconn=32768 # 没有启用syncookies的情况下，syn queue(半连接队列)大小除了受somaxconn限制外，也受这个参数的限制，默认1024，优化到8096，避免在高并发场景下丢包 net.ipv4.tcp_max_syn_backlog=8096 # 表示同一用户同时最大可以创建的 inotify 实例 (每个实例可以有很多 watch) fs.inotify.max_user_instances=8192 # max-file 表示系统级别的能够打开的文件句柄的数量， 一般如果遇到文件句柄达到上限时，会碰到 # Too many open files 或者 Socket/File: Can’t open so many files 等错误 fs.file-max=2097152 # 表示同一用户同时可以添加的watch数目（watch一般是针对目录，决定了同时同一用户可以监控的目录数量) 默认值 8192 在容器场景下偏小，在某些情况下可能会导致 inotify watch 数量耗尽，使得创建 Pod 不成功或者 kubelet 无法启动成功，将其优化到 524288 fs.inotify.max_user_watches=524288 net.core.bpf_jit_enable=1 net.core.bpf_jit_harden=1 net.core.bpf_jit_kallsyms=1 net.core.dev_weight_tx_bias=1 net.core.rmem_max=16777216 net.core.wmem_max=16777216 net.ipv4.tcp_rmem=4096 12582912 16777216 net.ipv4.tcp_wmem=4096 12582912 16777216 net.core.rps_sock_flow_entries=8192 # 以下三个参数是 arp 缓存的 gc 阀值，相比默认值提高了，当内核维护的 arp 表过于庞大时候，可以考虑优化下，避免在某些场景下arp缓存溢出导致网络超时，参考：https://k8s.imroc.io/avoid/cases/arp-cache-overflow-causes-healthcheck-failed # 存在于 ARP 高速缓存中的最少层数，如果少于这个数，垃圾收集器将不会运行。缺省值是 128 net.ipv4.neigh.default.gc_thresh1=2048 # 保存在 ARP 高速缓存中的最多的记录软限制。垃圾收集器在开始收集前，允许记录数超过这个数字 5 秒。缺省值是 512 net.ipv4.neigh.default.gc_thresh2=4096 # 保存在 ARP 高速缓存中的最多记录的硬限制，一旦高速缓存中的数目高于此，垃圾收集器将马上运行。缺省值是 1024 net.ipv4.neigh.default.gc_thresh3=8192 net.ipv4.tcp_max_orphans=32768 net.ipv4.tcp_max_tw_buckets=32768 vm.max_map_count=262144 kernel.threads-max=30058 net.ipv4.ip_forward=1 # 避免发生故障时没有 coredump kernel.core_pattern=core "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/trick/analysis-exitcode/",
	"title": "分析 ExitCode 定位 Pod 异常退出原因",
	"tags": [],
	"description": "",
	"content": "使用 kubectl describe pod \u0026lt;pod name\u0026gt; 查看异常 pod 的状态:\nContainers: kubedns: Container ID: docker://5fb8adf9ee62afc6d3f6f3d9590041818750b392dff015d7091eaaf99cf1c945 Image: ccr.ccs.tencentyun.com/library/kubedns-amd64:1.14.4 Image ID: docker-pullable://ccr.ccs.tencentyun.com/library/kubedns-amd64@sha256:40790881bbe9ef4ae4ff7fe8b892498eecb7fe6dcc22661402f271e03f7de344 Ports: 10053/UDP, 10053/TCP, 10055/TCP Host Ports: 0/UDP, 0/TCP, 0/TCP Args: --domain=cluster.local. --dns-port=10053 --config-dir=/kube-dns-config --v=2 State: Running Started: Tue, 27 Aug 2019 10:58:49 +0800 Last State: Terminated Reason: Error Exit Code: 255 Started: Tue, 27 Aug 2019 10:40:42 +0800 Finished: Tue, 27 Aug 2019 10:58:27 +0800 Ready: True Restart Count: 1 在容器列表里看 Last State 字段，其中 ExitCode 即程序上次退出时的状态码，如果不为 0，表示异常退出，我们可以分析下原因。\n退出状态码的区间  必须在 0-255 之间 0 表示正常退出 外界中断将程序退出的时候状态码区间在 129-255，(操作系统给程序发送中断信号，比如 kill -9 是 SIGKILL，ctrl+c 是 SIGINT) 一般程序自身原因导致的异常退出状态区间在 1-128 (这只是一般约定，程序如果一定要用129-255的状态码也是可以的)  假如写代码指定的退出状态码时不在 0-255 之间，例如: exit(-1)，这时会自动做一个转换，最终呈现的状态码还是会在 0-255 之间。我们把状态码记为 code\n 当指定的退出时状态码为负数，那么转换公式如下:  256 - (|code| % 256)  当指定的退出时状态码为正数，那么转换公式如下:  code % 256 常见异常状态码  137 (被 SIGKILL 中断信号杀死)   此状态码一般是因为 pod 中容器内存达到了它的资源限制(resources.limits)，一般是内存溢出(OOM)，CPU达到限制只需要不分时间片给程序就可以。因为限制资源是通过 linux 的 cgroup 实现的，所以 cgroup 会将此容器强制杀掉，类似于 kill -9，此时在 describe pod 中可以看到 Reason 是 OOMKilled\n  还可能是宿主机本身资源不够用了(OOM)，内核会选取一些进程杀掉来释放内存\n  不管是 cgroup 限制杀掉进程还是因为节点机器本身资源不够导致进程死掉，都可以从系统日志中找到记录:\n ubuntu 的系统日志在 /var/log/syslog，centos 的系统日志在 /var/log/messages，都可以用 journalctl -k 来查看系统日志\n   也可能是 livenessProbe (存活检查) 失败，kubelet 杀死的 pod\n  还可能是被恶意木马进程杀死\n   1 和 255  这种可能是一般错误，具体错误原因只能看容器日志，因为很多程序员写异常退出时习惯用 exit(1) 或 exit(-1)，-1 会根据转换规则转成 255    状态码参考 这里罗列了一些状态码的含义：Appendix E. Exit Codes With Special Meanings\nLinux 标准中断信号 Linux 程序被外界中断时会发送中断信号，程序退出时的状态码就是中断信号值加上 128 得到的，比如 SIGKILL 的中断信号值为 9，那么程序退出状态码就为 9+128=137。以下是标准信号值参考：\nSignal Value Action Comment ────────────────────────────────────────────────────────────────────── SIGHUP 1 Term Hangup detected on controlling terminal or death of controlling process SIGINT 2 Term Interrupt from keyboard SIGQUIT 3 Core Quit from keyboard SIGILL 4 Core Illegal Instruction SIGABRT 6 Core Abort signal from abort(3) SIGFPE 8 Core Floating-point exception SIGKILL 9 Term Kill signal SIGSEGV 11 Core Invalid memory reference SIGPIPE 13 Term Broken pipe: write to pipe with no readers; see pipe(7) SIGALRM 14 Term Timer signal from alarm(2) SIGTERM 15 Term Termination signal SIGUSR1 30,10,16 Term User-defined signal 1 SIGUSR2 31,12,17 Term User-defined signal 2 SIGCHLD 20,17,18 Ign Child stopped or terminated SIGCONT 19,18,25 Cont Continue if stopped SIGSTOP 17,19,23 Stop Stop process SIGTSTP 18,20,24 Stop Stop typed at terminal SIGTTIN 21,21,26 Stop Terminal input for background process SIGTTOU 22,22,27 Stop Terminal output for background process C/C++ 退出状态码 /usr/include/sysexits.h 试图将退出状态码标准化(仅限 C/C++):\n#define EX_OK 0 /* successful termination */ #define EX__BASE 64 /* base value for error messages */ #define EX_USAGE 64 /* command line usage error */ #define EX_DATAERR 65 /* data format error */ #define EX_NOINPUT 66 /* cannot open input */ #define EX_NOUSER 67 /* addressee unknown */ #define EX_NOHOST 68 /* host name unknown */ #define EX_UNAVAILABLE 69 /* service unavailable */ #define EX_SOFTWARE 70 /* internal software error */ #define EX_OSERR 71 /* system error (e.g., can\u0026#39;t fork) */ #define EX_OSFILE 72 /* critical OS file missing */ #define EX_CANTCREAT 73 /* can\u0026#39;t create (user) output file */ #define EX_IOERR 74 /* input/output error */ #define EX_TEMPFAIL 75 /* temp failure; user is invited to retry */ #define EX_PROTOCOL 76 /* remote error in protocol */ #define EX_NOPERM 77 /* permission denied */ #define EX_CONFIG 78 /* configuration error */ #define EX__MAX 78 /* maximum listed value */ "
},
{
	"uri": "https://k8s.imroc.io/security/user/create-user-using-csr-api/",
	"title": "利用 CSR API 创建用户",
	"tags": [],
	"description": "",
	"content": "k8s 支持 CSR API，通过创建 CertificateSigningRequest 资源就可以发起 CSR 请求，管理员审批通过之后 kube-controller-manager 就会为我们签发证书，确保 kube-controller-manager 配了根证书密钥对:\n--cluster-signing-cert-file=/var/lib/kubernetes/ca.pem --cluster-signing-key-file=/var/lib/kubernetes/ca-key.pem 创建步骤 我们用 cfssl 来创建 key 和 csr 文件，所以需要先安装 cfssl:\ncurl -L https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -o cfssl curl -L https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -o cfssljson curl -L https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -o cfssl-certinfo chmod +x cfssl cfssljson cfssl-certinfo sudo mv cfssl cfssljson cfssl-certinfo /usr/local/bin/ 指定要创建的用户名:\nUSERNAME=\u0026#34;roc\u0026#34; 再创建 key 和 csr 文件:\ncat \u0026lt;\u0026lt;EOF | cfssl genkey - | cfssljson -bare ${USERNAME} { \u0026#34;CN\u0026#34;: \u0026#34;${USERNAME}\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 } } EOF 生成以下文件:\nroc.csr roc-key.pem 创建 CertificateSigningRequest(发起 CSR 请求):\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: certificates.k8s.io/v1beta1 kind: CertificateSigningRequest metadata: name: ${USERNAME} spec: request: $(cat ${USERNAME}.csr | base64 | tr -d \u0026#39;\\n\u0026#39;) usages: - digital signature - key encipherment - client auth EOF 管理员审批 CSR 请求:\n# 查看 csr # kubectl get csr # 审批 csr kubectl certificate approve ${USERNAME} 获取证书:\nkubectl get csr ${USERNAME} -o jsonpath={.status.certificate} | base64 --decode \u0026gt; ${USERNAME}.pem 得到证书文件:\nroc.pem 至此，我们已经创建好了用户，用户的证书密钥对文件:\nroc.pem roc-key.pem 配置 kubeconfig # 增加 user kubectl config set-credentials ${USERNAME} --embed-certs=true --client-certificate=${USERNAME}.pem --client-key=${USERNAME}-key.pem # 如果还没配 cluster，可以通过下面命令配一下 kubectl config set-cluster \u0026lt;cluster\u0026gt; --server=\u0026lt;apiserver-url\u0026gt; --certificate-authority=\u0026lt;ca-cert-file\u0026gt; # 增加 context，绑定 cluster 和 user kubectl config set-context \u0026lt;context\u0026gt; --cluster=\u0026lt;cluster\u0026gt; --user=${USERNAME} # 使用刚增加的 context kubectl config use-context \u0026lt;context\u0026gt; 配置用户权限 我们可以用 RBAC 控制用户权限，参考 使用 RBAC 控制用户权限\n参考资料  Manage TLS Certificates in a Cluster: https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/  "
},
{
	"uri": "https://k8s.imroc.io/cluster/runtime/containerd/install-containerd/",
	"title": "安装 containerd",
	"tags": [],
	"description": "",
	"content": "二进制部署  下载二进制:\nwget -q --show-progress --https-only --timestamping \\  https://github.com/opencontainers/runc/releases/download/v1.0.0-rc8/runc.amd64 \\  https://github.com/containerd/containerd/releases/download/v1.3.0/containerd-1.3.0.linux-amd64.tar.gz \\  https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.16.1/crictl-v1.16.1-linux-amd64.tar.gz sudo mv runc.amd64 runc 安装二进制:\ntar -xvf crictl-v1.16.1-linux-amd64.tar.gz chmod +x crictl runc sudo cp crictl runc /usr/local/bin/ mkdir containerd tar -xvf containerd-1.3.0.linux-amd64.tar.gz -C containerd sudo cp containerd/bin/* /bin/ 创建 containerd 启动配置 config.toml:\nsudo mkdir -p /etc/containerd/ cat \u0026lt;\u0026lt; EOF | sudo tee /etc/containerd/config.toml [plugins] [plugins.cri.containerd] snapshotter = \u0026#34;overlayfs\u0026#34; [plugins.cri.containerd.default_runtime] runtime_type = \u0026#34;io.containerd.runtime.v1.linux\u0026#34; runtime_engine = \u0026#34;/usr/local/bin/runc\u0026#34; runtime_root = \u0026#34;\u0026#34; EOF 创建 systemd 配置 containerd.service:\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/systemd/system/containerd.service [Unit] Description=containerd container runtime Documentation=https://containerd.io After=network.target [Service] ExecStartPre=/sbin/modprobe overlay ExecStart=/bin/containerd Restart=always RestartSec=5 Delegate=yes KillMode=process OOMScoreAdjust=-999 LimitNOFILE=1048576 LimitNPROC=infinity LimitCORE=infinity [Install] WantedBy=multi-user.target EOF 启动:\nsudo systemctl daemon-reload sudo systemctl enable containerd sudo systemctl start containerd 配置 crictl (方便后面使用 crictl 管理与调试 containerd 的容器与镜像):\ncrictl config runtime-endpoint unix:///var/run/containerd/containerd.sock "
},
{
	"uri": "https://k8s.imroc.io/deploy/appendix/install-kubectl/",
	"title": "安装 kubectl",
	"tags": [],
	"description": "",
	"content": "二进制安装 指定K8S版本与节点cpu架构:\nVERSION=\u0026#34;v1.16.1\u0026#34; ARCH=\u0026#34;amd64\u0026#34; 下载安装:\nwget -q --show-progress --https-only --timestamping \\  https://storage.googleapis.com/kubernetes-release/release/${VERSION}/bin/linux/${ARCH}/kubectl chmod +x kubectl mv kubectl /usr/local/bin/ "
},
{
	"uri": "https://k8s.imroc.io/cluster/metrics/install-metrics-server/",
	"title": "安装 metrics server",
	"tags": [],
	"description": "",
	"content": "官方 yaml 安装 下载:\ngit clone --depth 1 https://github.com/kubernetes-sigs/metrics-server.git cd metrics-server 修改 deploy/1.8+/metrics-server-deployment.yaml，在 args 里增加 --kubelet-insecure-tls (防止 metrics server 访问 kubelet 采集指标时报证书问题 x509: certificate signed by unknown authority):\ncontainers: - name: metrics-server image: k8s.gcr.io/metrics-server-amd64:v0.3.6 args: - --cert-dir=/tmp - --secure-port=4443 - --kubelet-insecure-tls # 这里是新增的一行 安装:\nkubectl apply -f deploy/1.8+/ 参考资料  Github 主页: https://github.com/kubernetes-sigs/metrics-server  "
},
{
	"uri": "https://k8s.imroc.io/cluster/ingress/nginx/install-nginx-ingress/",
	"title": "安装 nginx ingress controller",
	"tags": [],
	"description": "",
	"content": "最佳安装方案 如何暴露 ingress 访问入口? 最佳方案是使用 LoadBalancer 类型的 Service 来暴露，即创建外部负载均衡器来暴露流量，后续访问 ingress 的流量都走这个负载均衡器的地址，ingress 规则里面配的域名也要配置解析到这个负载均衡器的 IP 地址。\n这种方式需要集群支持 LoadBalancer 类型的 Service，如果是云厂商提供的 k8s 服务，或者在云上自建集群并使用了云厂商提供的 cloud provider，也都是支持的，创建 LoadBalancer 类型的 Service 的时候会自动调云厂商的接口创建云厂商提供的负载均衡器产品(通常公网类型的负载均衡器是付费的)；如果你的集群不是前面说的情况，是自建集群并且有自己的负载均衡器方案，并部署了相关插件来适配，比如 MetalLB 和 Porter，这样也是可以支持 LoadBalancer 类型的 Service 的。\n使用 helm 安装 helm install stable/nginx-ingress \\  --name nginx \\  --namespace kube-system \\  --set controller.ingressClass=nginx \\  --set controller.publishService.enabled=true \\  controller.ingressClass: 创建的 ingress 中包含 kubernetes.io/ingress.class 这个 annotation 并且值与这里配置的一致，这个 nginx ingress controller 才会处理 (生成转发规则) controller.publishService.enabled: 这个置为 true 主要是为了让 ingress 的外部地址正确显示 (显示为负载均衡器的地址)，因为如果不配置这个，默认情况下会将 ingress controller 所有实例的节点 ip 写到 ingress 的 address 里  安装完成后如何获取负载均衡器的 IP 地址？查看 nginx ingress controller 的 service 的 EXTERNAL-IP 就可以:\n$ kubectl -n kube-system get service nginx-nginx-ingress-controller NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nginx-nginx-ingress-controller LoadBalancer 172.16.255.194 119.28.123.174 80:32348/TCP,443:32704/TCP 10m 如果需要新的流量入口，可以按照同样的方法用 helm 安装新的 release，注意要设置不同的 controller.ingressClass，将希望用新流量入口暴露的 ingress 的 kubernetes.io/ingress.class annotation 设置成这里的值就可以。\n如果转发性能跟不上，可以增加 controller 的副本，设置 controller.replicaCount 的值，或者启用 HPA 自动伸缩，将 controller.autoscaling.enabled 置为 true，更多细节控制请参考官方文档。\n配置优化 配置更改如果比较多推荐使用覆盖 values.yaml 的方式来安装 nginx ingress:\n 导出默认的 values.yaml:  helm inspect values stable/nginx-ingress \u0026gt; values.yaml 修改 values.yaml 中的配置 执行 helm install 的时候去掉 --set 的方式设置的变量，替换为使用 -f values.yaml  有时可能更新 nginx ingress 的部署，滚动更新时可能造成部分连接异常，可以参考服务平滑更新最佳实践 使用 preStopHook 和 readinessProbe 保证服务平滑更新不中断，nginx ingress 默认加了 readinessProbe，但 preStop 没有加，我们可以修改 values.yaml 中 controller.lifecycle，加上 preStop，示例:\nlifecycle: preStop: exec: command: [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;sleep 30\u0026#34;] 还可以 使用反亲和性避免单点故障，修改 controller.affinity 字段示例:\naffinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - weight: 100 labelSelector: matchExpressions: - key: app operator: In values: - nginx-ingress - key: component operator: In values: - controller - key: release operator: In values: - nginx topologyKey: kubernetes.io/hostname 参考资料  Github 主页: https://github.com/kubernetes/ingress-nginx helm hub 主页: https://hub.helm.sh/charts/nginx/nginx-ingress 官方文档: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/  "
},
{
	"uri": "https://k8s.imroc.io/cluster/ingress/traefik/install-traefik-ingress/",
	"title": "安装 traefik ingress controller",
	"tags": [],
	"description": "",
	"content": "最佳安装方案 如何暴露 ingress 访问入口? 最佳方案是使用 LoadBalancer 类型的 Service 来暴露，即创建外部负载均衡器来暴露流量，后续访问 ingress 的流量都走这个负载均衡器的地址，ingress 规则里面配的域名也要配置解析到这个负载均衡器的 IP 地址。\n这种方式需要集群支持 LoadBalancer 类型的 Service，如果是云厂商提供的 k8s 服务，或者在云上自建集群并使用了云厂商提供的 cloud provider，也都是支持的，创建 LoadBalancer 类型的 Service 的时候会自动调云厂商的接口创建云厂商提供的负载均衡器产品(通常公网类型的负载均衡器是付费的)；如果你的集群不是前面说的情况，是自建集群并且有自己的负载均衡器方案，并部署了相关插件来适配，比如 MetalLB 和 Porter，这样也是可以支持 LoadBalancer 类型的 Service 的。\n使用 helm 安装 helm install stable/traefik \\  --name traefik \\  --namespace kube-system \\  --set kubernetes.ingressClass=traefik \\  --set kubernetes.ingressEndpoint.useDefaultPublishedService=true \\  --set rbac.enabled=true  kubernetes.ingressClass=traefik: 创建的 ingress 中包含 kubernetes.io/ingress.class 这个 annotation 并且值与这里配置的一致，这个 traefik ingress controller 才会处理 (生成转发规则) kubernetes.ingressEndpoint.useDefaultPublishedService=true: 这个置为 true 主要是为了让 ingress 的外部地址正确显示 (显示为负载均衡器的地址)，因为如果不配置这个，默认情况下会将 ingress controller 所有实例的节点 ip 写到 ingress 的 address 里 rbac.enabled 默认为 false，如果没有事先给 default 的 service account 绑足够权限就会报错，通常置为 true，自动创建 rbac 规则  参考资料  Github 主页: https://github.com/containous/traefik helm hub 主页: https://hub.helm.sh/charts/stable/traefik 官方文档: https://docs.traefik.io  "
},
{
	"uri": "https://k8s.imroc.io/trick/shell/",
	"title": "实用命令与脚本",
	"tags": [],
	"description": "",
	"content": "目录：  Pod 相关脚本   网络调试相关脚本   节点相关脚本   "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/trick/capture-packets-in-container/",
	"title": "容器内抓包定位网络问题",
	"tags": [],
	"description": "",
	"content": "在使用 kubernetes 跑应用的时候，可能会遇到一些网络问题，比较常见的是服务端无响应(超时)或回包内容不正常，如果没找出各种配置上有问题，这时我们需要确认数据包到底有没有最终被路由到容器里，或者报文到达容器的内容和出容器的内容符不符合预期，通过分析报文可以进一步缩小问题范围。那么如何在容器内抓包呢？本文提供实用的脚本一键进入容器网络命名空间(netns)，使用宿主机上的tcpdump进行抓包。\n使用脚本一键进入 pod netns 抓包  发现某个服务不通，最好将其副本数调为1，并找到这个副本 pod 所在节点和 pod 名称  kubectl get pod -o wide  登录 pod 所在节点，将如下脚本粘贴到 shell (注册函数到当前登录的 shell，我们后面用)  function e() { set -eu ns=${2-\u0026#34;default\u0026#34;} pod=`kubectl -n $ns describe pod $1 | grep -A10 \u0026#34;^Containers:\u0026#34; | grep -Eo \u0026#39;docker://.*$\u0026#39; | head -n 1 | sed \u0026#39;s/docker:\\/\\/\\(.*\\)$/\\1/\u0026#39;` pid=`docker inspect -f {{.State.Pid}} $pod` echo \u0026#34;entering pod netns for $ns/$1\u0026#34; cmd=\u0026#34;nsenter -n --target $pid\u0026#34; echo $cmd $cmd }  一键进入 pod 所在的 netns，格式：e POD_NAME NAMESPACE，示例：  e istio-galley-58c7c7c646-m6568 istio-system e proxy-5546768954-9rxg6 # 省略 NAMESPACE 默认为 default  这时已经进入 pod 的 netns，可以执行宿主机上的 ip a 或 ifconfig 来查看容器的网卡，执行 netstat -tunlp 查看当前容器监听了哪些端口，再通过 tcpdump 抓包：  tcpdump -i eth0 -w test.pcap port 80  ctrl-c 停止抓包，再用 scp 或 sz 将抓下来的包下载到本地使用 wireshark 分析，提供一些常用的 wireshark 过滤语法：  # 使用 telnet 连上并发送一些测试文本，比如 \u0026#34;lbtest\u0026#34;， # 用下面语句可以看发送的测试报文有没有到容器 tcp contains \u0026#34;lbtest\u0026#34; # 如果容器提供的是http服务，可以使用 curl 发送一些测试路径的请求， # 通过下面语句过滤 uri 看报文有没有都容器 http.request.uri==\u0026#34;/mytest\u0026#34; 脚本原理 我们解释下步骤二中用到的脚本的原理\n 查看指定 pod 运行的容器 ID  kubectl describe pod \u0026lt;pod\u0026gt; -n mservice  获得容器进程的 pid  docker inspect -f {{.State.Pid}} \u0026lt;container\u0026gt;  进入该容器的 network namespace  nsenter -n --target \u0026lt;PID\u0026gt; 依赖宿主机的命名：kubectl, docker, nsenter, grep, head, sed\n"
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/pod/container-proccess-exit-by-itself/",
	"title": "容器进程主动退出",
	"tags": [],
	"description": "",
	"content": "容器进程如果是自己主动退出(不是被外界中断杀死)，退出状态码一般在 0-128 之间，根据约定，正常退出时状态码为 0，1-127 说明是程序发生异常，主动退出了，比如检测到启动的参数和条件不满足要求，或者运行过程中发生 panic 但没有捕获处理导致程序退出。除了可能是业务程序 BUG，还有其它许多可能原因，这里我们一一列举下。\nDNS 无法解析 可能程序依赖 集群 DNS 服务，比如启动时连接数据库，数据库使用 service 名称或外部域名都需要 DNS 解析，如果解析失败程序将报错并主动退出。解析失败的可能原因:\n 集群网络有问题，Pod 连不上集群 DNS 服务 集群 DNS 服务挂了，无法响应解析请求 Service 或域名地址配置有误，本身是无法解析的地址  程序配置有误  配置文件格式错误，程序启动解析配置失败报错退出 配置内容不符合规范，比如配置中某个字段是必选但没有填写，配置校验不通过，程序报错主动退出  "
},
{
	"uri": "https://k8s.imroc.io/cluster/network/understanding/",
	"title": "彻底理解集群网络",
	"tags": [],
	"description": "",
	"content": "什么是集群网络 TODO\nK8S 网络模型 TODO\n如何实现 K8S 集群网络 TODO\n公有云 K8S 服务是如何实现集群网络的 TODO\nCNI 插件 TODO\n开源网络方案 TODO\n参考资料  Cluster Networking: https://kubernetes.io/docs/concepts/cluster-administration/networking/  "
},
{
	"uri": "https://k8s.imroc.io/security/permission/app/",
	"title": "控制应用权限",
	"tags": [],
	"description": "",
	"content": "不仅用户 (人) 可以操作集群，应用 (程序) 也可以操作集群，通过给 Pod 设置 Serivce Account 来对应用进行授权，如果不设置会默认配置一个 \u0026ldquo;default\u0026rdquo; 的 Service Account，几乎没有权限。\n原理 创建 Pod 时，在 apiserver 中的 service account admission controller 检测 Pod 是否指定了 ServiceAccount，如果没有就自动设置一个 \u0026ldquo;default\u0026rdquo;，如果指定了会检测指定的 ServiceAccount 是否存在，不存在的话会拒绝该 Pod，存在话就将此 ServiceAccount 对应的 Secret 挂载到 Pod 中每个容器的 /var/run/secrets/kubernetes.io/serviceaccount 这个路径，这个 Secret 是 controller manager 中 token controller 去 watch ServiceAccount，为每个 ServiceAccount 生成对应的 token 类型的 Secret 得来的。\nPod 内的程序如果要调用 apiserver 接口操作集群，会使用 SDK，通常是 client-go ， SDK 使用 in-cluster 的方式调用 apiserver，从固定路径 /var/run/secrets/kubernetes.io/serviceaccount 读取认证配置信息去连 apiserver，从而实现认证，再结合 RBAC 配置可以实现权限控制。\n使用 RBAC 细化应用权限 ServiceAccount 仅针对某个命名空间，所以 Pod 指定的 ServiceAccount 只能引用当前命名空间的 ServiceAccount 的，即便是 \u0026ldquo;default\u0026rdquo; 每个命名空间也都是相互独立的，下面给出几个 RBAC 定义示例。\nbuild-robot 这个 ServiceAccount 可以读取 build 命名空间中 Pod 的信息和 log:\napiVersion: v1 kind: ServiceAccount metadata: name: build-robot namespace: build --- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: namespace: build name: pod-reader rules: - apiGroups: [\u0026#34;\u0026#34;] resources: [\u0026#34;pods\u0026#34;, \u0026#34;pods/log\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: read-pods namespace: build subjects: - kind: ServiceAccount name: build-robot apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io 为 Pod 指定 ServiceAccount 示例:\napiVersion: v1 kind: Pod metadata: name: build namespace: build spec: containers: - image: imroc/build-robot:v1 name: builder serviceAccountName: build-robot 为应用默认指定 imagePullSecrets  ServiceAccount 中也可以指定 imagePullSecrets，也就是只要给 Pod 指定了这个 ServiceAccount，就有对应的 imagePullSecrets，而如果不指定 ServiceAccount 会默认指定 \u0026ldquo;default\u0026rdquo;，我们可以给 \u0026ldquo;default\u0026rdquo; 这个 ServiceAccount 指定 imagePullSecrets 来实现给某个命名空间指定默认的 imagePullSecrets\n创建 imagePullSecrets:\nkubectl create secret docker-registry \u0026lt;secret-name\u0026gt; --docker-server=\u0026lt;your-registry-server\u0026gt; --docker-username=\u0026lt;your-name\u0026gt; --docker-password=\u0026lt;your-password\u0026gt; --docker-email=\u0026lt;your-email\u0026gt; -n \u0026lt;namespace\u0026gt;  \u0026lt;secret-name\u0026gt;: 是要创建的 imagePullSecrets 的名称 \u0026lt;namespace\u0026gt;: 是要创建的 imagePullSecrets 所在命名空间 \u0026lt;your-registry-server\u0026gt;: 是你的私有仓库的地址 \u0026lt;your-name\u0026gt;: 是你的 Docker 用户名 \u0026lt;your-password\u0026gt; 是你的 Docker 密码 \u0026lt;your-email\u0026gt; 是你的 Docker 邮箱  指定默认 imagePullSecrets:\nkubectl patch serviceaccount default -p \u0026#39;{\u0026#34;imagePullSecrets\u0026#34;: [{\u0026#34;name\u0026#34;: \u0026#34;\u0026lt;secret-name\u0026gt;\u0026#34;}]}\u0026#39; -n \u0026lt;namespace\u0026gt;  \u0026lt;secret-name\u0026gt;: 是 ServiceAccount 要关联的 imagePullSecrets 的名称 \u0026lt;namespace\u0026gt;: 是 ServiceAccount 所在的命名空间，跟 imagePullSecrets 在同一个命名空间  参考资料  Configure Service Accounts for Pods: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/  "
},
{
	"uri": "https://k8s.imroc.io/security/permission/user/",
	"title": "控制用户权限",
	"tags": [],
	"description": "",
	"content": "为了简单方便，小集群或测试环境集群我们通常使用最高权限的 admin 账号，可以做任何操作，但是如果是重要的生产环境集群，可以操作集群的人比较多，如果这时还用这个账号可能就会比较危险，一旦有人误操作或故意搞事就可能酿成大错，即使 apiserver 开启审计也无法知道是谁做的操作，所以最好控制下权限，根据人的级别或角色创建拥有对应权限的账号，这个可以通过 RBAC 来实现(确保 kube-apiserver 启动参数 --authorization-mode=RBAC)，基本思想是创建 User 或 ServiceAccount 绑定 Role 或 ClusterRole 来控制权限。\nUser 来源 User 的来源有多种:\n token 文件: 给 kube-apiserver 启动参数 --token-auth-file 传一个 token 认证文件，比如: --token-auth-file=/etc/kubernetes/known_tokens.csv  token 文件每一行表示一个用户，示例: wJmq****PPWj,admin,admin,system:masters 第一个字段是 token 的值，最后一个字段是用户组，token 认证用户名不重要，不会识别   证书: 通过使用 CA 证书给用户签发证书，签发的证书中 CN 字段是用户名，O 是用户组  使用 RBAC 控制用户权限  下面给出几个 RBAC 定义示例。\n给 roc 授权 test 命名空间所有权限，istio-system 命名空间的只读权限:\nkind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: admin namespace: test rules: - apiGroups: [\u0026#34;*\u0026#34;] resources: [\u0026#34;*\u0026#34;] verbs: [\u0026#34;*\u0026#34;] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: admin-to-roc namespace: test subjects: - kind: User name: roc apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: admin apiGroup: rbac.authorization.k8s.io --- kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: readonly namespace: istio-system rules: - apiGroups: [\u0026#34;*\u0026#34;] resources: [\u0026#34;*\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;list\u0026#34;] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: readonly-to-roc namespace: istio-system subjects: - kind: User name: roc apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: readonly apiGroup: rbac.authorization.k8s.io 给 roc 授权整个集群的只读权限:\nkind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: readonly rules: - apiGroups: [\u0026#34;*\u0026#34;] resources: [\u0026#34;*\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;list\u0026#34;] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: readonly-to-roc subjects: - kind: User name: roc apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: readonly apiGroup: rbac.authorization.k8s.io 给 manager 用户组里所有用户授权 secret 读权限:\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: secret-reader rules: - apiGroups: [\u0026#34;\u0026#34;] resources: [\u0026#34;secrets\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;list\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: read-secrets-global subjects: - kind: Group name: manager apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io 配置 kubeconfig # 如果使用证书认证，使用下面命令配置用户认证信息 kubectl config set-credentials \u0026lt;user\u0026gt; --embed-certs=true --client-certificate=\u0026lt;client-cert-file\u0026gt; --client-key=\u0026lt;client-key-file\u0026gt; # 如果使用 token 认证，使用下面命令配置用户认证信息 # kubectl config set-credentials \u0026lt;user\u0026gt; --token=\u0026#39;\u0026lt;token\u0026gt;\u0026#39; # 配置cluster entry kubectl config set-cluster \u0026lt;cluster\u0026gt; --server=\u0026lt;apiserver-url\u0026gt; --certificate-authority=\u0026lt;ca-cert-file\u0026gt; # 配置context entry kubectl config set-context \u0026lt;context\u0026gt; --cluster=\u0026lt;cluster\u0026gt; --user=\u0026lt;user\u0026gt; # 配置当前使用的context kubectl config use-context \u0026lt;context\u0026gt; # 查看 kubectl config view 参考资料  https://kubernetes.io/zh/docs/reference/access-authn-authz/service-accounts-admin/ https://kubernetes.io/docs/reference/access-authn-authz/rbac/  "
},
{
	"uri": "https://k8s.imroc.io/best-practice/wildcard-domain-forward/",
	"title": "泛域名转发",
	"tags": [],
	"description": "",
	"content": "需求 集群对外暴露了一个公网IP作为流量入口(可以是 Ingress 或 Service)，DNS 解析配置了一个泛域名指向该IP（比如 *.test.imroc.io），现希望根据请求中不同 Host 转发到不同的后端 Service。比如 a.test.imroc.io 的请求被转发到 my-svc-a，b.test.imroc.io 的请求转发到 my-svc-b。当前 K8S 的 Ingress 并不原生支持这种泛域名转发规则，本文将给出一个解决方案来实现泛域名转发。\n简单做法 先说一种简单的方法，这也是大多数人的第一反应：配置 Ingress 规则\n假如泛域名有两个不同 Host 分别转发到不同 Service，Ingress 类似这样写:\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: my-ingress spec: rules: - host: a.test.imroc.io http: paths: - backend: serviceName: my-svc-a servicePort: 80 path: / - host: b.test.imroc.io http: paths: - backend: serviceName: my-svc-b servicePort: 80 path: / 但是！如果 Host 非常多会怎样？（比如200+）\n 每次新增 Host 都要改 Ingress 规则，太麻烦 单个 Ingress 上面的规则越来越多，更改规则对 LB 的压力变大，可能会导致偶尔访问不了  正确姿势 我们可以约定请求中泛域名 Host 通配符的 * 号匹配到的字符跟 Service 的名字相关联（可以是相等，或者 Service 统一在前面加个前缀，比如 a.test.imroc.io 转发到 my-svc-a 这个 Service)，集群内起一个反向代理服务，匹配泛域名的请求全部转发到这个代理服务上，这个代理服务只做一件简单的事，解析 Host，正则匹配抓取泛域名中 * 号这部分，把它转换为 Service 名字，然后在集群里转发（集群 DNS 解析)\n这个反向代理服务可以是 Nginx+Lua脚本 来实现，或者自己写个简单程序来做反向代理，这里我用 OpenResty 来实现，它可以看成是 Nginx 的发行版，自带 lua 支持。\n有几点需要说明下：\n 我们使用 nginx 的 proxy_pass 来反向代理到后端服务，proxy_pass 后面跟的变量，我们需要用 lua 来判断 Host 修改变量 nginx 的 proxy_pass 后面跟的如果是可变的域名（非IP，需要 dns 解析)，它需要一个域名解析器，不会走默认的 dns 解析，需要在 nginx.conf 里添加 resolver 配置项来设置一个外部的 dns 解析器 这个解析器我们是用 go-dnsmasq 来实现，它可以将集群的 dns 解析代理给 nginx，以 sidecar 的形式注入到 pod 中，监听 53 端口  nginx.conf 里关键的配置如下图所示：\n下面给出完整的 yaml 示例\nproxy.yaml:\napiVersion: apps/v1beta1 kind: Deployment metadata: labels: component: nginx name: proxy spec: replicas: 1 selector: matchLabels: component: nginx template: metadata: labels: component: nginx spec: containers: - name: nginx image: \u0026#34;openresty/openresty:centos\u0026#34; ports: - name: http containerPort: 80 protocol: TCP volumeMounts: - mountPath: /usr/local/openresty/nginx/conf/nginx.conf name: config subPath: nginx.conf - name: dnsmasq image: \u0026#34;janeczku/go-dnsmasq:release-1.0.7\u0026#34; args: - --listen - \u0026#34;127.0.0.1:53\u0026#34; - --default-resolver - --append-search-domains - --hostsfile=/etc/hosts - --verbose volumes: - name: config configMap: name: configmap-nginx --- apiVersion: v1 kind: ConfigMap metadata: labels: component: nginx name: configmap-nginx data: nginx.conf: |- worker_processes 1; error_log /error.log; events { accept_mutex on; multi_accept on; use epoll; worker_connections 1024; } http { include mime.types; default_type application/octet-stream; log_format main \u0026#39;$time_local $remote_user $remote_addr $host $request_uri $request_method $http_cookie \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34; \u0026#39; \u0026#39;$request_time $upstream_response_time \u0026#34;$upstream_cache_status\u0026#34;\u0026#39;; log_format browser \u0026#39;$time_iso8601 $cookie_km_uid $remote_addr $host $request_uri $request_method \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34; \u0026#39; \u0026#39;$request_time $upstream_response_time \u0026#34;$upstream_cache_status\u0026#34; $http_x_requested_with $http_x_real_ip $upstream_addr $request_body\u0026#39;; log_format client \u0026#39;{\u0026#34;@timestamp\u0026#34;:\u0026#34;$time_iso8601\u0026#34;,\u0026#39; \u0026#39;\u0026#34;time_local\u0026#34;:\u0026#34;$time_local\u0026#34;,\u0026#39; \u0026#39;\u0026#34;remote_user\u0026#34;:\u0026#34;$remote_user\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_x_forwarded_for\u0026#34;:\u0026#34;$http_x_forwarded_for\u0026#34;,\u0026#39; \u0026#39;\u0026#34;host\u0026#34;:\u0026#34;$server_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;remote_addr\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_x_real_ip\u0026#34;:\u0026#34;$http_x_real_ip\u0026#34;,\u0026#39; \u0026#39;\u0026#34;body_bytes_sent\u0026#34;:$body_bytes_sent,\u0026#39; \u0026#39;\u0026#34;request_time\u0026#34;:$request_time,\u0026#39; \u0026#39;\u0026#34;status\u0026#34;:$status,\u0026#39; \u0026#39;\u0026#34;upstream_response_time\u0026#34;:\u0026#34;$upstream_response_time\u0026#34;,\u0026#39; \u0026#39;\u0026#34;upstream_response_status\u0026#34;:\u0026#34;$upstream_status\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request\u0026#34;:\u0026#34;$request\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_referer\u0026#34;:\u0026#34;$http_referer\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_user_agent\u0026#34;:\u0026#34;$http_user_agent\u0026#34;}\u0026#39;; access_log /access.log main; sendfile on; keepalive_timeout 120s 100s; keepalive_requests 500; send_timeout 60000s; client_header_buffer_size 4k; proxy_ignore_client_abort on; proxy_buffers 16 32k; proxy_buffer_size 64k; proxy_busy_buffers_size 64k; proxy_send_timeout 60000; proxy_read_timeout 60000; proxy_connect_timeout 60000; proxy_cache_valid 200 304 2h; proxy_cache_valid 500 404 2s; proxy_cache_key $host$request_uri$cookie_user; proxy_cache_methods GET HEAD POST; proxy_redirect off; proxy_http_version 1.1; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Frame-Options SAMEORIGIN; server_tokens off; client_max_body_size 50G; add_header X-Cache $upstream_cache_status; autoindex off; resolver 127.0.0.1:53 ipv6=off; server { listen 80; location / { set $service \u0026#39;\u0026#39;; rewrite_by_lua \u0026#39; local host = ngx.var.host local m = ngx.re.match(host, \u0026#34;(.+).test.imroc.io\u0026#34;) if m then ngx.var.service = \u0026#34;my-svc-\u0026#34; .. m[1] end \u0026#39;; proxy_pass http://$service; } } } 让该代理服务暴露公网访问可以用 Service 或 Ingress\n用 Service 的示例 (service.yaml):\napiVersion: v1 kind: Service metadata: labels: component: nginx name: service-nginx spec: type: LoadBalancer ports: - name: http port: 80 targetPort: http selector: component: nginx 用 Ingress 的示例 (ingress.yaml):\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: ingress-nginx spec: rules: - host: \u0026#34;*.test.imroc.io\u0026#34; http: paths: - backend: serviceName: service-nginx servicePort: 80 path: / "
},
{
	"uri": "https://k8s.imroc.io/security/user/",
	"title": "用户管理",
	"tags": [],
	"description": "",
	"content": "目录  利用 CSR API 创建用户     "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/handle/disk-full/",
	"title": "磁盘爆满",
	"tags": [],
	"description": "",
	"content": "什么情况下磁盘可能会爆满 ？ kubelet 有 gc 和驱逐机制，通过 --image-gc-high-threshold, --image-gc-low-threshold, --eviction-hard, --eviction-soft, --eviction-minimum-reclaim 等参数控制 kubelet 的 gc 和驱逐策略来释放磁盘空间，如果配置正确的情况下，磁盘一般不会爆满。\n通常导致爆满的原因可能是配置不正确或者节点上有其它非 K8S 管理的进程在不断写数据到磁盘占用大量空间导致磁盘爆满。\n磁盘爆满会有什么影响 ？ 影响 K8S 运行我们主要关注 kubelet 和容器运行时这两个最关键的组件，它们所使用的目录通常不一样，kubelet 一般不会单独挂盘，直接使用系统磁盘，因为通常占用空间不会很大，容器运行时单独挂盘的场景比较多，当磁盘爆满的时候我们也要看 kubelet 和 容器运行时使用的目录是否在这个磁盘，通过 df 命令可以查看磁盘挂载点。\n容器运行时使用的目录所在磁盘爆满 如果容器运行时使用的目录所在磁盘空间爆满，可能会造成容器运行时无响应，比如 docker，执行 docker 相关的命令一直 hang 住， kubelet 日志也可以看到 PLEG unhealthy，因为 CRI 调用 timeout，当然也就无法创建或销毁容器，通常表现是 Pod 一直 ContainerCreating 或 一直 Terminating。\ndocker 默认使用的目录主要有:\n /var/run/docker: 用于存储容器运行状态，通过 dockerd 的 --exec-root 参数指定。 /var/lib/docker: 用于持久化容器相关的数据，比如容器镜像、容器可写层数据、容器标准日志输出、通过 docker 创建的 volume 等  Pod 启动可能报类似下面的事件:\nWarning FailedCreatePodSandBox 53m kubelet, 172.22.0.44 Failed create pod sandbox: rpc error: code = DeadlineExceeded desc = context deadline exceeded Warning FailedCreatePodSandBox 2m (x4307 over 16h) kubelet, 10.179.80.31 (combined from similar events): Failed create pod sandbox: rpc error: code = Unknown desc = failed to create a sandbox for pod \u0026#34;apigateway-6dc48bf8b6-l8xrw\u0026#34;: Error response from daemon: mkdir /var/lib/docker/aufs/mnt/1f09d6c1c9f24e8daaea5bf33a4230de7dbc758e3b22785e8ee21e3e3d921214-init: no space left on device Warning Failed 5m1s (x3397 over 17h) kubelet, ip-10-0-151-35.us-west-2.compute.internal (combined from similar events): Error: container create failed: container_linux.go:336: starting container process caused \u0026#34;process_linux.go:399: container init caused \\\u0026#34;rootfs_linux.go:58: mounting \\\\\\\u0026#34;/sys\\\\\\\u0026#34; to rootfs \\\\\\\u0026#34;/var/lib/dockerd/storage/overlay/051e985771cc69f3f699895a1dada9ef6483e912b46a99e004af7bb4852183eb/merged\\\\\\\u0026#34; at \\\\\\\u0026#34;/var/lib/dockerd/storage/overlay/051e985771cc69f3f699895a1dada9ef6483e912b46a99e004af7bb4852183eb/merged/sys\\\\\\\u0026#34; caused \\\\\\\u0026#34;no space left on device\\\\\\\u0026#34;\\\u0026#34;\u0026#34; Pod 删除可能报类似下面的事件:\nNormal Killing 39s (x735 over 15h) kubelet, 10.179.80.31 Killing container with id docker://apigateway:Need to kill Pod kubelet 使用的目录所在磁盘爆满 如果 kubelet 使用的目录所在磁盘空间爆满(通常是系统盘)，新建 Pod 时连 Sandbox 都无法创建成功，因为 mkdir 将会失败，通常会有类似这样的 Pod 事件:\nWarning UnexpectedAdmissionError 44m kubelet, 172.22.0.44 Update plugin resources failed due to failed to write checkpoint file \u0026#34;kubelet_internal_checkpoint\u0026#34;: write /var/lib/kubelet/device-plugins/.728425055: no space left on device, which is unexpected. kubelet 默认使用的目录是 /var/lib/kubelet， 用于存储插件信息、Pod 相关的状态以及挂载的 volume (比如 emptyDir, ConfigMap, Secret)，通过 kubelet 的 --root-dir 参数指定。\n如何分析磁盘占用 ?  如果运行时使用的是 Docker，请参考本书 排错技巧: 分析 Docker 磁盘占用 (TODO)  如何恢复 ？ 如果容器运行时使用的 Docker，我们无法直接重启 dockerd 来释放一些空间，因为磁盘爆满后 dockerd 无法正常响应，停止的时候也会卡住。我们需要先手动清理一点文件腾出空间好让 dockerd 能够停止并重启。\n可以手动删除一些 docker 的 log 文件或可写层文件，通常删除 log:\n$ cd /var/lib/docker/containers $ du -sh * # 找到比较大的目录 $ cd dda02c9a7491fa797ab730c1568ba06cba74cecd4e4a82e9d90d00fa11de743c $ cat /dev/null \u0026gt; dda02c9a7491fa797ab730c1568ba06cba74cecd4e4a82e9d90d00fa11de743c-json.log.9 # 删除log文件  注意: 使用 cat /dev/null \u0026gt; 方式删除而不用 rm，因为用 rm 删除的文件，docker 进程可能不会释放文件，空间也就不会释放；log 的后缀数字越大表示越久远，先删除旧日志。  然后将该 node 标记不可调度，并将其已有的 pod 驱逐到其它节点，这样重启 dockerd 就会让该节点的 pod 对应的容器删掉，容器相关的日志(标准输出)与容器内产生的数据文件(没有挂载 volume, 可写层)也会被清理：\nkubectl drain \u0026lt;node-name\u0026gt; 重启 dockerd:\nsystemctl restart dockerd # or systemctl restart docker 等重启恢复，pod 调度到其它节点，排查磁盘爆满原因并清理和规避，然后取消节点不可调度标记:\nkubectl uncordon \u0026lt;node-name\u0026gt; 如何规避 ？ 正确配置 kubelet gc 和 驱逐相关的参数，即便到达爆满地步，此时节点上的 pod 也都早就自动驱逐到其它节点了，不会存在 Pod 一直 ContainerCreating 或 Terminating 的问题。\n"
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/kubernetes-overflow-and-drop/",
	"title": "神秘的溢出与丢包",
	"tags": [],
	"description": "",
	"content": "问题描述 有用户反馈大量图片加载不出来。\n图片下载走的 k8s ingress，这个 ingress 路径对应后端 service 是一个代理静态图片文件的 nginx deployment，这个 deployment 只有一个副本，静态文件存储在 nfs 上，nginx 通过挂载 nfs 来读取静态文件来提供图片下载服务，所以调用链是：client \u0026ndash;\u0026gt; k8s ingress \u0026ndash;\u0026gt; nginx \u0026ndash;\u0026gt; nfs。\n猜测 猜测: ingress 图片下载路径对应的后端服务出问题了。\n验证：在 k8s 集群直接 curl nginx 的 pod ip，发现不通，果然是后端服务的问题！\n抓包 继续抓包测试观察，登上 nginx pod 所在节点，进入容器的 netns 中：\n# 拿到 pod 中 nginx 的容器 id $ kubectl describe pod tcpbench-6484d4b457-847gl | grep -A10 \u0026#34;^Containers:\u0026#34; | grep -Eo \u0026#39;docker://.*$\u0026#39; | head -n 1 | sed \u0026#39;s/docker:\\/\\/\\(.*\\)$/\\1/\u0026#39; 49b4135534dae77ce5151c6c7db4d528f05b69b0c6f8b9dd037ec4e7043c113e # 通过容器 id 拿到 nginx 进程 pid $ docker inspect -f {{.State.Pid}} 49b4135534dae77ce5151c6c7db4d528f05b69b0c6f8b9dd037ec4e7043c113e 3985 # 进入 nginx 进程所在的 netns $ nsenter -n -t 3985 # 查看容器 netns 中的网卡信息，确认下 $ ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 3: eth0@if11: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default link/ether 56:04:c7:28:b0:3c brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.26.0.8/26 scope global eth0 valid_lft forever preferred_lft forever 使用 tcpdump 指定端口 24568 抓容器 netns 中 eth0 网卡的包:\ntcpdump -i eth0 -nnnn -ttt port 24568 在其它节点准备使用 nc 指定源端口为 24568 向容器发包：\nnc -u 24568 172.16.1.21 80 观察抓包结果：\n00:00:00.000000 IP 10.0.0.3.24568 \u0026gt; 172.16.1.21.80: Flags [S], seq 416500297, win 29200, options [mss 1424,sackOK,TS val 3000206334 ecr 0,nop,wscale 9], length 0 00:00:01.032218 IP 10.0.0.3.24568 \u0026gt; 172.16.1.21.80: Flags [S], seq 416500297, win 29200, options [mss 1424,sackOK,TS val 3000207366 ecr 0,nop,wscale 9], length 0 00:00:02.011962 IP 10.0.0.3.24568 \u0026gt; 172.16.1.21.80: Flags [S], seq 416500297, win 29200, options [mss 1424,sackOK,TS val 3000209378 ecr 0,nop,wscale 9], length 0 00:00:04.127943 IP 10.0.0.3.24568 \u0026gt; 172.16.1.21.80: Flags [S], seq 416500297, win 29200, options [mss 1424,sackOK,TS val 3000213506 ecr 0,nop,wscale 9], length 0 00:00:08.192056 IP 10.0.0.3.24568 \u0026gt; 172.16.1.21.80: Flags [S], seq 416500297, win 29200, options [mss 1424,sackOK,TS val 3000221698 ecr 0,nop,wscale 9], length 0 00:00:16.127983 IP 10.0.0.3.24568 \u0026gt; 172.16.1.21.80: Flags [S], seq 416500297, win 29200, options [mss 1424,sackOK,TS val 3000237826 ecr 0,nop,wscale 9], length 0 00:00:33.791988 IP 10.0.0.3.24568 \u0026gt; 172.16.1.21.80: Flags [S], seq 416500297, win 29200, options [mss 1424,sackOK,TS val 3000271618 ecr 0,nop,wscale 9], length 0 SYN 包到容器内网卡了，但容器没回 ACK，像是报文到达容器内的网卡后就被丢了。看样子跟防火墙应该也没什么关系，也检查了容器 netns 内的 iptables 规则，是空的，没问题。\n排除是 iptables 规则问题，在容器 netns 中使用 netstat -s 检查下是否有丢包统计:\n$ netstat -s | grep -E \u0026#39;overflow|drop\u0026#39; 12178939 times the listen queue of a socket overflowed 12247395 SYNs to LISTEN sockets dropped 果然有丢包，为了理解这里的丢包统计，我深入研究了一下，下面插播一些相关知识。\nsyn queue 与 accept queue Linux 进程监听端口时，内核会给它对应的 socket 分配两个队列：\n syn queue: 半连接队列。server 收到 SYN 后，连接会先进入 SYN_RCVD 状态，并放入 syn queue，此队列的包对应还没有完全建立好的连接（TCP 三次握手还没完成）。 accept queue: 全连接队列。当 TCP 三次握手完成之后，连接会进入 ESTABELISHED 状态并从 syn queue 移到 accept queue，等待被进程调用 accept() 系统调用 \u0026ldquo;拿走\u0026rdquo;。   注意：这两个队列的连接都还没有真正被应用层接收到，当进程调用 accept() 后，连接才会被应用层处理，具体到我们这个问题的场景就是 nginx 处理 HTTP 请求。\n 为了更好理解，可以看下这张 TCP 连接建立过程的示意图：\nlisten 与 accept 不管使用什么语言和框架，在写 server 端应用时，它们的底层在监听端口时最终都会调用 listen() 系统调用，处理新请求时都会先调用 accept() 系统调用来获取新的连接，然后再处理请求，只是有各自不同的封装而已，以 go 语言为例：\n// 调用 listen 监听端口 l, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:80\u0026#34;) if err != nil { panic(err) } for { // 不断调用 accept 获取新连接，如果 accept queue 为空就一直阻塞 \tconn, err := l.Accept() if err != nil { log.Println(\u0026#34;accept error:\u0026#34;, err) continue } // 每来一个新连接意味着一个新请求，启动协程处理请求 \tgo handle(conn) } Linux 的 backlog 内核既然给监听端口的 socket 分配了 syn queue 与 accept queue 两个队列，那它们有大小限制吗？可以无限往里面塞数据吗？当然不行！ 资源是有限的，尤其是在内核态，所以需要限制一下这两个队列的大小。那么它们的大小是如何确定的呢？我们先来看下 listen 这个系统调用:\nint listen(int sockfd, int backlog) 可以看到，能够传入一个整数类型的 backlog 参数，我们再通过 man listen 看下解释：\nThe behavior of the backlog argument on TCP sockets changed with Linux 2.2. Now it specifies the queue length for completely established sockets waiting to be accepted, instead of the number of incomplete connection requests. The maximum length of the queue for incomplete sockets can be set using /proc/sys/net/ipv4/tcp_max_syn_backlog. When syncookies are enabled there is no logical maximum length and this setting is ignored. See tcp(7) for more information. \nIf the backlog argument is greater than the value in /proc/sys/net/core/somaxconn, then it is silently truncated to that value; the default value in this file is 128. In kernels before 2.4.25, this limit was a hard coded value, SOMAXCONN, with the value 128.\n继续深挖了一下源码，结合这里的解释提炼一下：\n listen 的 backlog 参数同时指定了 socket 的 syn queue 与 accept queue 大小。 accept queue 最大不能超过 net.core.somaxconn 的值，即: max accept queue size = min(backlog, net.core.somaxconn)  如果启用了 syncookies (net.ipv4.tcp_syncookies=1)，当 syn queue 满了，server 还是可以继续接收 SYN 包并回复 SYN+ACK 给 client，只是不会存入 syn queue 了。因为会利用一套巧妙的 syncookies 算法机制生成隐藏信息写入响应的 SYN+ACK 包中，等 client 回 ACK 时，server 再利用 syncookies 算法校验报文，校验通过后三次握手就顺利完成了。所以如果启用了 syncookies，syn queue 的逻辑大小是没有限制的， syncookies 通常都是启用了的，所以一般不用担心 syn queue 满了导致丢包。syncookies 是为了防止 SYN Flood 攻击 (一种常见的 DDoS 方式)，攻击原理就是 client 不断发 SYN 包但不回最后的 ACK，填满 server 的 syn queue 从而无法建立新连接，导致 server 拒绝服务。 如果 syncookies 没有启用，syn queue 的大小就有限制，除了跟 accept queue 一样受 net.core.somaxconn 大小限制之外，还会受到 net.ipv4.tcp_max_syn_backlog 的限制，即: max syn queue size = min(backlog, net.core.somaxconn, net.ipv4.tcp_max_syn_backlog)   4.3 及其之前版本的内核，syn queue 的大小计算方式跟现在新版内核这里还不一样，详细请参考 commit ef547f2ac16b\n队列溢出 毫无疑问，在队列大小有限制的情况下，如果队列满了，再有新连接过来肯定就有问题。\n翻下 linux 源码，看下处理 SYN 包的部分，在 net/ipv4/tcp_input.c 的 tcp_conn_request 函数:\nif ((net-\u0026gt;ipv4.sysctl_tcp_syncookies == 2 || inet_csk_reqsk_queue_is_full(sk)) \u0026amp;\u0026amp; !isn) { want_cookie = tcp_syn_flood_action(sk, rsk_ops-\u0026gt;slab_name); if (!want_cookie) goto drop; } if (sk_acceptq_is_full(sk)) { NET_INC_STATS(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS); goto drop; } goto drop 最终会走到 tcp_listendrop 函数，实际上就是将 ListenDrops 计数器 +1:\nstatic inline void tcp_listendrop(const struct sock *sk) { atomic_inc(\u0026amp;((struct sock *)sk)-\u0026gt;sk_drops); __NET_INC_STATS(sock_net(sk), LINUX_MIB_LISTENDROPS); } 大致可以看出来，对于 SYN 包：\n 如果 syn queue 满了并且没有开启 syncookies 就丢包，并将 ListenDrops 计数器 +1。 如果 accept queue 满了也会丢包，并将 ListenOverflows 和 ListenDrops 计数器 +1。  而我们前面排查问题通过 netstat -s 看到的丢包统计，其实就是对应的 ListenOverflows 和 ListenDrops 这两个计数器。\n除了用 netstat -s，还可以使用 nstat -az 直接看系统内各个计数器的值:\n$ nstat -az | grep -E \u0026#39;TcpExtListenOverflows|TcpExtListenDrops\u0026#39; TcpExtListenOverflows 12178939 0.0 TcpExtListenDrops 12247395 0.0 另外，对于低版本内核，当 accept queue 满了，并不会完全丢弃 SYN 包，而是对 SYN 限速。把内核源码切到 3.10 版本，看 net/ipv4/tcp_ipv4.c 中 tcp_v4_conn_request 函数:\n/* Accept backlog is full. If we have already queued enough * of warm entries in syn queue, drop request. It is better than * clogging syn queue with openreqs with exponentially increasing * timeout. */ if (sk_acceptq_is_full(sk) \u0026amp;\u0026amp; inet_csk_reqsk_queue_young(sk) \u0026gt; 1) { NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS); goto drop; } 其中 inet_csk_reqsk_queue_young(sk) \u0026gt; 1 的条件实际就是用于限速，仿佛在对 client 说: 哥们，你慢点！我的 accept queue 都满了，即便咱们握手成功，连接也可能放不进去呀。\n回到问题上来 总结之前观察到两个现象：\n 容器内抓包发现收到 client 的 SYN，但 nginx 没回包。 通过 netstat -s 发现有溢出和丢包的统计 (ListenOverflows 与 ListenDrops)。  根据之前的分析，我们可以推测是 syn queue 或 accept queue 满了。\n先检查下 syncookies 配置:\n$ cat /proc/sys/net/ipv4/tcp_syncookies 1 确认启用了 syncookies，所以 syn queue 大小没有限制，不会因为 syn queue 满而丢包，并且即便没开启 syncookies，syn queue 有大小限制，队列满了也不会使 ListenOverflows 计数器 +1。\n从计数器结果来看，ListenOverflows 和 ListenDrops 的值差别不大，所以推测很有可能是 accept queue 满了，因为当 accept queue 满了会丢 SYN 包，并且同时将 ListenOverflows 与 ListenDrops 计数器分别 +1。\n如何验证 accept queue 满了呢？可以在容器的 netns 中执行 ss -lnt 看下:\n$ ss -lnt State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 129 128 *:80 *:* 通过这条命令我们可以看到当前 netns 中监听 tcp 80 端口的 socket，Send-Q 为 128，Recv-Q 为 129。\n什么意思呢？通过调研得知：\n 对于 LISTEN 状态，Send-Q 表示 accept queue 的最大限制大小，Recv-Q 表示其实际大小。 对于 ESTABELISHED 状态，Send-Q 和 Recv-Q 分别表示发送和接收数据包的 buffer。  所以，看这里输出结果可以得知 accept queue 满了，当 Recv-Q 的值比 Send-Q 大 1 时表明 accept queue 溢出了，如果再收到 SYN 包就会丢弃掉。\n导致 accept queue 满的原因一般都是因为进程调用 accept() 太慢了，导致大量连接不能被及时 \u0026ldquo;拿走\u0026rdquo;。\n那么什么情况下进程调用 accept() 会很慢呢？猜测可能是进程连接负载高，处理不过来。\n而负载高不仅可能是 CPU 繁忙导致，还可能是 IO 慢导致，当文件 IO 慢时就会有很多 IO WAIT，在 IO WAIT 时虽然 CPU 不怎么干活，但也会占据 CPU 时间片，影响 CPU 干其它活。\n最终进一步定位发现是 nginx pod 挂载的 nfs 服务对应的 nfs server 负载较高，导致 IO 延时较大，从而使 nginx 调用 accept() 变慢，accept queue 溢出，使得大量代理静态图片文件的请求被丢弃，也就导致很多图片加载不出来。\n虽然根因不是 k8s 导致的问题，但也从中挖出一些在高并发场景下值得优化的点，请继续往下看。\nsomaxconn 的默认值很小 我们再看下之前 ss -lnt 的输出:\n$ ss -lnt State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 129 128 *:80 *:* 仔细一看，Send-Q 表示 accept queue 最大的大小，才 128 ？也太小了吧！\n根据前面的介绍我们知道，accept queue 的最大大小会受 net.core.somaxconn 内核参数的限制，我们看下 pod 所在节点上这个内核参数的大小:\n$ cat /proc/sys/net/core/somaxconn 32768 是 32768，挺大的，为什么这里 accept queue 最大大小就只有 128 了呢？\nnet.core.somaxconn 这个内核参数是 namespace 隔离了的，我们在容器 netns 中再确认了下：\n$ cat /proc/sys/net/core/somaxconn 128 为什么只有 128？看下 stackoverflow 这里 的讨论:\nThe \u0026quot;net/core\u0026quot; subsys is registered per network namespace. And the initial value for somaxconn is set to 128.\n原来新建的 netns 中 somaxconn 默认就为 128，在 include/linux/socket.h 中可以看到这个常量的定义:\n/* Maximum queue length specifiable by listen. */ #define SOMAXCONN\t128 很多人在使用 k8s 时都没太在意这个参数，为什么大家平常在较高并发下也没发现有问题呢？\n因为通常进程 accept() 都是很快的，所以一般 accept queue 基本都没什么积压的数据，也就不会溢出导致丢包了。\n对于并发量很高的应用，还是建议将 somaxconn 调高。虽然可以进入容器 netns 后使用 sysctl -w net.core.somaxconn=1024 或 echo 1024 \u0026gt; /proc/sys/net/core/somaxconn 临时调整，但调整的意义不大，因为容器内的进程一般在启动的时候才会调用 listen()，然后 accept queue 的大小就被决定了，并且不再改变。\n下面介绍几种调整方式:\n方式一: 使用 k8s sysctls 特性直接给 pod 指定内核参数 示例 yaml:\napiVersion: v1 kind: Pod metadata: name: sysctl-example spec: securityContext: sysctls: - name: net.core.somaxconn value: \u0026#34;8096\u0026#34; 有些参数是 unsafe 类型的，不同环境不一样，我的环境里是可以直接设置 pod 的 net.core.somaxconn 这个 sysctl 的。如果你的环境不行，请参考官方文档 Using sysctls in a Kubernetes Cluster 启用 unsafe 类型的 sysctl。\n 注：此特性在 k8s v1.12 beta，默认开启。\n 方式二: 使用 initContainers 设置内核参数 示例 yaml:\napiVersion: v1 kind: Pod metadata: name: sysctl-example-init spec: initContainers: - image: busybox command: - sh - -c - echo 1024 \u0026gt; /proc/sys/net/core/somaxconn imagePullPolicy: Always name: setsysctl securityContext: privileged: true Containers: ...  注: init container 需要 privileged 权限。\n 方式三: 安装 tuning CNI 插件统一设置 sysctl tuning plugin 地址: https://github.com/containernetworking/plugins/tree/master/plugins/meta/tuning\nCNI 配置示例:\n{ \u0026#34;name\u0026#34;: \u0026#34;mytuning\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;tuning\u0026#34;, \u0026#34;sysctl\u0026#34;: { \u0026#34;net.core.somaxconn\u0026#34;: \u0026#34;1024\u0026#34; } } nginx 的 backlog 我们使用方式一尝试给 nginx pod 的 somaxconn 调高到 8096 后观察:\n$ ss -lnt State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 512 511 *:80 *:* WTF? 还是溢出了，而且调高了 somaxconn 之后虽然 accept queue 的最大大小 (Send-Q) 变大了，但跟 8096 还差很远呀！\n在经过一番研究，发现 nginx 在 listen() 时并没有读取 somaxconn 作为 backlog 默认值传入，它有自己的默认值，也支持在配置里改。通过 ngx_http_core_module 的官方文档我们可以看到它在 linux 下的默认值就是 511:\nbacklog=number sets the backlog parameter in the listen() call that limits the maximum length for the queue of pending connections. By default, backlog is set to -1 on FreeBSD, DragonFly BSD, and macOS, and to 511 on other platforms. 配置示例:\nlisten 80 default backlog=1024; 所以，在容器中使用 nginx 来支撑高并发的业务时，记得要同时调整下 net.core.somaxconn 内核参数和 nginx.conf 中的 backlog 配置。\n参考资料  Using sysctls in a Kubernetes Cluster: https://kubernetes-io-vnext-staging.netlify.com/docs/tasks/administer-cluster/sysctl-cluster/ SYN packet handling in the wild: https://blog.cloudflare.com/syn-packet-handling-in-the-wild/ "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/network/low-throughput/",
	"title": "网络性能差",
	"tags": [],
	"description": "",
	"content": "IPVS 模式吞吐性能低 内核参数关闭 conn_reuse_mode:\nsysctl net.ipv4.vs.conn_reuse_mode=0 参考 issue: https://github.com/kubernetes/kubernetes/issues/70747\n"
},
{
	"uri": "https://k8s.imroc.io/cluster/network/",
	"title": "网络方案",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/trick/shell/network/",
	"title": "网络调试相关脚本",
	"tags": [],
	"description": "",
	"content": "进入容器 netns 粘贴脚本到命令行:\nfunction e() { set -eu ns=${2-\u0026#34;default\u0026#34;} pod=`kubectl -n $ns describe pod $1 | grep -A10 \u0026#34;^Containers:\u0026#34; | grep -Eo \u0026#39;docker://.*$\u0026#39; | head -n 1 | sed \u0026#39;s/docker:\\/\\/\\(.*\\)$/\\1/\u0026#39;` pid=`docker inspect -f {{.State.Pid}} $pod` echo \u0026#34;entering pod netns for $ns/$1\u0026#34; cmd=\u0026#34;nsenter -n --target $pid\u0026#34; echo $cmd $cmd } 进入在当前节点上运行的某个 pod 的 netns:\n# 进入 kube-system 命名空间下名为 metrics-server-6cf9685556-rclw5 的 pod 所在的 netns e metrics-server-6cf9685556-rclw5 kube-system 进入 pod 的 netns 后就使用节点上的工具在该 netns 中做操作，比如用 ip a 查询网卡和ip、用 ip route 查询路由、用 tcpdump 抓容器内的包等。\n不断尝试建立TCP连接测试网络连通性 while true; do echo \u0026#34;\u0026#34; | telnet 10.0.0.3 443; sleep 0.1; done  ctrl+c 终止测试 替换 10.0.0.3 与 443 为需要测试的 IP/域名 和端口  "
},
{
	"uri": "https://k8s.imroc.io/trick/shell/node/",
	"title": "节点相关脚本",
	"tags": [],
	"description": "",
	"content": "表格输出各节点占用的 podCIDR kubectl get no -o=custom-columns=INTERNAL-IP:.metadata.name,EXTERNAL-IP:.status.addresses[1].address,CIDR:.spec.podCIDR 示例输出:\nINTERNAL-IP EXTERNAL-IP CIDR 10.100.12.194 152.136.146.157 10.101.64.64/27 10.100.16.11 10.100.16.11 10.101.66.224/27 10.100.16.24 10.100.16.24 10.101.64.32/27 10.100.16.26 10.100.16.26 10.101.65.0/27 10.100.16.37 10.100.16.37 10.101.64.0/27 表格输出各节点总可用资源 (Allocatable) kubectl get no -o=custom-columns=\u0026#34;NODE:.metadata.name,ALLOCATABLE CPU:.status.allocatable.cpu,ALLOCATABLE MEMORY:.status.allocatable.memory\u0026#34; 示例输出：\nNODE ALLOCATABLE CPU ALLOCATABLE MEMORY 10.0.0.2 3920m 7051692Ki 10.0.0.3 3920m 7051816Ki 输出各节点已分配资源的情况 所有种类的资源已分配情况概览：\nkubectl get nodes --no-headers | awk \u0026#39;{print $1}\u0026#39; | xargs -I {} sh -c \u0026#34;echo {} ; kubectl describe node {} | grep Allocated -A 5 | grep -ve Event -ve Allocated -ve percent -ve --;\u0026#34; 示例输出:\n10.0.0.2 Resource Requests Limits cpu 3040m (77%) 19800m (505%) memory 4843402752 (67%) 15054901888 (208%) 10.0.0.3 Resource Requests Limits cpu 300m (7%) 1 (25%) memory 250M (3%) 2G (27%) 表格输出 cpu 已分配情况:\nkubectl get nodes --no-headers | awk \u0026#39;{print $1}\u0026#39; | xargs -I {} sh -c \u0026#39;echo -n \u0026#34;{}\\t\u0026#34; ; kubectl describe node {} | grep Allocated -A 5 | grep -ve Event -ve Allocated -ve percent -ve -- | grep cpu | awk \u0026#39;\\\u0026#39;\u0026#39;{print $2$3}\u0026#39;\\\u0026#39;\u0026#39;;\u0026#39; 示例输出：\n10.0.0.2\t3040m(77%) 10.0.0.3\t300m(7%) 表格输出 memory 已分配情况:\nkubectl get nodes --no-headers | awk \u0026#39;{print $1}\u0026#39; | xargs -I {} sh -c \u0026#39;echo -n \u0026#34;{}\\t\u0026#34; ; kubectl describe node {} | grep Allocated -A 5 | grep -ve Event -ve Allocated -ve percent -ve -- | grep memory | awk \u0026#39;\\\u0026#39;\u0026#39;{print $2$3}\u0026#39;\\\u0026#39;\u0026#39;;\u0026#39; 示例输出：\n10.0.0.2\t4843402752(67%) 10.0.0.3\t250M(3%) 线程数排名统计 printf \u0026#34; NUM PID\\t\\tCOMMAND\\n\u0026#34; \u0026amp;\u0026amp; ps -eLf | awk \u0026#39;{$1=null;$3=null;$4=null;$5=null;$6=null;$7=null;$8=null;$9=null;print}\u0026#39; | sort |uniq -c |sort -rn | head -10 示例输出:\nNUM PID\tCOMMAND 594 14418 java -server -Dspring.profiles.active=production -Xms2048M -Xmx2048M -Xss256k -Dinfo.app.version=33 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/gather-server/gather-server-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/gather-server -Dserver.tomcat.accesslog.directory=/home/log/gather-server -jar /home/app/gather-server.jar --server.port=8080 --management.port=10086 449 7088 java -server -Dspring.profiles.active=production -Dspring.cloud.config.token=nLfe-bQ0CcGnNZ_Q4Pt9KTizgRghZrGUVVqaDZYHU3R-Y_-U6k7jkm8RrBn7LPJD -Xms4256M -Xmx4256M -Xss256k -XX:+PrintFlagsFinal -XX:+UseG1GC -XX:+UseStringDeduplication -XX:MaxGCPauseMillis=200 -XX:MetaspaceSize=128M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -verbosegc -XX:+PrintGCDateStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=15 -XX:GCLogFileSize=50M -XX:AutoBoxCacheMax=520 -Xloggc:/home/log/oauth-server/oauth-server-gac.log -Dinfo.app.version=12 -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.config=classpath:log4j2-spring-prod.xml -Dlogging.path=/home/log/oauth-server -Dserver.tomcat.accesslog.directory=/home/log/oauth-server -jar /home/app/oauth-server.jar --server.port=8080 --management.port=10086 --zuul.server.netty.threads.worker=14 --zuul.server.netty.socket.epoll=true 394 516 java -server -Dspring.profiles.active=production -Xms2048M -Xmx2048M -Xss1024k -Dinfo.app.version=43 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/asset-server/asset-server-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/asset-server -Dserver.tomcat.accesslog.directory=/home/log/asset-server -jar /home/app/asset-server.jar --server.port=8080 --management.port=10086 305 14668 java -server -Dspring.profiles.active=production -Xms1024M -Xmx1024M -Xss256k -Dinfo.app.version=3 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/talent-adapter-distribute/talent-adapter-distribute-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/talent-adapter-distribute -Dserver.tomcat.accesslog.directory=/home/log/talent-adapter-distribute -jar /home/app/talent-adapter-distribute.jar --server.port=8080 --management.port=10086 250 3979 java -server -Dspring.profiles.active=production -Xms2048M -Xmx2048M -Xss256k -Dinfo.app.version=20 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/uc-facade-server/uc-facade-server-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/uc-facade-server -Dserver.tomcat.accesslog.directory=/home/log/uc-facade-server -jar /home/app/uc-facade-server.jar --server.port=8080 --management.port=10086 246 12468 java -server -Dspring.profiles.active=production -Xms2048M -Xmx2048M -Xss256k -Dinfo.app.version=7 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/talent-user-server/talent-user-server-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/talent-user-server -Dserver.tomcat.accesslog.directory=/home/log/talent-user-server -jar /home/app/talent-user-server.jar --server.port=8080 --management.port=10086 242 19401 java -server -Dspring.profiles.active=production -Xms1024M -Xmx1024M -Xss256k -Dinfo.app.version=25 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/job-admin-server/job-admin-server-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/job-admin-server -Dserver.tomcat.accesslog.directory=/home/log/job-admin-server -jar /home/app/job-admin-server.jar --server.port=8080 --management.port=10086 213 539 java -server -Dspring.profiles.active=production -Xms512M -Xmx3072M -Xss256k -Dinfo.app.version=1 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/family-aplus-web/family-aplus-web-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/family-aplus-web -Dserver.tomcat.accesslog.directory=/home/log/family-aplus-web -jar /home/app/family-aplus-web.jar --server.port=8080 --management.port=10086 187 9357 java -server -Dspring.profiles.active=production -Xms2048M -Xmx2048M -Xss256k -Dinfo.app.version=2 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/orion-panel-server/orion-panel-server-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/orion-panel-server -Dserver.tomcat.accesslog.directory=/home/log/orion-panel-server -jar /home/app/orion-panel-server.jar --server.port=8080 --management.port=10086 181 14267 java -server -Dspring.profiles.active=production -Xms1024M -Xmx1024M -Xss256k -Dinfo.app.version=6 -XX:+UseG1GC -XX:+UseStringDeduplication -XX:+PrintGCDateStamps -verbosegc -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=10011 -Xloggc:/home/log/talent-mission-server/talent-mission-server-gac.log -Ddefault.client.encoding=UTF-8 -Dfile.encoding=UTF-8 -Dlogging.path=/home/log/talent-mission-server -Dserver.tomcat.accesslog.directory=/home/log/talent-mission-server -jar /home/app/talent-mission-server.jar --server.port=8080 --management.port=10086  第一列表示线程数 第二列表示进程 PID 第三列是进程启动命令  "
},
{
	"uri": "https://k8s.imroc.io/avoid/scale-keepalive-service/",
	"title": "解决长连接服务扩容失效",
	"tags": [],
	"description": "",
	"content": "在现网运营中，有很多场景为了提高效率，一般都采用建立长连接的方式来请求。我们发现在客户端以长连接请求服务端的场景下，K8S的自动扩容会失效。原因是客户端长连接一直保留在老的Pod容器中，新扩容的Pod没有新的连接过来，导致K8S按照步长扩容第一批Pod之后就停止了扩容操作，而且新扩容的Pod没能承载请求，进而出现服务过载的情况，自动扩容失去了意义。\n对长连接扩容失效的问题，我们的解决方法是将长连接转换为短连接。我们参考了 nginx keepalive 的设计，nginx 中 keepalive_requests 这个配置项设定了一个TCP连接能处理的最大请求数，达到设定值(比如1000)之后服务端会在 http 的 Header 头标记 “Connection:close”，通知客户端处理完当前的请求后关闭连接，新的请求需要重新建立TCP连接，所以这个过程中不会出现请求失败，同时又达到了将长连接按需转换为短连接的目的。通过这个办法客户端和云K8S服务端处理完一批请求后不断的更新TCP连接，自动扩容的新Pod能接收到新的连接请求，从而解决了自动扩容失效的问题。\n由于Golang并没有提供方法可以获取到每个连接处理过的请求数，我们重写了 net.Listener 和 net.Conn，注入请求计数器，对每个连接处理的请求做计数，并通过 net.Conn.LocalAddr() 获得计数值，判断达到阈值 1000 后在返回的 Header 中插入 “Connection:close” 通知客户端关闭连接，重新建立连接来发起请求。以上处理逻辑用 Golang 实现示例代码如下：\npackage main import ( \u0026#34;net\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) // 重新定义net.Listener type counterListener struct { net.Listener } // 重写net.Listener.Accept(),对接收到的连接注入请求计数器 func (c *counterListener) Accept() (net.Conn, error) { conn, err := c.Listener.Accept() if err != nil { return nil, err } return \u0026amp;counterConn{Conn: conn}, nil } // 定义计数器counter和计数方法Increment() type counter int func (c *counter) Increment() int { *c++ return int(*c) } // 重新定义net.Conn,注入计数器ct type counterConn struct { net.Conn ct counter } // 重写net.Conn.LocalAddr()，返回本地网络地址的同时返回该连接累计处理过的请求数 func (c *counterConn) LocalAddr() net.Addr { return \u0026amp;counterAddr{c.Conn.LocalAddr(), \u0026amp;c.ct} } // 定义TCP连接计数器,指向连接累计请求的计数器 type counterAddr struct { net.Addr *counter } func main() { r := gin.New() r.Use(func(c *gin.Context) { localAddr := c.Request.Context().Value(http.LocalAddrContextKey) if ct, ok := localAddr.(interface{ Increment() int }); ok { if ct.Increment() \u0026gt;= 1000 { c.Header(\u0026#34;Connection\u0026#34;, \u0026#34;close\u0026#34;) } } c.Next() }) r.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { c.String(200, \u0026#34;plain/text\u0026#34;, \u0026#34;hello\u0026#34;) }) l, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:8080\u0026#34;) if err != nil { panic(err) } err = http.Serve(\u0026amp;counterListener{l}, r) if err != nil { panic(err) } } "
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/lb-with-local-externaltrafficpolicy-timeout-occasionally/",
	"title": "访问 externalTrafficPolicy 为 Local 的 Service 对应 LB 有时超时",
	"tags": [],
	"description": "",
	"content": "现象：用户在 TKE 创建了公网 LoadBalancer 类型的 Service，externalTrafficPolicy 设为了 Local，访问这个 Service 对应的公网 LB 有时会超时。\nexternalTrafficPolicy 为 Local 的 Service 用于在四层获取客户端真实源 IP，官方参考文档：Source IP for Services with Type=LoadBalancer\nTKE 的 LoadBalancer 类型 Service 实现是使用 CLB 绑定所有节点对应 Service 的 NodePort，CLB 不做 SNAT，报文转发到 NodePort 时源 IP 还是真实的客户端 IP，如果 NodePort 对应 Service 的 externalTrafficPolicy 不是 Local 的就会做 SNAT，到 pod 时就看不到客户端真实源 IP 了，但如果是 Local 的话就不做 SNAT，如果本机 node 有这个 Service 的 endpoint 就转到对应 pod，如果没有就直接丢掉，因为如果转到其它 node 上的 pod 就必须要做 SNAT，不然无法回包，而 SNAT 之后就无法获取真实源 IP 了。\nLB 会对绑定节点的 NodePort 做健康检查探测，检查 LB 的健康检查状态: 发现这个 NodePort 的所有节点都不健康 !!!\n那么问题来了:\n 为什么会全不健康，这个 Service 有对应的 pod 实例，有些节点上是有 endpoint 的，为什么它们也不健康? LB 健康检查全不健康，但是为什么有时还是可以访问后端服务?  跟 LB 的同学确认: 如果后端 rs 全不健康会激活 LB 的全死全活逻辑，也就是所有后端 rs 都可以转发。\n那么有 endpoint 的 node 也是不健康这个怎么解释?\n在有 endpoint 的 node 上抓 NodePort 的包: 发现很多来自 LB 的 SYN，但是没有响应 ACK。\n看起来报文在哪被丢了，继续抓下 cbr0 看下: 发现没有来自 LB 的包，说明报文在 cbr0 之前被丢了。\n再观察用户集群环境信息:\n k8s 版本1.12 启用了 ipvs 只有 local 的 service 才有异常  尝试新建一个 1.12 启用 ipvs 和一个没启用 ipvs 的测试集群。也都创建 Local 的 LoadBalancer Service，发现启用 ipvs 的测试集群复现了那个问题，没启用 ipvs 的集群没这个问题。\n再尝试创建 1.10 的集群，也启用 ipvs，发现没这个问题。\n看起来跟集群版本和是否启用 ipvs 有关。\n1.12 对比 1.10 启用 ipvs 的集群: 1.12 的会将 LB 的 EXTERNAL-IP 绑到 kube-ipvs0 上，而 1.10 的不会:\n$ ip a show kube-ipvs0 | grep -A2 170.106.134.124 inet 170.106.134.124/32 brd 170.106.134.124 scope global kube-ipvs0 valid_lft forever preferred_lft forever  170.106.134.124 是 LB 的公网 IP 1.12 启用 ipvs 的集群将 LB 的公网 IP 绑到了 kube-ipvs0 网卡上  kube-ipvs0 是一个 dummy interface，实际不会接收报文，可以看到它的网卡状态是 DOWN，主要用于绑 ipvs 规则的 VIP，因为 ipvs 主要工作在 netfilter 的 INPUT 链，报文通过 PREROUTING 链之后需要决定下一步该进入 INPUT 还是 FORWARD 链，如果是本机 IP 就会进入 INPUT，如果不是就会进入 FORWARD 转发到其它机器。所以 k8s 利用 kube-ipvs0 这个网卡将 service 相关的 VIP 绑在上面以便让报文进入 INPUT 进而被 ipvs 转发。\n当 IP 被绑到 kube-ipvs0 上，内核会自动将上面的 IP 写入 local 路由:\n$ ip route show table local | grep 170.106.134.124 local 170.106.134.124 dev kube-ipvs0 proto kernel scope host src 170.106.134.124 内核认为在 local 路由里的 IP 是本机 IP，而 linux 默认有个行为: 忽略任何来自非回环网卡并且源 IP 是本机 IP 的报文。而 LB 的探测报文源 IP 就是 LB IP，也就是 Service 的 EXTERNAL-IP 猜想就是因为这个 IP 被绑到 kube-ipvs0，自动加进 local 路由导致内核直接忽略了 LB 的探测报文。\n带着猜想做实现， 试一下将 LB IP 从 local 路由中删除:\nip route del table local local 170.106.134.124 dev kube-ipvs0 proto kernel scope host src 170.106.134.124 发现这个 node 的在 LB 的健康检查的状态变成健康了! 看来就是因为这个 LB IP 被绑到 kube-ipvs0 导致内核忽略了来自 LB 的探测报文，然后 LB 收不到回包认为不健康。\n那为什么其它厂商没反馈这个问题？应该是 LB 的实现问题，腾讯云的公网 CLB 的健康探测报文源 IP 就是 LB 的公网 IP，而大多数厂商的 LB 探测报文源 IP 是保留 IP 并非 LB 自身的 VIP。\n如何解决呢? 发现一个内核参数: accept_local 可以让 linux 接收源 IP 是本机 IP 的报文。\n试了开启这个参数，确实在 cbr0 收到来自 LB 的探测报文了，说明报文能被 pod 收到，但抓 eth0 还是没有给 LB 回包。\n为什么没有回包? 分析下五元组，要给 LB 回包，那么 目的IP:目的Port 必须是探测报文的 源IP:源Port，所以目的 IP 就是 LB IP，由于容器不在主 netns，发包经过 veth pair 到 cbr0 之后需要再经过 netfilter 处理，报文进入 PREROUTING 链然后发现目的 IP 是本机 IP，进入 INPUT 链，所以报文就出不去了。再分析下进入 INPUT 后会怎样，因为目的 Port 跟 LB 探测报文源 Port 相同，是一个随机端口，不在 Service 的端口列表，所以没有对应的 IPVS 规则，IPVS 也就不会转发它，而 kube-ipvs0 上虽然绑了这个 IP，但它是一个 dummy interface，不会收包，所以报文最后又被忽略了。\n再看看为什么 1.12 启用 ipvs 会绑 EXTERNAL-IP 到 kube-ipvs0，翻翻 k8s 的 kube-proxy 支持 ipvs 的 proposal，发现有个地方说法有点漏洞:\nLB 类型 Service 的 status 里有 ingress IP，实际就是 kubectl get service 看到的 EXTERNAL-IP，这里说不会绑定这个 IP 到 kube-ipvs0，但后面又说会给它创建 ipvs 规则，既然没有绑到 kube-ipvs0，那么这个 IP 的报文根本不会进入 INPUT 被 ipvs 模块转发，创建的 ipvs 规则也是没用的。\n后来找到作者私聊，思考了下，发现设计上确实有这个问题。\n看了下 1.10 确实也是这么实现的，但是为什么 1.12 又绑了这个 IP 呢? 调研后发现是因为 #59976 这个 issue 发现一个问题，后来引入 #63066 这个 PR 修复的，而这个 PR 的行为就是让 LB IP 绑到 kube-ipvs0，这个提交影响 1.11 及其之后的版本。\n#59976 的问题是因为没绑 LB IP到 kube-ipvs0 上，在自建集群使用 MetalLB 来实现 LoadBalancer 类型的 Service，而有些网络环境下，pod 是无法直接访问 LB 的，导致 pod 访问 LB IP 时访问不了，而如果将 LB IP 绑到 kube-ipvs0 上就可以通过 ipvs 转发到 LB 类型 Service 对应的 pod 去， 而不需要真正经过 LB，所以引入了 #63066 这个PR。\n临时方案: 将 #63066 这个 PR 的更改回滚下，重新编译 kube-proxy，提供升级脚本升级存量 kube-proxy。\n如果是让 LB 健康检查探测支持用保留 IP 而不是自身的公网 IP ，也是可以解决，但需要跨团队合作，而且如果多个厂商都遇到这个问题，每家都需要为解决这个问题而做开发调整，代价较高，所以长期方案需要跟社区沟通一起推进，所以我提了 issue，将问题描述的很清楚: #79783\n小思考: 为什么 CLB 可以不做 SNAT ? 回包目的 IP 就是真实客户端 IP，但客户端是直接跟 LB IP 建立的连接，如果回包不经过 LB 是不可能发送成功的呀。\n是因为 CLB 的实现是在母机上通过隧道跟 CVM 互联的，多了一层封装，回包始终会经过 LB。\n就是因为 CLB 不做 SNAT，正常来自客户端的报文是可以发送到 nodeport，但健康检查探测报文由于源 IP 是 LB IP 被绑到 kube-ipvs0 导致被忽略，也就解释了为什么健康检查失败，但通过LB能访问后端服务，只是有时会超时。那么如果要做 SNAT 的 LB 岂不是更糟糕，所有报文都变成 LB IP，所有报文都会被忽略?\n我提的 issue 有回复指出，AWS 的 LB 会做 SNAT，但它们不将 LB 的 IP 写到 Service 的 Status 里，只写了 hostname，所以也不会绑 LB IP 到 kube-ipvs0:\n但是只写 hostname 也得 LB 支持自动绑域名解析，并且个人觉得只写 hostname 很别扭，通过 kubectl get svc 或者其它 k8s 管理系统无法直接获取 LB IP，这不是一个好的解决方法。\n我提了 #79976 这个 PR 可以解决问题: 给 kube-proxy 加 --exclude-external-ip 这个 flag 控制是否为 LB IP 创建 ipvs 规则和绑定 kube-ipvs0。\n但有人担心增加 kube-proxy flag 会增加 kube-proxy 的调试复杂度，看能否在 iptables 层面解决: 仔细一想，确实可行，打算有空实现下，重新提个 PR: "
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/no-route-to-host/",
	"title": "诡异的 No route to host",
	"tags": [],
	"description": "",
	"content": "问题反馈 有用户反馈 Deployment 滚动更新的时候，业务日志偶尔会报 \u0026ldquo;No route to host\u0026rdquo; 的错误。\n分析 之前没遇到滚动更新会报 \u0026ldquo;No route to host\u0026rdquo; 的问题，我们先看下滚动更新导致连接异常有哪些常见的报错:\n  Connection reset by peer: 连接被重置。通常是连接建立过，但 server 端发现 client 发的包不对劲就返回 RST，应用层就报错连接被重置。比如在 server 滚动更新过程中，client 给 server 发的请求还没完全结束，或者本身是一个类似 grpc 的多路复用长连接，当 server 对应的旧 Pod 删除(没有做优雅结束，停止时没有关闭连接)，新 Pod 很快创建启动并且刚好有跟之前旧 Pod 一样的 IP，这时 kube-proxy 也没感知到这个 IP 其实已经被删除然后又被重建了，针对这个 IP 的规则就不会更新，旧的连接依然发往这个 IP，但旧 Pod 已经不在了，后面继续发包时依然转发给这个 Pod IP，最终会被转发到这个有相同 IP 的新 Pod 上，而新 Pod 收到此包时检查报文发现不对劲，就返回 RST 给 client 告知将连接重置。针对这种情况，建议应用自身处理好优雅结束：Pod 进入 Terminating 状态后会发送 SIGTERM 信号给业务进程，业务进程的代码需处理这个信号，在进程退出前关闭所有连接。\n  Connection refused: 连接被拒绝。通常是连接还没建立，client 正在发 SYN 包请求建立连接，但到了 server 之后发现端口没监听，内核就返回 RST 包，然后应用层就报错连接被拒绝。比如在 server 滚动更新过程中，旧的 Pod 中的进程很快就停止了(网卡还未完全销毁)，但 client 所在节点的 iptables/ipvs 规则还没更新，包就可能会被转发到了这个停止的 Pod (由于 k8s 的 controller 模式，从 Pod 删除到 service 的 endpoint 更新，再到 kube-proxy watch 到更新并更新 节点上的 iptables/ipvs 规则，这个过程是异步的，中间存在一点时间差，所以有可能存在 Pod 中的进程已经监听，但 iptables/ipvs 规则还没更新的情况)。针对这种情况，建议给容器加一个 preStop，在真正销毁 Pod 之前等待一段时间，留时间给 kube-proxy 更新转发规则，更新完之后就不会再有新连接往这个旧 Pod 转发了，preStop 示例:\nlifecycle: preStop: exec: command: - /bin/bash - -c - sleep 30 另外，还可能是新的 Pod 启动比较慢，虽然状态已经 Ready，但实际上可能端口还没监听，新的请求被转发到这个还没完全启动的 Pod 就会报错连接被拒绝。针对这种情况，建议给容器加就绪检查 (readinessProbe)，让容器真正启动完之后才将其状态置为 Ready，然后 kube-proxy 才会更新转发规则，这样就能保证新的请求只被转发到完全启动的 Pod，readinessProbe 示例:\nreadinessProbe: httpGet: path: /healthz port: 80 httpHeaders: - name: X-Custom-Header value: Awesome initialDelaySeconds: 15 timeoutSeconds: 1   Connection timed out: 连接超时。通常是连接还没建立，client 发 SYN 请求建立连接一直等到超时时间都没有收到 ACK，然后就报错连接超时。这个可能场景跟前面 Connection refused 可能的场景类似，不同点在于端口有监听，但进程无法正常响应了: 转发规则还没更新，旧 Pod 的进程正在停止过程中，虽然端口有监听，但已经不响应了；或者转发规则更新了，新 Pod 端口也监听了，但还没有真正就绪，还没有能力处理新请求。针对这些情况的建议跟前面一样：加 preStop 和 readinessProbe。\n  下面我们来继续分析下滚动更新时发生 No route to host 的可能情况。\n这个报错很明显，IP 无法路由，通常是将报文发到了一个已经彻底销毁的 Pod (网卡已经不在)。不可能发到一个网卡还没创建好的 Pod，因为即便不加存活检查，也是要等到 Pod 网络初始化完后才可能 Ready，然后 kube-proxy 才会更新转发规则。\n什么情况下会转发到一个已经彻底销毁的 Pod？ 借鉴前面几种滚动更新的报错分析，我们推测应该是 Pod 很快销毁了但转发规则还没更新，从而新的请求被转发了这个已经销毁的 Pod，最终报文到达这个 Pod 所在 PodCIDR 的 Node 上时，Node 发现本机已经没有这个 IP 的容器，然后 Node 就返回 ICMP 包告知 client 这个 IP 不可达，client 收到 ICMP 后，应用层就会报错 \u0026ldquo;No route to host\u0026rdquo;。\n所以根据我们的分析，关键点在于 Pod 销毁太快，转发规则还没来得及更新，导致后来的请求被转发到已销毁的 Pod。针对这种情况，我们可以给容器加一个 preStop，留时间给 kube-proxy 更新转发规则来解决，参考 《Kubernetes实践指南》中的部分章节: https://k8s.imroc.io/best-practice/high-availability-deployment-of-applications#smooth-update-using-prestophook-and-readinessprobe\n问题没有解决 我们自己没有复现用户的 \u0026ldquo;No route to host\u0026rdquo; 的问题，可能是复现条件比较苛刻，最后将我们上面理论上的分析结论作为解决方案给到了用户。\n但用户尝试加了 preStop 之后，问题依然存在，服务滚动更新时偶尔还是会出现 \u0026ldquo;No route to host\u0026rdquo;。\n深入分析 为了弄清楚根本原因，我们请求用户协助搭建了一个可以复现问题的测试环境，最终这个问题在测试环境中可以稳定复现。\n仔细观察，实际是部署两个服务：ServiceA 和 ServiceB。使用 ab 压测工具去压测 ServiceA （短连接），然后 ServiceA 会通过 RPC 调用 ServiceB (短连接)，滚动更新的是 ServiceB，报错发生在 ServiceA 调用 ServiceB 这条链路。\n在 ServiceB 滚动更新期间，新的 Pod Ready 了之后会被添加到 IPVS 规则的 RS 列表，但旧的 Pod 不会立即被踢掉，而是将新的 Pod 权重置为1，旧的置为 0，通过在 client 所在节点查看 IPVS 规则可以看出来:\nroot@VM-0-3-ubuntu:~# ipvsadm -ln -t 172.16.255.241:80 Prot LocalAddress:Port Scheduler Flags -\u0026gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 172.16.255.241:80 rr -\u0026gt; 172.16.8.106:80 Masq 0 5 14048 -\u0026gt; 172.16.8.107:80 Masq 1 2 243 为什么不立即踢掉旧的 Pod 呢？因为要支持优雅结束，让存量的连接处理完，等存量连接全部结束了再踢掉它(ActiveConn+InactiveConn=0)，这个逻辑可以通过这里的代码确认：https://github.com/kubernetes/kubernetes/blob/v1.17.0/pkg/proxy/ipvs/graceful_termination.go#L170\n然后再通过 ipvsadm -lnc | grep 172.16.8.106 发现旧 Pod 上的连接大多是 TIME_WAIT 状态，这个也容易理解：因为 ServiceA 作为 client 发起短连接请求调用 ServiceB，调用完成就会关闭连接，TCP 三次挥手后进入 TIME_WAIT 状态，等待 2*MSL (2 分钟) 的时长再清理连接。\n经过上面的分析，看起来都是符合预期的，那为什么还会出现 \u0026ldquo;No route to host\u0026rdquo; 呢？难道权重被置为 0 之后还有新连接往这个旧 Pod 转发？我们来抓包看下：\nroot@VM-0-3-ubuntu:~# tcpdump -i eth0 host 172.16.8.106 -n -tttt tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 2019-12-13 11:49:47.319093 IP 10.0.0.3.36708 \u0026gt; 172.16.8.106.80: Flags [S], seq 3988339656, win 29200, options [mss 1460,sackOK,TS val 3751111666 ecr 0,nop,wscale 9], length 0 2019-12-13 11:49:47.319133 IP 10.0.0.3.36706 \u0026gt; 172.16.8.106.80: Flags [S], seq 109196945, win 29200, options [mss 1460,sackOK,TS val 3751111666 ecr 0,nop,wscale 9], length 0 2019-12-13 11:49:47.319144 IP 10.0.0.3.36704 \u0026gt; 172.16.8.106.80: Flags [S], seq 1838682063, win 29200, options [mss 1460,sackOK,TS val 3751111666 ecr 0,nop,wscale 9], length 0 2019-12-13 11:49:47.319153 IP 10.0.0.3.36702 \u0026gt; 172.16.8.106.80: Flags [S], seq 1591982963, win 29200, options [mss 1460,sackOK,TS val 3751111666 ecr 0,nop,wscale 9], length 0 果然是！即使权重为 0，仍然会尝试发 SYN 包跟这个旧 Pod 建立连接，但永远无法收到 ACK，因为旧 Pod 已经销毁了。为什么会这样呢？难道是 IPVS 内核模块的调度算法有问题？尝试去看了下 linux 内核源码，并没有发现哪个调度策略的实现函数会将新连接调度到权重为 0 的 rs 上。\n这就奇怪了，可能不是调度算法的问题？继续尝试看更多的代码，主要是 net/netfilter/ipvs/ip_vs_core.c 中的 ip_vs_in 函数，也就是 IPVS 模块处理报文的主要入口，发现它会先在本地连接转发表看这个包是否已经有对应的连接了（匹配五元组），如果有就说明它不是新连接也就不会调度，直接发给这个连接对应的之前已经调度过的 rs (也不会判断权重)；如果没匹配到说明这个包是新的连接，就会走到调度这里 (rr, wrr 等调度策略)，这个逻辑看起来也没问题。\n那为什么会转发到权重为 0 的 rs ？难道是匹配连接这里出问题了？新的连接匹配到了旧的连接？我开始做实验验证这个猜想，修改一下这里的逻辑：检查匹配到的连接对应的 rs 如果权重为 0，则重新调度。然后重新编译和加载 IPVS 内核模块，再重新压测一下，发现问题解决了！没有报 \u0026ldquo;No route to host\u0026rdquo; 了。\n虽然通过改内核源码解决了，但我知道这不是一个好的解决方案，它会导致 IPVS 不支持连接的优雅结束，因为不再转发包给权重为 0 的 rs，存量的连接就会立即中断。\n继续陷入深思\u0026hellip;\u0026hellip;\n这个实验只是证明了猜想：新连接匹配到了旧连接。那为什么会这样呢？难道新连接报文的五元组跟旧连接的相同了？\n经过一番思考，发现这个是有可能的。因为 ServiceA 作为 client 请求 ServiceB，不同请求的源 IP 始终是相同的，关键点在于源端口是否可能相同。由于 ServiceA 向 ServiceB 发起大量短连接，ServiceA 所在节点就会有大量 TIME_WAIT 状态的连接，需要等 2 分钟 (2*MSL) 才会清理，而由于连接量太大，每次发起的连接都会占用一个源端口，当源端口不够用了，就会重用 TIME_WAIT 状态连接的源端口，这个时候当报文进入 IPVS 模块，检测到它的五元组跟本地连接转发表中的某个连接一致(TIME_WAIT 状态)，就以为它是一个存量连接，然后直接将报文转发给这个连接之前对应的 rs 上，然而这个 rs 对应的 Pod 早已销毁，所以抓包看到的现象是将 SYN 发给了旧 Pod，并且无法收到 ACK，伴随着返回 ICMP 告知这个 IP 不可达，也被应用解释为 \u0026ldquo;No route to host\u0026rdquo;。\n后来无意间又发现一个还在 open 状态的 issue，虽然还没提到 \u0026ldquo;No route to host\u0026rdquo; 关键字，但讨论的跟我们这个其实是同一个问题。我也参与了讨论，有兴趣的同学可以看下：https://github.com/kubernetes/kubernetes/issues/81775\n总结 这个问题通常发生的场景就是类似于我们测试环境这种：ServiceA 对外提供服务，当外部发起请求，ServiceA 会通过 rpc 或 http 调用 ServiceB，如果外部请求量变大，ServiceA 调用 ServiceB 的量也会跟着变大，大到一定程度，ServiceA 所在节点源端口不够用，复用 TIME_WAIT 状态连接的源端口，导致五元组跟 IPVS 里连接转发表中的 TIME_WAIT 连接相同，IPVS 就认为这是一个存量连接的报文，就不判断权重直接转发给之前的 rs，导致转发到已销毁的 Pod，从而发生 \u0026ldquo;No route to host\u0026rdquo;。\n如何规避？集群规模小可以使用 iptables 模式，如果需要使用 ipvs 模式，可以增加 ServiceA 的副本，并且配置反亲和性 (podAntiAffinity)，让 ServiceA 的 Pod 部署到不同节点，分摊流量，避免流量集中到某一个节点，导致调用 ServiceB 时源端口复用。\n如何彻底解决？暂时还没有一个完美的方案。\nIssue 85517 讨论让 kube-proxy 支持自定义配置几种连接状态的超时时间，但这对 TIME_WAIT 状态无效。\nIssue 81308 讨论 IVPS 的优雅结束是否不考虑不活跃的连接 (包括 TIME_WAIT 状态的连接)，也就是只考虑活跃连接，当活跃连接数为 0 之后立即踢掉 rs。这个确实可以更快的踢掉 rs，但无法让优雅结束做到那么优雅了，并且有人测试了，即便是不考虑不活跃连接，当请求量很大，还是不能很快踢掉 rs，因为源端口复用还是会导致不断有新的连接占用旧的连接，在较新的内核版本，SYN_RECV 状态也被视为活跃连接，所以活跃连接数还是不会很快降到 0。\n这个问题的终极解决方案该走向何方，我们拭目以待，感兴趣的同学可以持续关注 issue 81775 并参与讨论。想学习更多 K8S 知识，可以关注本人的开源书《Kubernetes实践指南》: https://k8s.imroc.io\n"
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/cross-vpc-connect-nodeport-timeout/",
	"title": "跨 VPC 访问 NodePort 经常超时",
	"tags": [],
	"description": "",
	"content": "现象: 从 VPC a 访问 VPC b 的 TKE 集群的某个节点的 NodePort，有时候正常，有时候会卡住直到超时。\n原因怎么查？\n当然是先抓包看看啦，抓 server 端 NodePort 的包，发现异常时 server 能收到 SYN，但没响应 ACK:\n反复执行 netstat -s | grep LISTEN 发现 SYN 被丢弃数量不断增加:\n分析：\n 两个VPC之间使用对等连接打通的，CVM 之间通信应该就跟在一个内网一样可以互通。 为什么同一 VPC 下访问没问题，跨 VPC 有问题? 两者访问的区别是什么?  再仔细看下 client 所在环境，发现 client 是 VPC a 的 TKE 集群节点，捋一下:\n client 在 VPC a 的 TKE 集群的节点 server 在 VPC b 的 TKE 集群的节点  因为 TKE 集群中有个叫 ip-masq-agent 的 daemonset，它会给 node 写 iptables 规则，默认 SNAT 目的 IP 是 VPC 之外的报文，所以 client 访问 server 会做 SNAT，也就是这里跨 VPC 相比同 VPC 访问 NodePort 多了一次 SNAT，如果是因为多了一次 SNAT 导致的这个问题，直觉告诉我这个应该跟内核参数有关，因为是 server 收到包没回包，所以应该是 server 所在 node 的内核参数问题，对比这个 node 和 普通 TKE node 的默认内核参数，发现这个 node net.ipv4.tcp_tw_recycle = 1，这个参数默认是关闭的，跟用户沟通后发现这个内核参数确实在做压测的时候调整过。\n解释一下，TCP 主动关闭连接的一方在发送最后一个 ACK 会进入 TIME_AWAIT 状态，再等待 2 个 MSL 时间后才会关闭(因为如果 server 没收到 client 第四次挥手确认报文，server 会重发第三次挥手 FIN 报文，所以 client 需要停留 2 MSL的时长来处理可能会重复收到的报文段；同时等待 2 MSL 也可以让由于网络不通畅产生的滞留报文失效，避免新建立的连接收到之前旧连接的报文)，了解更详细的过程请参考 TCP 四次挥手。\n参数 tcp_tw_recycle 用于快速回收 TIME_AWAIT 连接，通常在增加连接并发能力的场景会开启，比如发起大量短连接，快速回收可避免 tw_buckets 资源耗尽导致无法建立新连接 (time wait bucket table overflow)\n查得 tcp_tw_recycle 有个坑，在 RFC1323 有段描述:\nAn additional mechanism could be added to the TCP, a per-host cache of the last timestamp received from any connection. This value could then be used in the PAWS mechanism to reject old duplicate segments from earlier incarnations of the connection, if the timestamp clock can be guaranteed to have ticked at least once since the old connection was open. This would require that the TIME-WAIT delay plus the RTT together must be at least one tick of the sender’s timestamp clock. Such an extension is not part of the proposal of this RFC.\n大概意思是说 TCP 有一种行为，可以缓存每个连接最新的时间戳，后续请求中如果时间戳小于缓存的时间戳，即视为无效，相应的数据包会被丢弃。\nLinux 是否启用这种行为取决于 tcp_timestamps 和 tcp_tw_recycle，因为 tcp_timestamps 缺省开启，所以当 tcp_tw_recycle 被开启后，实际上这种行为就被激活了，当客户端或服务端以 NAT 方式构建的时候就可能出现问题。\n当多个客户端通过 NAT 方式联网并与服务端交互时，服务端看到的是同一个 IP，也就是说对服务端而言这些客户端实际上等同于一个，可惜由于这些客户端的时间戳可能存在差异，于是乎从服务端的视角看，便可能出现时间戳错乱的现象，进而直接导致时间戳小的数据包被丢弃。如果发生了此类问题，具体的表现通常是是客户端明明发送的 SYN，但服务端就是不响应 ACK。\n回到我们的问题上，client 所在节点上可能也会有其它 pod 访问到 server 所在节点，而它们都被 SNAT 成了 client 所在节点的 NODE IP，但时间戳存在差异，server 就会看到时间戳错乱，因为开启了 tcp_tw_recycle 和 tcp_timestamps 激活了上述行为，就丢掉了比缓存时间戳小的报文，导致部分 SYN 被丢弃，这也解释了为什么之前我们抓包发现异常时 server 收到了 SYN，但没有响应 ACK，进而说明为什么 client 的请求部分会卡住直到超时。\n由于 tcp_tw_recycle 坑太多，在内核 4.12 之后已移除: remove tcp_tw_recycle\n"
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/",
	"title": "踩坑分享",
	"tags": [],
	"description": "",
	"content": "  ARP 缓存爆满导致健康检查失败   DNS 5 秒延时   DNS 解析异常   kubectl edit 或者 apply 报 SchemaError   LB 压测 NodePort CPS 低   Pod 偶尔存活检查失败   Pod 访问另一个集群的 apiserver 有延时   神秘的溢出与丢包   访问 externalTrafficPolicy 为 Local 的 Service 对应 LB 有时超时   诡异的 No route to host   跨 VPC 访问 NodePort 经常超时   驱逐导致服务中断   "
},
{
	"uri": "https://k8s.imroc.io/cluster/runtime/",
	"title": "运行时方案",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/deploy/addons/coredns/",
	"title": "部署 CoreDNS",
	"tags": [],
	"description": "",
	"content": "下载部署脚本 $ git clone https://github.com/coredns/deployment.git $ cd deployment/kubernetes $ ls CoreDNS-k8s_version.md FAQs.md README.md Scaling_CoreDNS.md Upgrading_CoreDNS.md coredns.yaml.sed corefile-tool deploy.sh migration rollback.sh 部署脚本用法 查看 help:\n$ ./deploy.sh -h usage: ./deploy.sh [ -r REVERSE-CIDR ] [ -i DNS-IP ] [ -d CLUSTER-DOMAIN ] [ -t YAML-TEMPLATE ] -r : Define a reverse zone for the given CIDR. You may specifcy this option more than once to add multiple reverse zones. If no reverse CIDRs are defined, then the default is to handle all reverse zones (i.e. in-addr.arpa and ip6.arpa) -i : Specify the cluster DNS IP address. If not specificed, the IP address of the existing \u0026#34;kube-dns\u0026#34; service is used, if present. -s : Skips the translation of kube-dns configmap to the corresponding CoreDNS Corefile configuration. 部署 总体流程是我们使用 deploy.sh 生成 yaml 并保存成 coredns.yaml 文件并执行 kubectl apply -f coredns.yaml 进行部署 ，如果要卸载，执行 kubectl delete -f coredns.yaml。\ndeploy.sh 脚本依赖 jq 命令，所以先确保 jq 已安装:\napt install -y jq 全新部署 如果集群中没有 kube-dns 或低版本 coredns，我们直接用 -i 参数指定集群 DNS 的 CLUSTER IP，这个 IP 是安装集群时就确定好的，示例:\n./deploy.sh -i 10.32.0.255 \u0026gt; coredns.yaml kubectl apply -f coredns.yaml "
},
{
	"uri": "https://k8s.imroc.io/cluster/network/flannel/deploy/",
	"title": "部署 Flannel",
	"tags": [],
	"description": "",
	"content": "记集群网段为 CLUSTER_CIDR:\nCLUSTER_CIDR=10.10.0.0/16 创建 flannel 资源文件:\ncat \u0026lt;\u0026lt;EOF | sudo tee kube-flannel.yml apiVersion: policy/v1beta1 kind: PodSecurityPolicy metadata: name: psp.flannel.unprivileged annotations: seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default spec: privileged: false volumes: - configMap - secret - emptyDir - hostPath allowedHostPaths: - pathPrefix: \u0026#34;/etc/cni/net.d\u0026#34; - pathPrefix: \u0026#34;/etc/kube-flannel\u0026#34; - pathPrefix: \u0026#34;/run/flannel\u0026#34; readOnlyRootFilesystem: false # Users and groups runAsUser: rule: RunAsAny supplementalGroups: rule: RunAsAny fsGroup: rule: RunAsAny # Privilege Escalation allowPrivilegeEscalation: false defaultAllowPrivilegeEscalation: false # Capabilities allowedCapabilities: [\u0026#39;NET_ADMIN\u0026#39;] defaultAddCapabilities: [] requiredDropCapabilities: [] # Host namespaces hostPID: false hostIPC: false hostNetwork: true hostPorts: - min: 0 max: 65535 # SELinux seLinux: # SELinux is unsed in CaaSP rule: \u0026#39;RunAsAny\u0026#39; --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: flannel rules: - apiGroups: [\u0026#39;extensions\u0026#39;] resources: [\u0026#39;podsecuritypolicies\u0026#39;] verbs: [\u0026#39;use\u0026#39;] resourceNames: [\u0026#39;psp.flannel.unprivileged\u0026#39;] - apiGroups: - \u0026#34;\u0026#34; resources: - pods verbs: - get - apiGroups: - \u0026#34;\u0026#34; resources: - nodes verbs: - list - watch - apiGroups: - \u0026#34;\u0026#34; resources: - nodes/status verbs: - patch --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: flannel roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: flannel subjects: - kind: ServiceAccount name: flannel namespace: kube-system --- apiVersion: v1 kind: ServiceAccount metadata: name: flannel namespace: kube-system --- kind: ConfigMap apiVersion: v1 metadata: name: kube-flannel-cfg namespace: kube-system labels: tier: node app: flannel data: cni-conf.json: | { \u0026#34;cniVersion\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;cbr0\u0026#34;, \u0026#34;plugins\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;flannel\u0026#34;, \u0026#34;delegate\u0026#34;: { \u0026#34;hairpinMode\u0026#34;: true, \u0026#34;isDefaultGateway\u0026#34;: true } }, { \u0026#34;type\u0026#34;: \u0026#34;portmap\u0026#34;, \u0026#34;capabilities\u0026#34;: { \u0026#34;portMappings\u0026#34;: true } } ] } net-conf.json: | { \u0026#34;Network\u0026#34;: \u0026#34;${CLUSTER_CIDR}\u0026#34;, \u0026#34;Backend\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;vxlan\u0026#34; } } --- apiVersion: apps/v1 kind: DaemonSet metadata: name: kube-flannel-ds-amd64 namespace: kube-system labels: tier: node app: flannel spec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: beta.kubernetes.io/os operator: In values: - linux - key: beta.kubernetes.io/arch operator: In values: - amd64 hostNetwork: true tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.11.0-amd64 command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.11.0-amd64 command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; limits: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; securityContext: privileged: false capabilities: add: [\u0026#34;NET_ADMIN\u0026#34;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg --- apiVersion: apps/v1 kind: DaemonSet metadata: name: kube-flannel-ds-arm64 namespace: kube-system labels: tier: node app: flannel spec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: beta.kubernetes.io/os operator: In values: - linux - key: beta.kubernetes.io/arch operator: In values: - arm64 hostNetwork: true tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.11.0-arm64 command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.11.0-arm64 command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; limits: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; securityContext: privileged: false capabilities: add: [\u0026#34;NET_ADMIN\u0026#34;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg --- apiVersion: apps/v1 kind: DaemonSet metadata: name: kube-flannel-ds-arm namespace: kube-system labels: tier: node app: flannel spec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: beta.kubernetes.io/os operator: In values: - linux - key: beta.kubernetes.io/arch operator: In values: - arm hostNetwork: true tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.11.0-arm command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.11.0-arm command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; limits: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; securityContext: privileged: false capabilities: add: [\u0026#34;NET_ADMIN\u0026#34;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg --- apiVersion: apps/v1 kind: DaemonSet metadata: name: kube-flannel-ds-ppc64le namespace: kube-system labels: tier: node app: flannel spec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: beta.kubernetes.io/os operator: In values: - linux - key: beta.kubernetes.io/arch operator: In values: - ppc64le hostNetwork: true tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.11.0-ppc64le command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.11.0-ppc64le command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; limits: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; securityContext: privileged: false capabilities: add: [\u0026#34;NET_ADMIN\u0026#34;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg --- apiVersion: apps/v1 kind: DaemonSet metadata: name: kube-flannel-ds-s390x namespace: kube-system labels: tier: node app: flannel spec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: beta.kubernetes.io/os operator: In values: - linux - key: beta.kubernetes.io/arch operator: In values: - s390x hostNetwork: true tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.11.0-s390x command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.11.0-s390x command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; limits: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; securityContext: privileged: false capabilities: add: [\u0026#34;NET_ADMIN\u0026#34;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg EOF 部署:\nkubectl apply -f kube-flannel.yml  以上资源文件参考 flannel 官方: https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml (仅提取了 CLUSTER_CIDR 变量)\n "
},
{
	"uri": "https://k8s.imroc.io/deploy/appendix/",
	"title": "附录",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/security/permission/",
	"title": "集群权限控制",
	"tags": [],
	"description": "",
	"content": "账户类型 K8S 主要有以下两种账户类型概念:\n 用户账户 (User): 控制人的权限。 服务账户 (ServiceAccount): 控制应用程序的权限  如果开启集群审计，就可以区分某个操作是哪个用户或哪个应程序执行的。\n"
},
{
	"uri": "https://k8s.imroc.io/security/cert/",
	"title": "集群证书管理",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/best-practice/configuration-management/",
	"title": "集群配置管理",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://k8s.imroc.io/avoid/cases/eviction-leads-to-service-disruption/",
	"title": "驱逐导致服务中断",
	"tags": [],
	"description": "",
	"content": "TODO 优化\n案例 TKE 一客户的某个节点有问题，无法挂载nfs，通过新加节点，驱逐故障节点的 pod 来规避，但导致了业务 10min 服务不可用，排查发现其它节点 pod 很多集体出现了重启，主要是连不上 kube-dns 无法解析 service，业务调用不成功，从而对外表现为服务不可用。\n为什么会中断？驱逐的原理是先封锁节点，然后将旧的 node 上的 pod 删除，replicaset 控制器检测到 pod 减少，会重新创建一个 pod，调度到新的 node上，这个过程是先删除，再创建，并非是滚动更新，因此更新过程中，如果一个deployment的所有 pod 都在被驱逐的节点上，则可能导致该服务不可用。\n那为什么会影响其它 pod？分析kubelet日志，kube-dns 有两个副本，都在这个被驱逐的节点上，所以驱逐的时候 kube-dns 不通，影响了其它 pod 解析 service，导致服务集体不可用。\n那为什么会中断这么久？通常在新的节点应该很会快才是，通过进一步分析新节点的 kubelet 日志，发现 kube-dns 从拉镜像到容器启动之间花了很长时间，检查节点上的镜像发现有很多大镜像(1~2GB)，猜测是拉取镜像有并发限制，kube-dns 的镜像虽小，但在排队等大镜像下载完，检查 kubelet 启动参数，确实有 --registry-burst 这个参数控制镜像下载并发数限制。但最终发现其实应该是 --serialize-image-pulls 这个参数导致的，kubelet 启动参数没有指定该参数，而该参数默认值为 true，即默认串行下载镜像，不并发下载，所以导致镜像下载排队，是的 kube-dns 延迟了很长时间才启动。\n解决方案  避免服务单点故障，多副本，并加反亲和性 设置 preStop hook 与 readinessProbe，更新路由规则  "
},
{
	"uri": "https://k8s.imroc.io/troubleshooting/handle/high-load/",
	"title": "高负载",
	"tags": [],
	"description": "",
	"content": "TODO 优化\n节点高负载会导致进程无法获得足够的 cpu 时间片来运行，通常表现为网络 timeout，健康检查失败，服务不可用。\n过多 IO 等待 有时候即便 cpu ‘us’ (user) 不高但 cpu ‘id’ (idle) 很高的情况节点负载也很高，这是为什么呢？通常是文件 IO 性能达到瓶颈导致 IO WAIT 过多，从而使得节点整体负载升高，影响其它进程的性能。\n使用 top 命令看下当前负载：\ntop - 19:42:06 up 23:59, 2 users, load average: 34.64, 35.80, 35.76 Tasks: 679 total, 1 running, 678 sleeping, 0 stopped, 0 zombie Cpu(s): 15.6%us, 1.7%sy, 0.0%ni, 74.7%id, 7.9%wa, 0.0%hi, 0.1%si, 0.0%st Mem: 32865032k total, 30989168k used, 1875864k free, 370748k buffers Swap: 8388604k total, 5440k used, 8383164k free, 7982424k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 9783 mysql 20 0 17.3g 16g 8104 S 186.9 52.3 3752:33 mysqld 5700 nginx 20 0 1330m 66m 9496 S 8.9 0.2 0:20.82 php-fpm 6424 nginx 20 0 1330m 65m 8372 S 8.3 0.2 0:04.97 php-fpm 6573 nginx 20 0 1330m 64m 7368 S 8.3 0.2 0:01.49 php-fpm 5927 nginx 20 0 1320m 56m 9272 S 7.6 0.2 0:12.54 php-fpm 5956 nginx 20 0 1330m 65m 8500 S 7.6 0.2 0:12.70 php-fpm 6126 nginx 20 0 1321m 57m 8964 S 7.3 0.2 0:09.72 php-fpm 6127 nginx 20 0 1319m 54m 9520 S 6.6 0.2 0:08.73 php-fpm 6131 nginx 20 0 1320m 56m 9404 S 6.6 0.2 0:09.43 php-fpm 6174 nginx 20 0 1321m 56m 8444 S 6.3 0.2 0:08.92 php-fpm 5790 nginx 20 0 1319m 54m 9468 S 5.6 0.2 0:17.33 php-fpm 6575 nginx 20 0 1320m 55m 8212 S 5.6 0.2 0:02.11 php-fpm 6160 nginx 20 0 1310m 44m 8296 S 4.0 0.1 0:10.05 php-fpm 5597 nginx 20 0 1310m 46m 9556 S 3.6 0.1 0:21.03 php-fpm 5786 nginx 20 0 1310m 45m 8528 S 3.6 0.1 0:15.53 php-fpm 5797 nginx 20 0 1310m 46m 9444 S 3.6 0.1 0:14.02 php-fpm 6158 nginx 20 0 1310m 45m 8324 S 3.6 0.1 0:10.20 php-fpm 5698 nginx 20 0 1310m 46m 9184 S 3.3 0.1 0:20.62 php-fpm 5779 nginx 20 0 1309m 44m 8336 S 3.3 0.1 0:15.34 php-fpm 6540 nginx 20 0 1306m 40m 7884 S 3.3 0.1 0:02.46 php-fpm 5553 nginx 20 0 1300m 36m 9568 S 3.0 0.1 0:21.58 php-fpm 5722 nginx 20 0 1310m 45m 8552 S 3.0 0.1 0:17.25 php-fpm 5920 nginx 20 0 1302m 36m 8208 S 3.0 0.1 0:14.23 php-fpm 6432 nginx 20 0 1310m 45m 8420 S 3.0 0.1 0:05.86 php-fpm 5285 nginx 20 0 1302m 38m 9696 S 2.7 0.1 0:23.41 php-fpm wa (wait) 表示 IO WAIT 的 cpu 占用，默认看到的是所有核的平均值，要看每个核的 wa 值需要按下 \u0026ldquo;1\u0026rdquo;:\ntop - 19:42:08 up 23:59, 2 users, load average: 34.64, 35.80, 35.76 Tasks: 679 total, 1 running, 678 sleeping, 0 stopped, 0 zombie Cpu0 : 29.5%us, 3.7%sy, 0.0%ni, 48.7%id, 17.9%wa, 0.0%hi, 0.1%si, 0.0%st Cpu1 : 29.3%us, 3.7%sy, 0.0%ni, 48.9%id, 17.9%wa, 0.0%hi, 0.1%si, 0.0%st Cpu2 : 26.1%us, 3.1%sy, 0.0%ni, 64.4%id, 6.0%wa, 0.0%hi, 0.3%si, 0.0%st Cpu3 : 25.9%us, 3.1%sy, 0.0%ni, 65.5%id, 5.4%wa, 0.0%hi, 0.1%si, 0.0%st Cpu4 : 24.9%us, 3.0%sy, 0.0%ni, 66.8%id, 5.0%wa, 0.0%hi, 0.3%si, 0.0%st Cpu5 : 24.9%us, 2.9%sy, 0.0%ni, 67.0%id, 4.8%wa, 0.0%hi, 0.3%si, 0.0%st Cpu6 : 24.2%us, 2.7%sy, 0.0%ni, 68.3%id, 4.5%wa, 0.0%hi, 0.3%si, 0.0%st Cpu7 : 24.3%us, 2.6%sy, 0.0%ni, 68.5%id, 4.2%wa, 0.0%hi, 0.3%si, 0.0%st Cpu8 : 23.8%us, 2.6%sy, 0.0%ni, 69.2%id, 4.1%wa, 0.0%hi, 0.3%si, 0.0%st Cpu9 : 23.9%us, 2.5%sy, 0.0%ni, 69.3%id, 4.0%wa, 0.0%hi, 0.3%si, 0.0%st Cpu10 : 23.3%us, 2.4%sy, 0.0%ni, 68.7%id, 5.6%wa, 0.0%hi, 0.0%si, 0.0%st Cpu11 : 23.3%us, 2.4%sy, 0.0%ni, 69.2%id, 5.1%wa, 0.0%hi, 0.0%si, 0.0%st Cpu12 : 21.8%us, 2.4%sy, 0.0%ni, 60.2%id, 15.5%wa, 0.0%hi, 0.0%si, 0.0%st Cpu13 : 21.9%us, 2.4%sy, 0.0%ni, 60.6%id, 15.2%wa, 0.0%hi, 0.0%si, 0.0%st Cpu14 : 21.4%us, 2.3%sy, 0.0%ni, 72.6%id, 3.7%wa, 0.0%hi, 0.0%si, 0.0%st Cpu15 : 21.5%us, 2.2%sy, 0.0%ni, 73.2%id, 3.1%wa, 0.0%hi, 0.0%si, 0.0%st Cpu16 : 21.2%us, 2.2%sy, 0.0%ni, 73.6%id, 3.0%wa, 0.0%hi, 0.0%si, 0.0%st Cpu17 : 21.2%us, 2.1%sy, 0.0%ni, 73.8%id, 2.8%wa, 0.0%hi, 0.0%si, 0.0%st Cpu18 : 20.9%us, 2.1%sy, 0.0%ni, 74.1%id, 2.9%wa, 0.0%hi, 0.0%si, 0.0%st Cpu19 : 21.0%us, 2.1%sy, 0.0%ni, 74.4%id, 2.5%wa, 0.0%hi, 0.0%si, 0.0%st Cpu20 : 20.7%us, 2.0%sy, 0.0%ni, 73.8%id, 3.4%wa, 0.0%hi, 0.0%si, 0.0%st Cpu21 : 20.8%us, 2.0%sy, 0.0%ni, 73.9%id, 3.2%wa, 0.0%hi, 0.0%si, 0.0%st Cpu22 : 20.8%us, 2.0%sy, 0.0%ni, 74.4%id, 2.8%wa, 0.0%hi, 0.0%si, 0.0%st Cpu23 : 20.8%us, 1.9%sy, 0.0%ni, 74.4%id, 2.8%wa, 0.0%hi, 0.0%si, 0.0%st Mem: 32865032k total, 30209248k used, 2655784k free, 370748k buffers Swap: 8388604k total, 5440k used, 8383164k free, 7986552k cached wa 通常是 0%，如果经常在 1 之上，说明存储设备的速度已经太慢，无法跟上 cpu 的处理速度。\n使用 atop 看下当前磁盘 IO 状态:\nATOP - lemp 2017/01/23 19:42:32 --------- 10s elapsed PRC | sys 3.18s | user 33.24s | #proc 679 | #tslpu 28 | #zombie 0 | #exit 0 | CPU | sys 29% | user 330% | irq 1% | idle 1857% | wait 182% | curscal 69% | CPL | avg1 33.00 | avg5 35.29 | avg15 35.59 | csw 62610 | intr 76926 | numcpu 24 | MEM | tot 31.3G | free 2.1G | cache 7.6G | dirty 41.0M | buff 362.1M | slab 1.2G | SWP | tot 8.0G | free 8.0G | | | vmcom 23.9G | vmlim 23.7G | DSK | sda | busy 100% | read 4 | write 1789 | MBw/s 2.84 | avio 5.58 ms | NET | transport | tcpi 10357 | tcpo 9065 | udpi 0 | udpo 0 | tcpao 174 | NET | network | ipi 10360 | ipo 9065 | ipfrw 0 | deliv 10359 | icmpo 0 | NET | eth0 4% | pcki 6649 | pcko 6136 | si 1478 Kbps | so 4115 Kbps | erro 0 | NET | lo ---- | pcki 4082 | pcko 4082 | si 8967 Kbps | so 8967 Kbps | erro 0 | PID TID THR SYSCPU USRCPU VGROW RGROW RDDSK WRDSK ST EXC S CPUNR CPU CMD 1/12 9783 - 156 0.21s 19.44s 0K -788K 4K 1344K -- - S 4 197% mysqld 5596 - 1 0.10s 0.62s 47204K 47004K 0K 220K -- - S 18 7% php-fpm 6429 - 1 0.06s 0.34s 19840K 19968K 0K 0K -- - S 21 4% php-fpm 6210 - 1 0.03s 0.30s -5216K -5204K 0K 0K -- - S 19 3% php-fpm 5757 - 1 0.05s 0.27s 26072K 26012K 0K 4K -- - S 13 3% php-fpm 6433 - 1 0.04s 0.28s -2816K -2816K 0K 0K -- - S 11 3% php-fpm 5846 - 1 0.06s 0.22s -2560K -2660K 0K 0K -- - S 7 3% php-fpm 5791 - 1 0.05s 0.21s 5764K 5692K 0K 0K -- - S 22 3% php-fpm 5860 - 1 0.04s 0.21s 48088K 47724K 0K 0K -- - S 1 3% php-fpm 6231 - 1 0.04s 0.20s -256K -4K 0K 0K -- - S 1 2% php-fpm 6154 - 1 0.03s 0.21s -3004K -3184K 0K 0K -- - S 21 2% php-fpm 6573 - 1 0.04s 0.20s -512K -168K 0K 0K -- - S 4 2% php-fpm 6435 - 1 0.04s 0.19s -3216K -2980K 0K 0K -- - S 15 2% php-fpm 5954 - 1 0.03s 0.20s 0K 164K 0K 4K -- - S 0 2% php-fpm 6133 - 1 0.03s 0.19s 41056K 40432K 0K 0K -- - S 18 2% php-fpm 6132 - 1 0.02s 0.20s 37836K 37440K 0K 0K -- - S 11 2% php-fpm 6242 - 1 0.03s 0.19s -12.2M -12.3M 0K 4K -- - S 12 2% php-fpm 6285 - 1 0.02s 0.19s 39516K 39420K 0K 0K -- - S 3 2% php-fpm 6455 - 1 0.05s 0.16s 29008K 28560K 0K 0K -- - S 14 2% php-fpm 在本例中磁盘 sda 已经 100% busy，已经严重达到性能瓶颈。按 \u0026lsquo;d\u0026rsquo; 看下是哪些进程在使用磁盘IO:\nATOP - lemp 2017/01/23 19:42:46 --------- 2s elapsed PRC | sys 0.24s | user 1.99s | #proc 679 | #tslpu 54 | #zombie 0 | #exit 0 | CPU | sys 11% | user 101% | irq 1% | idle 2089% | wait 208% | curscal 63% | CPL | avg1 38.49 | avg5 36.48 | avg15 35.98 | csw 4654 | intr 6876 | numcpu 24 | MEM | tot 31.3G | free 2.2G | cache 7.6G | dirty 48.7M | buff 362.1M | slab 1.2G | SWP | tot 8.0G | free 8.0G | | | vmcom 23.9G | vmlim 23.7G | DSK | sda | busy 100% | read 2 | write 362 | MBw/s 2.28 | avio 5.49 ms | NET | transport | tcpi 1031 | tcpo 968 | udpi 0 | udpo 0 | tcpao 45 | NET | network | ipi 1031 | ipo 968 | ipfrw 0 | deliv 1031 | icmpo 0 | NET | eth0 1% | pcki 558 | pcko 508 | si 762 Kbps | so 1077 Kbps | erro 0 | NET | lo ---- | pcki 406 | pcko 406 | si 2273 Kbps | so 2273 Kbps | erro 0 | PID TID RDDSK WRDSK WCANCL DSK CMD 1/5 9783 - 0K 468K 16K 40% mysqld 1930 - 0K 212K 0K 18% flush-8:0 5896 - 0K 152K 0K 13% nginx 880 - 0K 148K 0K 13% jbd2/sda5-8 5909 - 0K 60K 0K 5% nginx 5906 - 0K 36K 0K 3% nginx 5907 - 16K 8K 0K 2% nginx 5903 - 20K 0K 0K 2% nginx 5901 - 0K 12K 0K 1% nginx 5908 - 0K 8K 0K 1% nginx 5894 - 0K 8K 0K 1% nginx 5911 - 0K 8K 0K 1% nginx 5900 - 0K 4K 4K 0% nginx 5551 - 0K 4K 0K 0% php-fpm 5913 - 0K 4K 0K 0% nginx 5895 - 0K 4K 0K 0% nginx 6133 - 0K 0K 0K 0% php-fpm 5780 - 0K 0K 0K 0% php-fpm 6675 - 0K 0K 0K 0% atop 也可以使用 iotop -oPa 查看哪些进程占用磁盘 IO:\nTotal DISK READ: 15.02 K/s | Total DISK WRITE: 3.82 M/s PID PRIO USER DISK READ DISK WRITE SWAPIN IO\u0026gt; COMMAND 1930 be/4 root 0.00 B 1956.00 K 0.00 % 83.34 % [flush-8:0] 5914 be/4 nginx 0.00 B 0.00 B 0.00 % 36.56 % nginx: cache manager process 880 be/3 root 0.00 B 21.27 M 0.00 % 35.03 % [jbd2/sda5-8] 5913 be/2 nginx 36.00 K 1000.00 K 0.00 % 8.94 % nginx: worker process 5910 be/2 nginx 0.00 B 1048.00 K 0.00 % 8.43 % nginx: worker process 5896 be/2 nginx 56.00 K 452.00 K 0.00 % 6.91 % nginx: worker process 5909 be/2 nginx 20.00 K 1144.00 K 0.00 % 6.24 % nginx: worker process 5890 be/2 nginx 48.00 K 692.00 K 0.00 % 6.07 % nginx: worker process 5892 be/2 nginx 84.00 K 736.00 K 0.00 % 5.71 % nginx: worker process 5901 be/2 nginx 20.00 K 504.00 K 0.00 % 5.46 % nginx: worker process 5899 be/2 nginx 0.00 B 596.00 K 0.00 % 5.14 % nginx: worker process 5897 be/2 nginx 28.00 K 1388.00 K 0.00 % 4.90 % nginx: worker process 5908 be/2 nginx 48.00 K 700.00 K 0.00 % 4.43 % nginx: worker process 5905 be/2 nginx 32.00 K 1140.00 K 0.00 % 4.36 % nginx: worker process 5900 be/2 nginx 0.00 B 1208.00 K 0.00 % 4.31 % nginx: worker process 5904 be/2 nginx 36.00 K 1244.00 K 0.00 % 2.80 % nginx: worker process 5895 be/2 nginx 16.00 K 780.00 K 0.00 % 2.50 % nginx: worker process 5907 be/2 nginx 0.00 B 1548.00 K 0.00 % 2.43 % nginx: worker process 5903 be/2 nginx 36.00 K 1032.00 K 0.00 % 2.34 % nginx: worker process 6130 be/4 nginx 0.00 B 72.00 K 0.00 % 2.18 % php-fpm: pool www 5906 be/2 nginx 12.00 K 844.00 K 0.00 % 2.10 % nginx: worker process 5889 be/2 nginx 40.00 K 1164.00 K 0.00 % 2.00 % nginx: worker process 5894 be/2 nginx 44.00 K 760.00 K 0.00 % 1.61 % nginx: worker process 5902 be/2 nginx 52.00 K 992.00 K 0.00 % 1.55 % nginx: worker process 5893 be/2 nginx 64.00 K 972.00 K 0.00 % 1.22 % nginx: worker process 5814 be/4 nginx 36.00 K 44.00 K 0.00 % 1.06 % php-fpm: pool www 6159 be/4 nginx 4.00 K 4.00 K 0.00 % 1.00 % php-fpm: pool www 5693 be/4 nginx 0.00 B 4.00 K 0.00 % 0.86 % php-fpm: pool www 5912 be/2 nginx 68.00 K 300.00 K 0.00 % 0.72 % nginx: worker process 5911 be/2 nginx 20.00 K 788.00 K 0.00 % 0.72 % nginx: worker process 通过 man iotop 可以看下这几个参数的含义：\n-o, --only Only show processes or threads actually doing I/O, instead of showing all processes or threads. This can be dynamically toggled by pressing o. -P, --processes Only show processes. Normally iotop shows all threads. -a, --accumulated Show accumulated I/O instead of bandwidth. In this mode, iotop shows the amount of I/O processes have done since iotop started. 节点上部署了其它非 K8S 管理的服务 TODO 优化\n比如在节点上装了数据库，但不被 K8S 所管理，这是用法不正确，不建议在 K8S 节点上部署其它进程。\n参考资料  Linux server performance: Is disk I/O slowing your application: https://haydenjames.io/linux-server-performance-disk-io-slowing-application/  "
}]